{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data:  [[1, 0], [0, 1]]\n",
      "Input:  [[1, 0, 0, 1]]\n",
      "Input Reverse:  [[0, 1, 1, 0]]\n",
      "Input Equal:  [[1, 0, 1, 0], [0, 1, 0, 1]]\n",
      "Total Input:  [[1, 0, 0, 1], [0, 1, 1, 0], [1, 0, 1, 0], [0, 1, 0, 1]]\n",
      "Labels:  [0]\n",
      "tensor([[1, 0],\n",
      "        [0, 1]])\n",
      "tensor([0])\n",
      "tensor([[1, 0, 0, 1],\n",
      "        [0, 1, 1, 0],\n",
      "        [1, 0, 1, 0],\n",
      "        [0, 1, 0, 1]])\n",
      "tensor([[1, 0, 1, 0],\n",
      "        [1, 0, 0, 1],\n",
      "        [0, 1, 1, 0],\n",
      "        [0, 1, 0, 1]])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import itertools\n",
    "\n",
    "class Ti:\n",
    "    def createData(n):\n",
    "        data = []\n",
    "        for i in range(n):\n",
    "            oneHot = [0]*n\n",
    "            oneHot[i] = 1\n",
    "            data.append(oneHot)\n",
    "        return data\n",
    "    def createInput(array):\n",
    "        inputData = []\n",
    "        for i in range(len(array) - 1):\n",
    "            inputData.append(array[i] + array[i+1])\n",
    "        return inputData\n",
    "    def createInputReverse(array):\n",
    "        inputData = []\n",
    "        for i in range(len(array) - 1):\n",
    "            inputData.append(array[i+1] + array[i])\n",
    "        return inputData\n",
    "    def createInputEqual(array): #delete for later\n",
    "        inputData = []\n",
    "        for i in range(len(array)):\n",
    "            inputData.append(array[i] + array[i])\n",
    "        return inputData\n",
    "    def createInputTotal(array):\n",
    "        input = Ti.createInput(array)\n",
    "        inputReverse = Ti.createInputReverse(array)\n",
    "        inputEqual = Ti.createInputEqual(array) #delete for later\n",
    "        return input + inputReverse + inputEqual\n",
    "    def createLabels(array):\n",
    "        forwardArr = Ti.createInput(array)\n",
    "        reverseArr = Ti.createInputReverse(array)\n",
    "        equalArr = Ti.createInputEqual(array)\n",
    "        forwardLabel = [1] * len(forwardArr)\n",
    "        reverseLabel = [0] * len(reverseArr)\n",
    "        equalLabel = [0] * len(equalArr)\n",
    "        return forwardLabel + reverseLabel + equalLabel\n",
    "    def createTest(array):      \n",
    "        testSet = []\n",
    "        for i in array:\n",
    "            for j in array:\n",
    "                concatenated = i + j #remove equal vectors\n",
    "                testSet.append(concatenated)\n",
    "        return testSet\n",
    "\n",
    "\n",
    "num_items = 2\n",
    "\n",
    "## TESTING\n",
    "array = Ti.createData(num_items)\n",
    "print(\"Data: \", array)\n",
    "input = Ti.createInput(array)\n",
    "print(\"Input: \", input)\n",
    "inputReverse = Ti.createInputReverse(array)\n",
    "print(\"Input Reverse: \", inputReverse)\n",
    "inputEqual = Ti.createInputEqual(array)\n",
    "print(\"Input Equal: \", inputEqual)\n",
    "\n",
    "inputTotal = Ti.createInputTotal(array)\n",
    "print(\"Total Input: \", inputTotal)\n",
    "\n",
    "labels = Ti.createLabels(input)\n",
    "print(\"Labels: \", labels)\n",
    "\n",
    "tensorArray = torch.tensor(array)\n",
    "print(tensorArray)\n",
    "\n",
    "tensorLabels = torch.tensor(labels)\n",
    "print(tensorLabels)\n",
    "\n",
    "tensorInputTotal = torch.tensor(inputTotal)\n",
    "print(tensorInputTotal)\n",
    "\n",
    "tensorCreateTest = torch.tensor(Ti.createTest(array))\n",
    "print(tensorCreateTest)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n",
      "0 1\n",
      "0 2\n",
      "0 3\n",
      "0 4\n",
      "0 5\n",
      "0 6\n",
      "0 7\n",
      "0 8\n",
      "0 9\n",
      "1 0\n",
      "1 1\n",
      "1 2\n",
      "1 3\n",
      "1 4\n",
      "1 5\n",
      "1 6\n",
      "1 7\n",
      "1 8\n",
      "1 9\n",
      "2 0\n",
      "2 1\n",
      "2 2\n",
      "2 3\n",
      "2 4\n",
      "2 5\n",
      "2 6\n",
      "2 7\n",
      "2 8\n",
      "2 9\n",
      "3 0\n",
      "3 1\n",
      "3 2\n",
      "3 3\n",
      "3 4\n",
      "3 5\n",
      "3 6\n",
      "3 7\n",
      "3 8\n",
      "3 9\n",
      "4 0\n",
      "4 1\n",
      "4 2\n",
      "4 3\n",
      "4 4\n",
      "4 5\n",
      "4 6\n",
      "4 7\n",
      "4 8\n",
      "4 9\n",
      "5 0\n",
      "5 1\n",
      "5 2\n",
      "5 3\n",
      "5 4\n",
      "5 5\n",
      "5 6\n",
      "5 7\n",
      "5 8\n",
      "5 9\n",
      "6 0\n",
      "6 1\n",
      "6 2\n",
      "6 3\n",
      "6 4\n",
      "6 5\n",
      "6 6\n",
      "6 7\n",
      "6 8\n",
      "6 9\n",
      "7 0\n",
      "7 1\n",
      "7 2\n",
      "7 3\n",
      "7 4\n",
      "7 5\n",
      "7 6\n",
      "7 7\n",
      "7 8\n",
      "7 9\n",
      "8 0\n",
      "8 1\n",
      "8 2\n",
      "8 3\n",
      "8 4\n",
      "8 5\n",
      "8 6\n",
      "8 7\n",
      "8 8\n",
      "8 9\n",
      "9 0\n",
      "9 1\n",
      "9 2\n",
      "9 3\n",
      "9 4\n",
      "9 5\n",
      "9 6\n",
      "9 7\n",
      "9 8\n",
      "9 9\n",
      "[0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]]\n",
      "One hot vectors: \n",
      " tensor([[1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]])\n",
      "Concatenated Input vectors: \n",
      " tensor([[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
      "        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]])\n",
      "Labels: \n",
      " tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0])\n",
      "Testing Set: \n",
      " tensor([[1, 0, 0,  ..., 0, 0, 0],\n",
      "        [1, 0, 0,  ..., 0, 0, 0],\n",
      "        [1, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 1, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 1, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 1]])\n",
      "Testing Labels: \n",
      " tensor([0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1,\n",
      "        1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1,\n",
      "        1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import itertools\n",
    "import torch.nn.functional as F\n",
    "\n",
    "num_items = 10\n",
    "item_indices = torch.arange(num_items)  # Indices for items 'A', 'B', 'C'\n",
    "one_hot_vectors = F.one_hot(item_indices, num_classes = num_items)\n",
    "\n",
    "testSet = []\n",
    "testLabels = []\n",
    "for idx_i, i in enumerate(one_hot_vectors):\n",
    "    for idx_j, j in enumerate(one_hot_vectors):\n",
    "        concatenated = torch.cat((i,j))\n",
    "        testSet.append(concatenated.tolist())\n",
    "        testLabels.append(int(idx_i < idx_j))\n",
    "        print(idx_i, idx_j)\n",
    "print(testLabels)\n",
    "print(testSet)\n",
    "testSet = torch.tensor(testSet)\n",
    "testLabels = torch.tensor(testLabels)\n",
    "inputTotal = torch.tensor(Ti.createInputTotal(one_hot_vectors.tolist()))\n",
    "labels = torch.tensor(Ti.createLabels(one_hot_vectors.tolist()))\n",
    "\n",
    "print('One hot vectors: \\n', one_hot_vectors)\n",
    "print('Concatenated Input vectors: \\n' ,inputTotal)\n",
    "print('Labels: \\n', labels)\n",
    "print('Testing Set: \\n', testSet)\n",
    "print('Testing Labels: \\n', testLabels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "NeuralNetwork(\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=20, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=1, bias=True)\n",
      "    (3): Sigmoid()\n",
      "  )\n",
      ")\n",
      "loss: 0.680652  [    0/   28]\n",
      "loss: 0.678751  [    0/   28]\n",
      "loss: 0.676921  [    0/   28]\n",
      "loss: 0.675157  [    0/   28]\n",
      "loss: 0.673458  [    0/   28]\n",
      "loss: 0.671821  [    0/   28]\n",
      "loss: 0.670244  [    0/   28]\n",
      "loss: 0.668723  [    0/   28]\n",
      "loss: 0.667257  [    0/   28]\n",
      "loss: 0.665844  [    0/   28]\n",
      "loss: 0.664482  [    0/   28]\n",
      "loss: 0.663167  [    0/   28]\n",
      "loss: 0.661900  [    0/   28]\n",
      "loss: 0.660677  [    0/   28]\n",
      "loss: 0.659497  [    0/   28]\n",
      "loss: 0.658359  [    0/   28]\n",
      "loss: 0.657260  [    0/   28]\n",
      "loss: 0.656199  [    0/   28]\n",
      "loss: 0.655174  [    0/   28]\n",
      "loss: 0.654185  [    0/   28]\n",
      "loss: 0.653229  [    0/   28]\n",
      "loss: 0.652306  [    0/   28]\n",
      "loss: 0.651414  [    0/   28]\n",
      "loss: 0.650551  [    0/   28]\n",
      "loss: 0.649717  [    0/   28]\n",
      "loss: 0.648911  [    0/   28]\n",
      "loss: 0.648132  [    0/   28]\n",
      "loss: 0.647377  [    0/   28]\n",
      "loss: 0.646648  [    0/   28]\n",
      "loss: 0.645941  [    0/   28]\n",
      "loss: 0.645258  [    0/   28]\n",
      "loss: 0.644596  [    0/   28]\n",
      "loss: 0.643955  [    0/   28]\n",
      "loss: 0.643333  [    0/   28]\n",
      "loss: 0.642731  [    0/   28]\n",
      "loss: 0.642148  [    0/   28]\n",
      "loss: 0.641582  [    0/   28]\n",
      "loss: 0.641034  [    0/   28]\n",
      "loss: 0.640502  [    0/   28]\n",
      "loss: 0.639986  [    0/   28]\n",
      "loss: 0.639484  [    0/   28]\n",
      "loss: 0.638998  [    0/   28]\n",
      "loss: 0.638525  [    0/   28]\n",
      "loss: 0.638067  [    0/   28]\n",
      "loss: 0.637621  [    0/   28]\n",
      "loss: 0.637187  [    0/   28]\n",
      "loss: 0.636766  [    0/   28]\n",
      "loss: 0.636356  [    0/   28]\n",
      "loss: 0.635957  [    0/   28]\n",
      "loss: 0.635569  [    0/   28]\n",
      "loss: 0.635191  [    0/   28]\n",
      "loss: 0.634823  [    0/   28]\n",
      "loss: 0.634465  [    0/   28]\n",
      "loss: 0.634115  [    0/   28]\n",
      "loss: 0.633775  [    0/   28]\n",
      "loss: 0.633443  [    0/   28]\n",
      "loss: 0.633119  [    0/   28]\n",
      "loss: 0.632803  [    0/   28]\n",
      "loss: 0.632495  [    0/   28]\n",
      "loss: 0.632193  [    0/   28]\n",
      "loss: 0.631899  [    0/   28]\n",
      "loss: 0.631612  [    0/   28]\n",
      "loss: 0.631331  [    0/   28]\n",
      "loss: 0.631056  [    0/   28]\n",
      "loss: 0.630787  [    0/   28]\n",
      "loss: 0.630524  [    0/   28]\n",
      "loss: 0.630267  [    0/   28]\n",
      "loss: 0.630015  [    0/   28]\n",
      "loss: 0.629768  [    0/   28]\n",
      "loss: 0.629526  [    0/   28]\n",
      "loss: 0.629289  [    0/   28]\n",
      "loss: 0.629056  [    0/   28]\n",
      "loss: 0.628828  [    0/   28]\n",
      "loss: 0.628604  [    0/   28]\n",
      "loss: 0.628385  [    0/   28]\n",
      "loss: 0.628169  [    0/   28]\n",
      "loss: 0.627957  [    0/   28]\n",
      "loss: 0.627748  [    0/   28]\n",
      "loss: 0.627544  [    0/   28]\n",
      "loss: 0.627342  [    0/   28]\n",
      "loss: 0.627144  [    0/   28]\n",
      "loss: 0.626949  [    0/   28]\n",
      "loss: 0.626757  [    0/   28]\n",
      "loss: 0.626568  [    0/   28]\n",
      "loss: 0.626382  [    0/   28]\n",
      "loss: 0.626198  [    0/   28]\n",
      "loss: 0.626018  [    0/   28]\n",
      "loss: 0.625839  [    0/   28]\n",
      "loss: 0.625663  [    0/   28]\n",
      "loss: 0.625490  [    0/   28]\n",
      "loss: 0.625319  [    0/   28]\n",
      "loss: 0.625150  [    0/   28]\n",
      "loss: 0.624983  [    0/   28]\n",
      "loss: 0.624818  [    0/   28]\n",
      "loss: 0.624655  [    0/   28]\n",
      "loss: 0.624494  [    0/   28]\n",
      "loss: 0.624334  [    0/   28]\n",
      "loss: 0.624177  [    0/   28]\n",
      "loss: 0.624021  [    0/   28]\n",
      "loss: 0.623867  [    0/   28]\n",
      "loss: 0.623714  [    0/   28]\n",
      "loss: 0.623563  [    0/   28]\n",
      "loss: 0.623414  [    0/   28]\n",
      "loss: 0.623265  [    0/   28]\n",
      "loss: 0.623118  [    0/   28]\n",
      "loss: 0.622973  [    0/   28]\n",
      "loss: 0.622828  [    0/   28]\n",
      "loss: 0.622685  [    0/   28]\n",
      "loss: 0.622544  [    0/   28]\n",
      "loss: 0.622403  [    0/   28]\n",
      "loss: 0.622263  [    0/   28]\n",
      "loss: 0.622124  [    0/   28]\n",
      "loss: 0.621987  [    0/   28]\n",
      "loss: 0.621850  [    0/   28]\n",
      "loss: 0.621715  [    0/   28]\n",
      "loss: 0.621580  [    0/   28]\n",
      "loss: 0.621446  [    0/   28]\n",
      "loss: 0.621313  [    0/   28]\n",
      "loss: 0.621181  [    0/   28]\n",
      "loss: 0.621049  [    0/   28]\n",
      "loss: 0.620918  [    0/   28]\n",
      "loss: 0.620789  [    0/   28]\n",
      "loss: 0.620659  [    0/   28]\n",
      "loss: 0.620531  [    0/   28]\n",
      "loss: 0.620403  [    0/   28]\n",
      "loss: 0.620276  [    0/   28]\n",
      "loss: 0.620149  [    0/   28]\n",
      "loss: 0.620023  [    0/   28]\n",
      "loss: 0.619898  [    0/   28]\n",
      "loss: 0.619773  [    0/   28]\n",
      "loss: 0.619649  [    0/   28]\n",
      "loss: 0.619525  [    0/   28]\n",
      "loss: 0.619402  [    0/   28]\n",
      "loss: 0.619279  [    0/   28]\n",
      "loss: 0.619157  [    0/   28]\n",
      "loss: 0.619035  [    0/   28]\n",
      "loss: 0.618914  [    0/   28]\n",
      "loss: 0.618792  [    0/   28]\n",
      "loss: 0.618672  [    0/   28]\n",
      "loss: 0.618552  [    0/   28]\n",
      "loss: 0.618432  [    0/   28]\n",
      "loss: 0.618313  [    0/   28]\n",
      "loss: 0.618194  [    0/   28]\n",
      "loss: 0.618075  [    0/   28]\n",
      "loss: 0.617956  [    0/   28]\n",
      "loss: 0.617838  [    0/   28]\n",
      "loss: 0.617721  [    0/   28]\n",
      "loss: 0.617603  [    0/   28]\n",
      "loss: 0.617486  [    0/   28]\n",
      "loss: 0.617370  [    0/   28]\n",
      "loss: 0.617253  [    0/   28]\n",
      "loss: 0.617137  [    0/   28]\n",
      "loss: 0.617021  [    0/   28]\n",
      "loss: 0.616905  [    0/   28]\n",
      "loss: 0.616790  [    0/   28]\n",
      "loss: 0.616674  [    0/   28]\n",
      "loss: 0.616560  [    0/   28]\n",
      "loss: 0.616445  [    0/   28]\n",
      "loss: 0.616330  [    0/   28]\n",
      "loss: 0.616216  [    0/   28]\n",
      "loss: 0.616102  [    0/   28]\n",
      "loss: 0.615988  [    0/   28]\n",
      "loss: 0.615874  [    0/   28]\n",
      "loss: 0.615760  [    0/   28]\n",
      "loss: 0.615647  [    0/   28]\n",
      "loss: 0.615534  [    0/   28]\n",
      "loss: 0.615421  [    0/   28]\n",
      "loss: 0.615308  [    0/   28]\n",
      "loss: 0.615195  [    0/   28]\n",
      "loss: 0.615082  [    0/   28]\n",
      "loss: 0.614970  [    0/   28]\n",
      "loss: 0.614858  [    0/   28]\n",
      "loss: 0.614745  [    0/   28]\n",
      "loss: 0.614633  [    0/   28]\n",
      "loss: 0.614521  [    0/   28]\n",
      "loss: 0.614410  [    0/   28]\n",
      "loss: 0.614298  [    0/   28]\n",
      "loss: 0.614186  [    0/   28]\n",
      "loss: 0.614075  [    0/   28]\n",
      "loss: 0.613964  [    0/   28]\n",
      "loss: 0.613852  [    0/   28]\n",
      "loss: 0.613741  [    0/   28]\n",
      "loss: 0.613630  [    0/   28]\n",
      "loss: 0.613519  [    0/   28]\n",
      "loss: 0.613409  [    0/   28]\n",
      "loss: 0.613298  [    0/   28]\n",
      "loss: 0.613187  [    0/   28]\n",
      "loss: 0.613077  [    0/   28]\n",
      "loss: 0.612967  [    0/   28]\n",
      "loss: 0.612856  [    0/   28]\n",
      "loss: 0.612746  [    0/   28]\n",
      "loss: 0.612636  [    0/   28]\n",
      "loss: 0.612526  [    0/   28]\n",
      "loss: 0.612416  [    0/   28]\n",
      "loss: 0.612306  [    0/   28]\n",
      "loss: 0.612196  [    0/   28]\n",
      "loss: 0.612086  [    0/   28]\n",
      "loss: 0.611976  [    0/   28]\n",
      "loss: 0.611866  [    0/   28]\n",
      "loss: 0.611757  [    0/   28]\n",
      "loss: 0.611647  [    0/   28]\n",
      "loss: 0.611538  [    0/   28]\n",
      "loss: 0.611428  [    0/   28]\n",
      "loss: 0.611319  [    0/   28]\n",
      "loss: 0.611210  [    0/   28]\n",
      "loss: 0.611100  [    0/   28]\n",
      "loss: 0.610991  [    0/   28]\n",
      "loss: 0.610882  [    0/   28]\n",
      "loss: 0.610773  [    0/   28]\n",
      "loss: 0.610664  [    0/   28]\n",
      "loss: 0.610555  [    0/   28]\n",
      "loss: 0.610446  [    0/   28]\n",
      "loss: 0.610337  [    0/   28]\n",
      "loss: 0.610228  [    0/   28]\n",
      "loss: 0.610119  [    0/   28]\n",
      "loss: 0.610010  [    0/   28]\n",
      "loss: 0.609901  [    0/   28]\n",
      "loss: 0.609793  [    0/   28]\n",
      "loss: 0.609684  [    0/   28]\n",
      "loss: 0.609575  [    0/   28]\n",
      "loss: 0.609467  [    0/   28]\n",
      "loss: 0.609358  [    0/   28]\n",
      "loss: 0.609249  [    0/   28]\n",
      "loss: 0.609141  [    0/   28]\n",
      "loss: 0.609033  [    0/   28]\n",
      "loss: 0.608924  [    0/   28]\n",
      "loss: 0.608816  [    0/   28]\n",
      "loss: 0.608707  [    0/   28]\n",
      "loss: 0.608599  [    0/   28]\n",
      "loss: 0.608491  [    0/   28]\n",
      "loss: 0.608382  [    0/   28]\n",
      "loss: 0.608274  [    0/   28]\n",
      "loss: 0.608166  [    0/   28]\n",
      "loss: 0.608058  [    0/   28]\n",
      "loss: 0.607950  [    0/   28]\n",
      "loss: 0.607841  [    0/   28]\n",
      "loss: 0.607733  [    0/   28]\n",
      "loss: 0.607625  [    0/   28]\n",
      "loss: 0.607517  [    0/   28]\n",
      "loss: 0.607409  [    0/   28]\n",
      "loss: 0.607301  [    0/   28]\n",
      "loss: 0.607193  [    0/   28]\n",
      "loss: 0.607085  [    0/   28]\n",
      "loss: 0.606977  [    0/   28]\n",
      "loss: 0.606869  [    0/   28]\n",
      "loss: 0.606761  [    0/   28]\n",
      "loss: 0.606654  [    0/   28]\n",
      "loss: 0.606546  [    0/   28]\n",
      "loss: 0.606438  [    0/   28]\n",
      "loss: 0.606330  [    0/   28]\n",
      "loss: 0.606222  [    0/   28]\n",
      "loss: 0.606114  [    0/   28]\n",
      "loss: 0.606007  [    0/   28]\n",
      "loss: 0.605899  [    0/   28]\n",
      "loss: 0.605791  [    0/   28]\n",
      "loss: 0.605684  [    0/   28]\n",
      "loss: 0.605576  [    0/   28]\n",
      "loss: 0.605468  [    0/   28]\n",
      "loss: 0.605361  [    0/   28]\n",
      "loss: 0.605253  [    0/   28]\n",
      "loss: 0.605145  [    0/   28]\n",
      "loss: 0.605038  [    0/   28]\n",
      "loss: 0.604930  [    0/   28]\n",
      "loss: 0.604823  [    0/   28]\n",
      "loss: 0.604715  [    0/   28]\n",
      "loss: 0.604608  [    0/   28]\n",
      "loss: 0.604500  [    0/   28]\n",
      "loss: 0.604392  [    0/   28]\n",
      "loss: 0.604285  [    0/   28]\n",
      "loss: 0.604178  [    0/   28]\n",
      "loss: 0.604070  [    0/   28]\n",
      "loss: 0.603963  [    0/   28]\n",
      "loss: 0.603856  [    0/   28]\n",
      "loss: 0.603748  [    0/   28]\n",
      "loss: 0.603641  [    0/   28]\n",
      "loss: 0.603534  [    0/   28]\n",
      "loss: 0.603426  [    0/   28]\n",
      "loss: 0.603319  [    0/   28]\n",
      "loss: 0.603212  [    0/   28]\n",
      "loss: 0.603105  [    0/   28]\n",
      "loss: 0.602997  [    0/   28]\n",
      "loss: 0.602890  [    0/   28]\n",
      "loss: 0.602783  [    0/   28]\n",
      "loss: 0.602676  [    0/   28]\n",
      "loss: 0.602569  [    0/   28]\n",
      "loss: 0.602461  [    0/   28]\n",
      "loss: 0.602354  [    0/   28]\n",
      "loss: 0.602247  [    0/   28]\n",
      "loss: 0.602140  [    0/   28]\n",
      "loss: 0.602033  [    0/   28]\n",
      "loss: 0.601925  [    0/   28]\n",
      "loss: 0.601818  [    0/   28]\n",
      "loss: 0.601711  [    0/   28]\n",
      "loss: 0.601604  [    0/   28]\n",
      "loss: 0.601497  [    0/   28]\n",
      "loss: 0.601390  [    0/   28]\n",
      "loss: 0.601283  [    0/   28]\n",
      "loss: 0.601176  [    0/   28]\n",
      "loss: 0.601069  [    0/   28]\n",
      "loss: 0.600962  [    0/   28]\n",
      "loss: 0.600855  [    0/   28]\n",
      "loss: 0.600748  [    0/   28]\n",
      "loss: 0.600641  [    0/   28]\n",
      "loss: 0.600534  [    0/   28]\n",
      "loss: 0.600427  [    0/   28]\n",
      "loss: 0.600320  [    0/   28]\n",
      "loss: 0.600213  [    0/   28]\n",
      "loss: 0.600106  [    0/   28]\n",
      "loss: 0.600000  [    0/   28]\n",
      "loss: 0.599893  [    0/   28]\n",
      "loss: 0.599786  [    0/   28]\n",
      "loss: 0.599679  [    0/   28]\n",
      "loss: 0.599572  [    0/   28]\n",
      "loss: 0.599465  [    0/   28]\n",
      "loss: 0.599358  [    0/   28]\n",
      "loss: 0.599251  [    0/   28]\n",
      "loss: 0.599145  [    0/   28]\n",
      "loss: 0.599038  [    0/   28]\n",
      "loss: 0.598931  [    0/   28]\n",
      "loss: 0.598824  [    0/   28]\n",
      "loss: 0.598717  [    0/   28]\n",
      "loss: 0.598610  [    0/   28]\n",
      "loss: 0.598503  [    0/   28]\n",
      "loss: 0.598396  [    0/   28]\n",
      "loss: 0.598290  [    0/   28]\n",
      "loss: 0.598183  [    0/   28]\n",
      "loss: 0.598076  [    0/   28]\n",
      "loss: 0.597969  [    0/   28]\n",
      "loss: 0.597862  [    0/   28]\n",
      "loss: 0.597755  [    0/   28]\n",
      "loss: 0.597649  [    0/   28]\n",
      "loss: 0.597542  [    0/   28]\n",
      "loss: 0.597435  [    0/   28]\n",
      "loss: 0.597328  [    0/   28]\n",
      "loss: 0.597221  [    0/   28]\n",
      "loss: 0.597114  [    0/   28]\n",
      "loss: 0.597008  [    0/   28]\n",
      "loss: 0.596901  [    0/   28]\n",
      "loss: 0.596794  [    0/   28]\n",
      "loss: 0.596687  [    0/   28]\n",
      "loss: 0.596580  [    0/   28]\n",
      "loss: 0.596474  [    0/   28]\n",
      "loss: 0.596367  [    0/   28]\n",
      "loss: 0.596260  [    0/   28]\n",
      "loss: 0.596153  [    0/   28]\n",
      "loss: 0.596046  [    0/   28]\n",
      "loss: 0.595940  [    0/   28]\n",
      "loss: 0.595833  [    0/   28]\n",
      "loss: 0.595726  [    0/   28]\n",
      "loss: 0.595619  [    0/   28]\n",
      "loss: 0.595513  [    0/   28]\n",
      "loss: 0.595406  [    0/   28]\n",
      "loss: 0.595299  [    0/   28]\n",
      "loss: 0.595192  [    0/   28]\n",
      "loss: 0.595086  [    0/   28]\n",
      "loss: 0.594979  [    0/   28]\n",
      "loss: 0.594873  [    0/   28]\n",
      "loss: 0.594766  [    0/   28]\n",
      "loss: 0.594659  [    0/   28]\n",
      "loss: 0.594552  [    0/   28]\n",
      "loss: 0.594446  [    0/   28]\n",
      "loss: 0.594339  [    0/   28]\n",
      "loss: 0.594232  [    0/   28]\n",
      "loss: 0.594126  [    0/   28]\n",
      "loss: 0.594019  [    0/   28]\n",
      "loss: 0.593912  [    0/   28]\n",
      "loss: 0.593806  [    0/   28]\n",
      "loss: 0.593699  [    0/   28]\n",
      "loss: 0.593592  [    0/   28]\n",
      "loss: 0.593486  [    0/   28]\n",
      "loss: 0.593379  [    0/   28]\n",
      "loss: 0.593272  [    0/   28]\n",
      "loss: 0.593166  [    0/   28]\n",
      "loss: 0.593059  [    0/   28]\n",
      "loss: 0.592952  [    0/   28]\n",
      "loss: 0.592845  [    0/   28]\n",
      "loss: 0.592739  [    0/   28]\n",
      "loss: 0.592632  [    0/   28]\n",
      "loss: 0.592525  [    0/   28]\n",
      "loss: 0.592419  [    0/   28]\n",
      "loss: 0.592312  [    0/   28]\n",
      "loss: 0.592205  [    0/   28]\n",
      "loss: 0.592099  [    0/   28]\n",
      "loss: 0.591992  [    0/   28]\n",
      "loss: 0.591885  [    0/   28]\n",
      "loss: 0.591779  [    0/   28]\n",
      "loss: 0.591672  [    0/   28]\n",
      "loss: 0.591565  [    0/   28]\n",
      "loss: 0.591459  [    0/   28]\n",
      "loss: 0.591352  [    0/   28]\n",
      "loss: 0.591245  [    0/   28]\n",
      "loss: 0.591139  [    0/   28]\n",
      "loss: 0.591032  [    0/   28]\n",
      "loss: 0.590925  [    0/   28]\n",
      "loss: 0.590819  [    0/   28]\n",
      "loss: 0.590712  [    0/   28]\n",
      "loss: 0.590605  [    0/   28]\n",
      "loss: 0.590498  [    0/   28]\n",
      "loss: 0.590392  [    0/   28]\n",
      "loss: 0.590286  [    0/   28]\n",
      "loss: 0.590179  [    0/   28]\n",
      "loss: 0.590073  [    0/   28]\n",
      "loss: 0.589967  [    0/   28]\n",
      "loss: 0.589861  [    0/   28]\n",
      "loss: 0.589755  [    0/   28]\n",
      "loss: 0.589648  [    0/   28]\n",
      "loss: 0.589542  [    0/   28]\n",
      "loss: 0.589436  [    0/   28]\n",
      "loss: 0.589330  [    0/   28]\n",
      "loss: 0.589223  [    0/   28]\n",
      "loss: 0.589117  [    0/   28]\n",
      "loss: 0.589011  [    0/   28]\n",
      "loss: 0.588905  [    0/   28]\n",
      "loss: 0.588798  [    0/   28]\n",
      "loss: 0.588692  [    0/   28]\n",
      "loss: 0.588586  [    0/   28]\n",
      "loss: 0.588480  [    0/   28]\n",
      "loss: 0.588374  [    0/   28]\n",
      "loss: 0.588267  [    0/   28]\n",
      "loss: 0.588161  [    0/   28]\n",
      "loss: 0.588055  [    0/   28]\n",
      "loss: 0.587949  [    0/   28]\n",
      "loss: 0.587843  [    0/   28]\n",
      "loss: 0.587736  [    0/   28]\n",
      "loss: 0.587630  [    0/   28]\n",
      "loss: 0.587524  [    0/   28]\n",
      "loss: 0.587418  [    0/   28]\n",
      "loss: 0.587311  [    0/   28]\n",
      "loss: 0.587205  [    0/   28]\n",
      "loss: 0.587099  [    0/   28]\n",
      "loss: 0.586993  [    0/   28]\n",
      "loss: 0.586886  [    0/   28]\n",
      "loss: 0.586780  [    0/   28]\n",
      "loss: 0.586674  [    0/   28]\n",
      "loss: 0.586568  [    0/   28]\n",
      "loss: 0.586461  [    0/   28]\n",
      "loss: 0.586355  [    0/   28]\n",
      "loss: 0.586249  [    0/   28]\n",
      "loss: 0.586143  [    0/   28]\n",
      "loss: 0.586036  [    0/   28]\n",
      "loss: 0.585930  [    0/   28]\n",
      "loss: 0.585824  [    0/   28]\n",
      "loss: 0.585717  [    0/   28]\n",
      "loss: 0.585611  [    0/   28]\n",
      "loss: 0.585505  [    0/   28]\n",
      "loss: 0.585398  [    0/   28]\n",
      "loss: 0.585292  [    0/   28]\n",
      "loss: 0.585186  [    0/   28]\n",
      "loss: 0.585079  [    0/   28]\n",
      "loss: 0.584973  [    0/   28]\n",
      "loss: 0.584866  [    0/   28]\n",
      "loss: 0.584760  [    0/   28]\n",
      "loss: 0.584654  [    0/   28]\n",
      "loss: 0.584547  [    0/   28]\n",
      "loss: 0.584441  [    0/   28]\n",
      "loss: 0.584335  [    0/   28]\n",
      "loss: 0.584228  [    0/   28]\n",
      "loss: 0.584122  [    0/   28]\n",
      "loss: 0.584015  [    0/   28]\n",
      "loss: 0.583909  [    0/   28]\n",
      "loss: 0.583803  [    0/   28]\n",
      "loss: 0.583696  [    0/   28]\n",
      "loss: 0.583590  [    0/   28]\n",
      "loss: 0.583483  [    0/   28]\n",
      "loss: 0.583377  [    0/   28]\n",
      "loss: 0.583270  [    0/   28]\n",
      "loss: 0.583164  [    0/   28]\n",
      "loss: 0.583057  [    0/   28]\n",
      "loss: 0.582951  [    0/   28]\n",
      "loss: 0.582844  [    0/   28]\n",
      "loss: 0.582738  [    0/   28]\n",
      "loss: 0.582631  [    0/   28]\n",
      "loss: 0.582524  [    0/   28]\n",
      "loss: 0.582418  [    0/   28]\n",
      "loss: 0.582311  [    0/   28]\n",
      "loss: 0.582205  [    0/   28]\n",
      "loss: 0.582098  [    0/   28]\n",
      "loss: 0.581991  [    0/   28]\n",
      "loss: 0.581885  [    0/   28]\n",
      "loss: 0.581778  [    0/   28]\n",
      "loss: 0.581672  [    0/   28]\n",
      "loss: 0.581565  [    0/   28]\n",
      "loss: 0.581458  [    0/   28]\n",
      "loss: 0.581352  [    0/   28]\n",
      "loss: 0.581245  [    0/   28]\n",
      "loss: 0.581138  [    0/   28]\n",
      "loss: 0.581032  [    0/   28]\n",
      "loss: 0.580925  [    0/   28]\n",
      "loss: 0.580818  [    0/   28]\n",
      "loss: 0.580712  [    0/   28]\n",
      "loss: 0.580605  [    0/   28]\n",
      "loss: 0.580498  [    0/   28]\n",
      "loss: 0.580392  [    0/   28]\n",
      "loss: 0.580285  [    0/   28]\n",
      "loss: 0.580178  [    0/   28]\n",
      "loss: 0.580071  [    0/   28]\n",
      "loss: 0.579965  [    0/   28]\n",
      "loss: 0.579858  [    0/   28]\n",
      "loss: 0.579751  [    0/   28]\n",
      "loss: 0.579644  [    0/   28]\n",
      "loss: 0.579537  [    0/   28]\n",
      "loss: 0.579431  [    0/   28]\n",
      "loss: 0.579324  [    0/   28]\n",
      "loss: 0.579217  [    0/   28]\n",
      "loss: 0.579110  [    0/   28]\n",
      "loss: 0.579003  [    0/   28]\n",
      "loss: 0.578896  [    0/   28]\n",
      "loss: 0.578789  [    0/   28]\n",
      "loss: 0.578682  [    0/   28]\n",
      "loss: 0.578575  [    0/   28]\n",
      "loss: 0.578468  [    0/   28]\n",
      "loss: 0.578361  [    0/   28]\n",
      "loss: 0.578254  [    0/   28]\n",
      "loss: 0.578147  [    0/   28]\n",
      "loss: 0.578040  [    0/   28]\n",
      "loss: 0.577933  [    0/   28]\n",
      "loss: 0.577826  [    0/   28]\n",
      "loss: 0.577719  [    0/   28]\n",
      "loss: 0.577612  [    0/   28]\n",
      "loss: 0.577505  [    0/   28]\n",
      "loss: 0.577398  [    0/   28]\n",
      "loss: 0.577291  [    0/   28]\n",
      "loss: 0.577184  [    0/   28]\n",
      "loss: 0.577077  [    0/   28]\n",
      "loss: 0.576970  [    0/   28]\n",
      "loss: 0.576863  [    0/   28]\n",
      "loss: 0.576756  [    0/   28]\n",
      "loss: 0.576648  [    0/   28]\n",
      "loss: 0.576541  [    0/   28]\n",
      "loss: 0.576434  [    0/   28]\n",
      "loss: 0.576327  [    0/   28]\n",
      "loss: 0.576220  [    0/   28]\n",
      "loss: 0.576112  [    0/   28]\n",
      "loss: 0.576005  [    0/   28]\n",
      "loss: 0.575898  [    0/   28]\n",
      "loss: 0.575791  [    0/   28]\n",
      "loss: 0.575683  [    0/   28]\n",
      "loss: 0.575576  [    0/   28]\n",
      "loss: 0.575469  [    0/   28]\n",
      "loss: 0.575361  [    0/   28]\n",
      "loss: 0.575254  [    0/   28]\n",
      "loss: 0.575147  [    0/   28]\n",
      "loss: 0.575039  [    0/   28]\n",
      "loss: 0.574932  [    0/   28]\n",
      "loss: 0.574825  [    0/   28]\n",
      "loss: 0.574717  [    0/   28]\n",
      "loss: 0.574610  [    0/   28]\n",
      "loss: 0.574502  [    0/   28]\n",
      "loss: 0.574395  [    0/   28]\n",
      "loss: 0.574287  [    0/   28]\n",
      "loss: 0.574180  [    0/   28]\n",
      "loss: 0.574072  [    0/   28]\n",
      "loss: 0.573965  [    0/   28]\n",
      "loss: 0.573857  [    0/   28]\n",
      "loss: 0.573750  [    0/   28]\n",
      "loss: 0.573642  [    0/   28]\n",
      "loss: 0.573535  [    0/   28]\n",
      "loss: 0.573427  [    0/   28]\n",
      "loss: 0.573319  [    0/   28]\n",
      "loss: 0.573212  [    0/   28]\n",
      "loss: 0.573104  [    0/   28]\n",
      "loss: 0.572996  [    0/   28]\n",
      "loss: 0.572889  [    0/   28]\n",
      "loss: 0.572781  [    0/   28]\n",
      "loss: 0.572673  [    0/   28]\n",
      "loss: 0.572566  [    0/   28]\n",
      "loss: 0.572458  [    0/   28]\n",
      "loss: 0.572350  [    0/   28]\n",
      "loss: 0.572242  [    0/   28]\n",
      "loss: 0.572134  [    0/   28]\n",
      "loss: 0.572027  [    0/   28]\n",
      "loss: 0.571919  [    0/   28]\n",
      "loss: 0.571811  [    0/   28]\n",
      "loss: 0.571703  [    0/   28]\n",
      "loss: 0.571595  [    0/   28]\n",
      "loss: 0.571487  [    0/   28]\n",
      "loss: 0.571379  [    0/   28]\n",
      "loss: 0.571272  [    0/   28]\n",
      "loss: 0.571164  [    0/   28]\n",
      "loss: 0.571056  [    0/   28]\n",
      "loss: 0.570948  [    0/   28]\n",
      "loss: 0.570840  [    0/   28]\n",
      "loss: 0.570732  [    0/   28]\n",
      "loss: 0.570624  [    0/   28]\n",
      "loss: 0.570516  [    0/   28]\n",
      "loss: 0.570408  [    0/   28]\n",
      "loss: 0.570300  [    0/   28]\n",
      "loss: 0.570192  [    0/   28]\n",
      "loss: 0.570084  [    0/   28]\n",
      "loss: 0.569976  [    0/   28]\n",
      "loss: 0.569869  [    0/   28]\n",
      "loss: 0.569760  [    0/   28]\n",
      "loss: 0.569653  [    0/   28]\n",
      "loss: 0.569545  [    0/   28]\n",
      "loss: 0.569437  [    0/   28]\n",
      "loss: 0.569329  [    0/   28]\n",
      "loss: 0.569221  [    0/   28]\n",
      "loss: 0.569113  [    0/   28]\n",
      "loss: 0.569005  [    0/   28]\n",
      "loss: 0.568896  [    0/   28]\n",
      "loss: 0.568788  [    0/   28]\n",
      "loss: 0.568680  [    0/   28]\n",
      "loss: 0.568572  [    0/   28]\n",
      "loss: 0.568464  [    0/   28]\n",
      "loss: 0.568356  [    0/   28]\n",
      "loss: 0.568248  [    0/   28]\n",
      "loss: 0.568140  [    0/   28]\n",
      "loss: 0.568031  [    0/   28]\n",
      "loss: 0.567923  [    0/   28]\n",
      "loss: 0.567815  [    0/   28]\n",
      "loss: 0.567707  [    0/   28]\n",
      "loss: 0.567598  [    0/   28]\n",
      "loss: 0.567490  [    0/   28]\n",
      "loss: 0.567382  [    0/   28]\n",
      "loss: 0.567273  [    0/   28]\n",
      "loss: 0.567165  [    0/   28]\n",
      "loss: 0.567056  [    0/   28]\n",
      "loss: 0.566948  [    0/   28]\n",
      "loss: 0.566839  [    0/   28]\n",
      "loss: 0.566731  [    0/   28]\n",
      "loss: 0.566623  [    0/   28]\n",
      "loss: 0.566514  [    0/   28]\n",
      "loss: 0.566406  [    0/   28]\n",
      "loss: 0.566297  [    0/   28]\n",
      "loss: 0.566189  [    0/   28]\n",
      "loss: 0.566080  [    0/   28]\n",
      "loss: 0.565971  [    0/   28]\n",
      "loss: 0.565863  [    0/   28]\n",
      "loss: 0.565754  [    0/   28]\n",
      "loss: 0.565646  [    0/   28]\n",
      "loss: 0.565537  [    0/   28]\n",
      "loss: 0.565428  [    0/   28]\n",
      "loss: 0.565319  [    0/   28]\n",
      "loss: 0.565211  [    0/   28]\n",
      "loss: 0.565102  [    0/   28]\n",
      "loss: 0.564993  [    0/   28]\n",
      "loss: 0.564885  [    0/   28]\n",
      "loss: 0.564776  [    0/   28]\n",
      "loss: 0.564667  [    0/   28]\n",
      "loss: 0.564558  [    0/   28]\n",
      "loss: 0.564449  [    0/   28]\n",
      "loss: 0.564340  [    0/   28]\n",
      "loss: 0.564232  [    0/   28]\n",
      "loss: 0.564123  [    0/   28]\n",
      "loss: 0.564014  [    0/   28]\n",
      "loss: 0.563905  [    0/   28]\n",
      "loss: 0.563796  [    0/   28]\n",
      "loss: 0.563687  [    0/   28]\n",
      "loss: 0.563578  [    0/   28]\n",
      "loss: 0.563468  [    0/   28]\n",
      "loss: 0.563359  [    0/   28]\n",
      "loss: 0.563250  [    0/   28]\n",
      "loss: 0.563141  [    0/   28]\n",
      "loss: 0.563032  [    0/   28]\n",
      "loss: 0.562923  [    0/   28]\n",
      "loss: 0.562814  [    0/   28]\n",
      "loss: 0.562704  [    0/   28]\n",
      "loss: 0.562595  [    0/   28]\n",
      "loss: 0.562486  [    0/   28]\n",
      "loss: 0.562377  [    0/   28]\n",
      "loss: 0.562267  [    0/   28]\n",
      "loss: 0.562158  [    0/   28]\n",
      "loss: 0.562049  [    0/   28]\n",
      "loss: 0.561939  [    0/   28]\n",
      "loss: 0.561830  [    0/   28]\n",
      "loss: 0.561721  [    0/   28]\n",
      "loss: 0.561611  [    0/   28]\n",
      "loss: 0.561502  [    0/   28]\n",
      "loss: 0.561392  [    0/   28]\n",
      "loss: 0.561283  [    0/   28]\n",
      "loss: 0.561173  [    0/   28]\n",
      "loss: 0.561064  [    0/   28]\n",
      "loss: 0.560954  [    0/   28]\n",
      "loss: 0.560845  [    0/   28]\n",
      "loss: 0.560735  [    0/   28]\n",
      "loss: 0.560626  [    0/   28]\n",
      "loss: 0.560516  [    0/   28]\n",
      "loss: 0.560406  [    0/   28]\n",
      "loss: 0.560297  [    0/   28]\n",
      "loss: 0.560187  [    0/   28]\n",
      "loss: 0.560077  [    0/   28]\n",
      "loss: 0.559968  [    0/   28]\n",
      "loss: 0.559858  [    0/   28]\n",
      "loss: 0.559748  [    0/   28]\n",
      "loss: 0.559638  [    0/   28]\n",
      "loss: 0.559528  [    0/   28]\n",
      "loss: 0.559418  [    0/   28]\n",
      "loss: 0.559309  [    0/   28]\n",
      "loss: 0.559199  [    0/   28]\n",
      "loss: 0.559089  [    0/   28]\n",
      "loss: 0.558979  [    0/   28]\n",
      "loss: 0.558869  [    0/   28]\n",
      "loss: 0.558758  [    0/   28]\n",
      "loss: 0.558649  [    0/   28]\n",
      "loss: 0.558538  [    0/   28]\n",
      "loss: 0.558428  [    0/   28]\n",
      "loss: 0.558318  [    0/   28]\n",
      "loss: 0.558208  [    0/   28]\n",
      "loss: 0.558098  [    0/   28]\n",
      "loss: 0.557987  [    0/   28]\n",
      "loss: 0.557877  [    0/   28]\n",
      "loss: 0.557767  [    0/   28]\n",
      "loss: 0.557656  [    0/   28]\n",
      "loss: 0.557546  [    0/   28]\n",
      "loss: 0.557436  [    0/   28]\n",
      "loss: 0.557325  [    0/   28]\n",
      "loss: 0.557215  [    0/   28]\n",
      "loss: 0.557105  [    0/   28]\n",
      "loss: 0.556994  [    0/   28]\n",
      "loss: 0.556884  [    0/   28]\n",
      "loss: 0.556773  [    0/   28]\n",
      "loss: 0.556662  [    0/   28]\n",
      "loss: 0.556552  [    0/   28]\n",
      "loss: 0.556441  [    0/   28]\n",
      "loss: 0.556331  [    0/   28]\n",
      "loss: 0.556220  [    0/   28]\n",
      "loss: 0.556109  [    0/   28]\n",
      "loss: 0.555999  [    0/   28]\n",
      "loss: 0.555888  [    0/   28]\n",
      "loss: 0.555777  [    0/   28]\n",
      "loss: 0.555667  [    0/   28]\n",
      "loss: 0.555556  [    0/   28]\n",
      "loss: 0.555445  [    0/   28]\n",
      "loss: 0.555334  [    0/   28]\n",
      "loss: 0.555223  [    0/   28]\n",
      "loss: 0.555112  [    0/   28]\n",
      "loss: 0.555002  [    0/   28]\n",
      "loss: 0.554891  [    0/   28]\n",
      "loss: 0.554780  [    0/   28]\n",
      "loss: 0.554669  [    0/   28]\n",
      "loss: 0.554558  [    0/   28]\n",
      "loss: 0.554447  [    0/   28]\n",
      "loss: 0.554335  [    0/   28]\n",
      "loss: 0.554224  [    0/   28]\n",
      "loss: 0.554113  [    0/   28]\n",
      "loss: 0.554002  [    0/   28]\n",
      "loss: 0.553891  [    0/   28]\n",
      "loss: 0.553779  [    0/   28]\n",
      "loss: 0.553668  [    0/   28]\n",
      "loss: 0.553557  [    0/   28]\n",
      "loss: 0.553446  [    0/   28]\n",
      "loss: 0.553334  [    0/   28]\n",
      "loss: 0.553223  [    0/   28]\n",
      "loss: 0.553112  [    0/   28]\n",
      "loss: 0.553000  [    0/   28]\n",
      "loss: 0.552889  [    0/   28]\n",
      "loss: 0.552777  [    0/   28]\n",
      "loss: 0.552666  [    0/   28]\n",
      "loss: 0.552554  [    0/   28]\n",
      "loss: 0.552443  [    0/   28]\n",
      "loss: 0.552331  [    0/   28]\n",
      "loss: 0.552220  [    0/   28]\n",
      "loss: 0.552108  [    0/   28]\n",
      "loss: 0.551996  [    0/   28]\n",
      "loss: 0.551884  [    0/   28]\n",
      "loss: 0.551773  [    0/   28]\n",
      "loss: 0.551661  [    0/   28]\n",
      "loss: 0.551549  [    0/   28]\n",
      "loss: 0.551437  [    0/   28]\n",
      "loss: 0.551325  [    0/   28]\n",
      "loss: 0.551214  [    0/   28]\n",
      "loss: 0.551102  [    0/   28]\n",
      "loss: 0.550990  [    0/   28]\n",
      "loss: 0.550878  [    0/   28]\n",
      "loss: 0.550765  [    0/   28]\n",
      "loss: 0.550653  [    0/   28]\n",
      "loss: 0.550541  [    0/   28]\n",
      "loss: 0.550429  [    0/   28]\n",
      "loss: 0.550317  [    0/   28]\n",
      "loss: 0.550205  [    0/   28]\n",
      "loss: 0.550093  [    0/   28]\n",
      "loss: 0.549980  [    0/   28]\n",
      "loss: 0.549868  [    0/   28]\n",
      "loss: 0.549756  [    0/   28]\n",
      "loss: 0.549643  [    0/   28]\n",
      "loss: 0.549531  [    0/   28]\n",
      "loss: 0.549419  [    0/   28]\n",
      "loss: 0.549306  [    0/   28]\n",
      "loss: 0.549193  [    0/   28]\n",
      "loss: 0.549081  [    0/   28]\n",
      "loss: 0.548968  [    0/   28]\n",
      "loss: 0.548856  [    0/   28]\n",
      "loss: 0.548743  [    0/   28]\n",
      "loss: 0.548631  [    0/   28]\n",
      "loss: 0.548518  [    0/   28]\n",
      "loss: 0.548405  [    0/   28]\n",
      "loss: 0.548292  [    0/   28]\n",
      "loss: 0.548179  [    0/   28]\n",
      "loss: 0.548067  [    0/   28]\n",
      "loss: 0.547954  [    0/   28]\n",
      "loss: 0.547841  [    0/   28]\n",
      "loss: 0.547728  [    0/   28]\n",
      "loss: 0.547615  [    0/   28]\n",
      "loss: 0.547502  [    0/   28]\n",
      "loss: 0.547389  [    0/   28]\n",
      "loss: 0.547276  [    0/   28]\n",
      "loss: 0.547163  [    0/   28]\n",
      "loss: 0.547049  [    0/   28]\n",
      "loss: 0.546936  [    0/   28]\n",
      "loss: 0.546823  [    0/   28]\n",
      "loss: 0.546710  [    0/   28]\n",
      "loss: 0.546596  [    0/   28]\n",
      "loss: 0.546483  [    0/   28]\n",
      "loss: 0.546370  [    0/   28]\n",
      "loss: 0.546257  [    0/   28]\n",
      "loss: 0.546143  [    0/   28]\n",
      "loss: 0.546030  [    0/   28]\n",
      "loss: 0.545916  [    0/   28]\n",
      "loss: 0.545803  [    0/   28]\n",
      "loss: 0.545690  [    0/   28]\n",
      "loss: 0.545576  [    0/   28]\n",
      "loss: 0.545463  [    0/   28]\n",
      "loss: 0.545349  [    0/   28]\n",
      "loss: 0.545235  [    0/   28]\n",
      "loss: 0.545122  [    0/   28]\n",
      "loss: 0.545008  [    0/   28]\n",
      "loss: 0.544894  [    0/   28]\n",
      "loss: 0.544781  [    0/   28]\n",
      "loss: 0.544667  [    0/   28]\n",
      "loss: 0.544553  [    0/   28]\n",
      "loss: 0.544439  [    0/   28]\n",
      "loss: 0.544325  [    0/   28]\n",
      "loss: 0.544211  [    0/   28]\n",
      "loss: 0.544097  [    0/   28]\n",
      "loss: 0.543983  [    0/   28]\n",
      "loss: 0.543869  [    0/   28]\n",
      "loss: 0.543755  [    0/   28]\n",
      "loss: 0.543641  [    0/   28]\n",
      "loss: 0.543527  [    0/   28]\n",
      "loss: 0.543413  [    0/   28]\n",
      "loss: 0.543299  [    0/   28]\n",
      "loss: 0.543184  [    0/   28]\n",
      "loss: 0.543070  [    0/   28]\n",
      "loss: 0.542956  [    0/   28]\n",
      "loss: 0.542842  [    0/   28]\n",
      "loss: 0.542728  [    0/   28]\n",
      "loss: 0.542614  [    0/   28]\n",
      "loss: 0.542499  [    0/   28]\n",
      "loss: 0.542385  [    0/   28]\n",
      "loss: 0.542271  [    0/   28]\n",
      "loss: 0.542156  [    0/   28]\n",
      "loss: 0.542042  [    0/   28]\n",
      "loss: 0.541927  [    0/   28]\n",
      "loss: 0.541812  [    0/   28]\n",
      "loss: 0.541698  [    0/   28]\n",
      "loss: 0.541583  [    0/   28]\n",
      "loss: 0.541469  [    0/   28]\n",
      "loss: 0.541354  [    0/   28]\n",
      "loss: 0.541239  [    0/   28]\n",
      "loss: 0.541125  [    0/   28]\n",
      "loss: 0.541010  [    0/   28]\n",
      "loss: 0.540895  [    0/   28]\n",
      "loss: 0.540780  [    0/   28]\n",
      "loss: 0.540665  [    0/   28]\n",
      "loss: 0.540551  [    0/   28]\n",
      "loss: 0.540435  [    0/   28]\n",
      "loss: 0.540321  [    0/   28]\n",
      "loss: 0.540205  [    0/   28]\n",
      "loss: 0.540090  [    0/   28]\n",
      "loss: 0.539975  [    0/   28]\n",
      "loss: 0.539860  [    0/   28]\n",
      "loss: 0.539745  [    0/   28]\n",
      "loss: 0.539629  [    0/   28]\n",
      "loss: 0.539514  [    0/   28]\n",
      "loss: 0.539399  [    0/   28]\n",
      "loss: 0.539283  [    0/   28]\n",
      "loss: 0.539168  [    0/   28]\n",
      "loss: 0.539053  [    0/   28]\n",
      "loss: 0.538937  [    0/   28]\n",
      "loss: 0.538822  [    0/   28]\n",
      "loss: 0.538706  [    0/   28]\n",
      "loss: 0.538591  [    0/   28]\n",
      "loss: 0.538475  [    0/   28]\n",
      "loss: 0.538359  [    0/   28]\n",
      "loss: 0.538243  [    0/   28]\n",
      "loss: 0.538128  [    0/   28]\n",
      "loss: 0.538012  [    0/   28]\n",
      "loss: 0.537896  [    0/   28]\n",
      "loss: 0.537780  [    0/   28]\n",
      "loss: 0.537664  [    0/   28]\n",
      "loss: 0.537548  [    0/   28]\n",
      "loss: 0.537432  [    0/   28]\n",
      "loss: 0.537317  [    0/   28]\n",
      "loss: 0.537201  [    0/   28]\n",
      "loss: 0.537084  [    0/   28]\n",
      "loss: 0.536968  [    0/   28]\n",
      "loss: 0.536852  [    0/   28]\n",
      "loss: 0.536735  [    0/   28]\n",
      "loss: 0.536619  [    0/   28]\n",
      "loss: 0.536503  [    0/   28]\n",
      "loss: 0.536386  [    0/   28]\n",
      "loss: 0.536270  [    0/   28]\n",
      "loss: 0.536153  [    0/   28]\n",
      "loss: 0.536037  [    0/   28]\n",
      "loss: 0.535920  [    0/   28]\n",
      "loss: 0.535804  [    0/   28]\n",
      "loss: 0.535687  [    0/   28]\n",
      "loss: 0.535571  [    0/   28]\n",
      "loss: 0.535454  [    0/   28]\n",
      "loss: 0.535337  [    0/   28]\n",
      "loss: 0.535220  [    0/   28]\n",
      "loss: 0.535104  [    0/   28]\n",
      "loss: 0.534987  [    0/   28]\n",
      "loss: 0.534870  [    0/   28]\n",
      "loss: 0.534753  [    0/   28]\n",
      "loss: 0.534637  [    0/   28]\n",
      "loss: 0.534520  [    0/   28]\n",
      "loss: 0.534403  [    0/   28]\n",
      "loss: 0.534285  [    0/   28]\n",
      "loss: 0.534168  [    0/   28]\n",
      "loss: 0.534051  [    0/   28]\n",
      "loss: 0.533934  [    0/   28]\n",
      "loss: 0.533817  [    0/   28]\n",
      "loss: 0.533700  [    0/   28]\n",
      "loss: 0.533583  [    0/   28]\n",
      "loss: 0.533465  [    0/   28]\n",
      "loss: 0.533348  [    0/   28]\n",
      "loss: 0.533231  [    0/   28]\n",
      "loss: 0.533113  [    0/   28]\n",
      "loss: 0.532996  [    0/   28]\n",
      "loss: 0.532879  [    0/   28]\n",
      "loss: 0.532761  [    0/   28]\n",
      "loss: 0.532644  [    0/   28]\n",
      "loss: 0.532526  [    0/   28]\n",
      "loss: 0.532408  [    0/   28]\n",
      "loss: 0.532291  [    0/   28]\n",
      "loss: 0.532173  [    0/   28]\n",
      "loss: 0.532055  [    0/   28]\n",
      "loss: 0.531937  [    0/   28]\n",
      "loss: 0.531820  [    0/   28]\n",
      "loss: 0.531702  [    0/   28]\n",
      "loss: 0.531584  [    0/   28]\n",
      "loss: 0.531466  [    0/   28]\n",
      "loss: 0.531348  [    0/   28]\n",
      "loss: 0.531230  [    0/   28]\n",
      "loss: 0.531112  [    0/   28]\n",
      "loss: 0.530994  [    0/   28]\n",
      "loss: 0.530876  [    0/   28]\n",
      "loss: 0.530758  [    0/   28]\n",
      "loss: 0.530640  [    0/   28]\n",
      "loss: 0.530522  [    0/   28]\n",
      "loss: 0.530403  [    0/   28]\n",
      "loss: 0.530285  [    0/   28]\n",
      "loss: 0.530167  [    0/   28]\n",
      "loss: 0.530048  [    0/   28]\n",
      "loss: 0.529930  [    0/   28]\n",
      "loss: 0.529812  [    0/   28]\n",
      "loss: 0.529693  [    0/   28]\n",
      "loss: 0.529575  [    0/   28]\n",
      "loss: 0.529456  [    0/   28]\n",
      "loss: 0.529337  [    0/   28]\n",
      "loss: 0.529219  [    0/   28]\n",
      "loss: 0.529100  [    0/   28]\n",
      "loss: 0.528982  [    0/   28]\n",
      "loss: 0.528862  [    0/   28]\n",
      "loss: 0.528744  [    0/   28]\n",
      "loss: 0.528625  [    0/   28]\n",
      "loss: 0.528506  [    0/   28]\n",
      "loss: 0.528387  [    0/   28]\n",
      "loss: 0.528268  [    0/   28]\n",
      "loss: 0.528149  [    0/   28]\n",
      "loss: 0.528031  [    0/   28]\n",
      "loss: 0.527912  [    0/   28]\n",
      "loss: 0.527793  [    0/   28]\n",
      "loss: 0.527674  [    0/   28]\n",
      "loss: 0.527555  [    0/   28]\n",
      "loss: 0.527436  [    0/   28]\n",
      "loss: 0.527317  [    0/   28]\n",
      "loss: 0.527198  [    0/   28]\n",
      "loss: 0.527079  [    0/   28]\n",
      "loss: 0.526960  [    0/   28]\n",
      "loss: 0.526841  [    0/   28]\n",
      "loss: 0.526722  [    0/   28]\n",
      "loss: 0.526603  [    0/   28]\n",
      "loss: 0.526483  [    0/   28]\n",
      "loss: 0.526364  [    0/   28]\n",
      "loss: 0.526245  [    0/   28]\n",
      "loss: 0.526125  [    0/   28]\n",
      "loss: 0.526006  [    0/   28]\n",
      "loss: 0.525887  [    0/   28]\n",
      "loss: 0.525767  [    0/   28]\n",
      "loss: 0.525648  [    0/   28]\n",
      "loss: 0.525528  [    0/   28]\n",
      "loss: 0.525408  [    0/   28]\n",
      "loss: 0.525289  [    0/   28]\n",
      "loss: 0.525169  [    0/   28]\n",
      "loss: 0.525050  [    0/   28]\n",
      "loss: 0.524929  [    0/   28]\n",
      "loss: 0.524810  [    0/   28]\n",
      "loss: 0.524690  [    0/   28]\n",
      "loss: 0.524570  [    0/   28]\n",
      "loss: 0.524450  [    0/   28]\n",
      "loss: 0.524329  [    0/   28]\n",
      "loss: 0.524210  [    0/   28]\n",
      "loss: 0.524090  [    0/   28]\n",
      "loss: 0.523970  [    0/   28]\n",
      "loss: 0.523850  [    0/   28]\n",
      "loss: 0.523729  [    0/   28]\n",
      "loss: 0.523609  [    0/   28]\n",
      "loss: 0.523489  [    0/   28]\n",
      "loss: 0.523369  [    0/   28]\n",
      "loss: 0.523249  [    0/   28]\n",
      "loss: 0.523128  [    0/   28]\n",
      "loss: 0.523008  [    0/   28]\n",
      "loss: 0.522888  [    0/   28]\n",
      "loss: 0.522768  [    0/   28]\n",
      "loss: 0.522647  [    0/   28]\n",
      "loss: 0.522527  [    0/   28]\n",
      "loss: 0.522406  [    0/   28]\n",
      "loss: 0.522285  [    0/   28]\n",
      "loss: 0.522165  [    0/   28]\n",
      "loss: 0.522044  [    0/   28]\n",
      "loss: 0.521924  [    0/   28]\n",
      "loss: 0.521803  [    0/   28]\n",
      "loss: 0.521682  [    0/   28]\n",
      "loss: 0.521562  [    0/   28]\n",
      "loss: 0.521440  [    0/   28]\n",
      "loss: 0.521320  [    0/   28]\n",
      "loss: 0.521199  [    0/   28]\n",
      "loss: 0.521078  [    0/   28]\n",
      "loss: 0.520957  [    0/   28]\n",
      "loss: 0.520836  [    0/   28]\n",
      "loss: 0.520714  [    0/   28]\n",
      "loss: 0.520594  [    0/   28]\n",
      "loss: 0.520472  [    0/   28]\n",
      "loss: 0.520351  [    0/   28]\n",
      "loss: 0.520230  [    0/   28]\n",
      "loss: 0.520109  [    0/   28]\n",
      "loss: 0.519988  [    0/   28]\n",
      "loss: 0.519867  [    0/   28]\n",
      "loss: 0.519745  [    0/   28]\n",
      "loss: 0.519624  [    0/   28]\n",
      "loss: 0.519503  [    0/   28]\n",
      "loss: 0.519382  [    0/   28]\n",
      "loss: 0.519260  [    0/   28]\n",
      "loss: 0.519138  [    0/   28]\n",
      "loss: 0.519017  [    0/   28]\n",
      "loss: 0.518896  [    0/   28]\n",
      "loss: 0.518774  [    0/   28]\n",
      "loss: 0.518652  [    0/   28]\n",
      "loss: 0.518531  [    0/   28]\n",
      "loss: 0.518409  [    0/   28]\n",
      "loss: 0.518287  [    0/   28]\n",
      "loss: 0.518166  [    0/   28]\n",
      "loss: 0.518044  [    0/   28]\n",
      "loss: 0.517922  [    0/   28]\n",
      "loss: 0.517800  [    0/   28]\n",
      "loss: 0.517678  [    0/   28]\n",
      "loss: 0.517556  [    0/   28]\n",
      "loss: 0.517434  [    0/   28]\n",
      "loss: 0.517313  [    0/   28]\n",
      "loss: 0.517190  [    0/   28]\n",
      "loss: 0.517068  [    0/   28]\n",
      "loss: 0.516946  [    0/   28]\n",
      "loss: 0.516824  [    0/   28]\n",
      "loss: 0.516702  [    0/   28]\n",
      "loss: 0.516580  [    0/   28]\n",
      "loss: 0.516457  [    0/   28]\n",
      "loss: 0.516335  [    0/   28]\n",
      "loss: 0.516213  [    0/   28]\n",
      "loss: 0.516090  [    0/   28]\n",
      "loss: 0.515968  [    0/   28]\n",
      "loss: 0.515845  [    0/   28]\n",
      "loss: 0.515723  [    0/   28]\n",
      "loss: 0.515601  [    0/   28]\n",
      "loss: 0.515478  [    0/   28]\n",
      "loss: 0.515355  [    0/   28]\n",
      "loss: 0.515232  [    0/   28]\n",
      "loss: 0.515109  [    0/   28]\n",
      "loss: 0.514987  [    0/   28]\n",
      "loss: 0.514864  [    0/   28]\n",
      "loss: 0.514742  [    0/   28]\n",
      "loss: 0.514619  [    0/   28]\n",
      "loss: 0.514496  [    0/   28]\n",
      "loss: 0.514373  [    0/   28]\n",
      "loss: 0.514250  [    0/   28]\n",
      "loss: 0.514127  [    0/   28]\n",
      "loss: 0.514004  [    0/   28]\n",
      "loss: 0.513881  [    0/   28]\n",
      "loss: 0.513758  [    0/   28]\n",
      "loss: 0.513635  [    0/   28]\n",
      "loss: 0.513512  [    0/   28]\n",
      "loss: 0.513389  [    0/   28]\n",
      "loss: 0.513266  [    0/   28]\n",
      "loss: 0.513143  [    0/   28]\n",
      "loss: 0.513020  [    0/   28]\n",
      "loss: 0.512897  [    0/   28]\n",
      "loss: 0.512773  [    0/   28]\n",
      "loss: 0.512650  [    0/   28]\n",
      "loss: 0.512527  [    0/   28]\n",
      "loss: 0.512404  [    0/   28]\n",
      "loss: 0.512281  [    0/   28]\n",
      "loss: 0.512157  [    0/   28]\n",
      "loss: 0.512033  [    0/   28]\n",
      "loss: 0.511910  [    0/   28]\n",
      "loss: 0.511786  [    0/   28]\n",
      "loss: 0.511662  [    0/   28]\n",
      "loss: 0.511539  [    0/   28]\n",
      "loss: 0.511415  [    0/   28]\n",
      "loss: 0.511291  [    0/   28]\n",
      "loss: 0.511168  [    0/   28]\n",
      "loss: 0.511044  [    0/   28]\n",
      "loss: 0.510920  [    0/   28]\n",
      "loss: 0.510797  [    0/   28]\n",
      "loss: 0.510673  [    0/   28]\n",
      "loss: 0.510549  [    0/   28]\n",
      "loss: 0.510425  [    0/   28]\n",
      "loss: 0.510301  [    0/   28]\n",
      "loss: 0.510177  [    0/   28]\n",
      "loss: 0.510053  [    0/   28]\n",
      "loss: 0.509929  [    0/   28]\n",
      "loss: 0.509805  [    0/   28]\n",
      "loss: 0.509680  [    0/   28]\n",
      "loss: 0.509556  [    0/   28]\n",
      "loss: 0.509432  [    0/   28]\n",
      "loss: 0.509308  [    0/   28]\n",
      "loss: 0.509184  [    0/   28]\n",
      "loss: 0.509060  [    0/   28]\n",
      "loss: 0.508936  [    0/   28]\n",
      "loss: 0.508811  [    0/   28]\n",
      "loss: 0.508687  [    0/   28]\n",
      "loss: 0.508562  [    0/   28]\n",
      "loss: 0.508438  [    0/   28]\n",
      "loss: 0.508313  [    0/   28]\n",
      "loss: 0.508189  [    0/   28]\n",
      "loss: 0.508064  [    0/   28]\n",
      "loss: 0.507939  [    0/   28]\n",
      "loss: 0.507815  [    0/   28]\n",
      "loss: 0.507691  [    0/   28]\n",
      "loss: 0.507565  [    0/   28]\n",
      "loss: 0.507441  [    0/   28]\n",
      "loss: 0.507317  [    0/   28]\n",
      "loss: 0.507191  [    0/   28]\n",
      "loss: 0.507067  [    0/   28]\n",
      "loss: 0.506942  [    0/   28]\n",
      "loss: 0.506817  [    0/   28]\n",
      "loss: 0.506693  [    0/   28]\n",
      "loss: 0.506567  [    0/   28]\n",
      "loss: 0.506443  [    0/   28]\n",
      "loss: 0.506317  [    0/   28]\n",
      "loss: 0.506192  [    0/   28]\n",
      "loss: 0.506068  [    0/   28]\n",
      "loss: 0.505942  [    0/   28]\n",
      "loss: 0.505817  [    0/   28]\n",
      "loss: 0.505692  [    0/   28]\n",
      "loss: 0.505567  [    0/   28]\n",
      "loss: 0.505442  [    0/   28]\n",
      "loss: 0.505317  [    0/   28]\n",
      "loss: 0.505192  [    0/   28]\n",
      "loss: 0.505068  [    0/   28]\n",
      "loss: 0.504942  [    0/   28]\n",
      "loss: 0.504817  [    0/   28]\n",
      "loss: 0.504692  [    0/   28]\n",
      "loss: 0.504567  [    0/   28]\n",
      "loss: 0.504441  [    0/   28]\n",
      "loss: 0.504316  [    0/   28]\n",
      "loss: 0.504191  [    0/   28]\n",
      "loss: 0.504065  [    0/   28]\n",
      "loss: 0.503941  [    0/   28]\n",
      "loss: 0.503814  [    0/   28]\n",
      "loss: 0.503690  [    0/   28]\n",
      "loss: 0.503563  [    0/   28]\n",
      "loss: 0.503439  [    0/   28]\n",
      "loss: 0.503313  [    0/   28]\n",
      "loss: 0.503188  [    0/   28]\n",
      "loss: 0.503062  [    0/   28]\n",
      "loss: 0.502936  [    0/   28]\n",
      "loss: 0.502811  [    0/   28]\n",
      "loss: 0.502685  [    0/   28]\n",
      "loss: 0.502560  [    0/   28]\n",
      "loss: 0.502434  [    0/   28]\n",
      "loss: 0.502309  [    0/   28]\n",
      "loss: 0.502182  [    0/   28]\n",
      "loss: 0.502056  [    0/   28]\n",
      "loss: 0.501931  [    0/   28]\n",
      "loss: 0.501805  [    0/   28]\n",
      "loss: 0.501680  [    0/   28]\n",
      "loss: 0.501553  [    0/   28]\n",
      "loss: 0.501428  [    0/   28]\n",
      "loss: 0.501302  [    0/   28]\n",
      "loss: 0.501176  [    0/   28]\n",
      "loss: 0.501051  [    0/   28]\n",
      "loss: 0.500924  [    0/   28]\n",
      "loss: 0.500799  [    0/   28]\n",
      "loss: 0.500672  [    0/   28]\n",
      "loss: 0.500546  [    0/   28]\n",
      "loss: 0.500421  [    0/   28]\n",
      "loss: 0.500294  [    0/   28]\n",
      "loss: 0.500168  [    0/   28]\n",
      "loss: 0.500041  [    0/   28]\n",
      "loss: 0.499915  [    0/   28]\n",
      "loss: 0.499789  [    0/   28]\n",
      "loss: 0.499662  [    0/   28]\n",
      "loss: 0.499536  [    0/   28]\n",
      "loss: 0.499409  [    0/   28]\n",
      "loss: 0.499283  [    0/   28]\n",
      "loss: 0.499157  [    0/   28]\n",
      "loss: 0.499029  [    0/   28]\n",
      "loss: 0.498903  [    0/   28]\n",
      "loss: 0.498777  [    0/   28]\n",
      "loss: 0.498650  [    0/   28]\n",
      "loss: 0.498523  [    0/   28]\n",
      "loss: 0.498397  [    0/   28]\n",
      "loss: 0.498270  [    0/   28]\n",
      "loss: 0.498143  [    0/   28]\n",
      "loss: 0.498016  [    0/   28]\n",
      "loss: 0.497888  [    0/   28]\n",
      "loss: 0.497762  [    0/   28]\n",
      "loss: 0.497635  [    0/   28]\n",
      "loss: 0.497508  [    0/   28]\n",
      "loss: 0.497382  [    0/   28]\n",
      "loss: 0.497253  [    0/   28]\n",
      "loss: 0.497128  [    0/   28]\n",
      "loss: 0.497000  [    0/   28]\n",
      "loss: 0.496873  [    0/   28]\n",
      "loss: 0.496745  [    0/   28]\n",
      "loss: 0.496619  [    0/   28]\n",
      "loss: 0.496491  [    0/   28]\n",
      "loss: 0.496364  [    0/   28]\n",
      "loss: 0.496237  [    0/   28]\n",
      "loss: 0.496109  [    0/   28]\n",
      "loss: 0.495982  [    0/   28]\n",
      "loss: 0.495855  [    0/   28]\n",
      "loss: 0.495728  [    0/   28]\n",
      "loss: 0.495600  [    0/   28]\n",
      "loss: 0.495473  [    0/   28]\n",
      "loss: 0.495345  [    0/   28]\n",
      "loss: 0.495218  [    0/   28]\n",
      "loss: 0.495090  [    0/   28]\n",
      "loss: 0.494963  [    0/   28]\n",
      "loss: 0.494835  [    0/   28]\n",
      "loss: 0.494708  [    0/   28]\n",
      "loss: 0.494580  [    0/   28]\n",
      "loss: 0.494452  [    0/   28]\n",
      "loss: 0.494324  [    0/   28]\n",
      "loss: 0.494197  [    0/   28]\n",
      "loss: 0.494069  [    0/   28]\n",
      "loss: 0.493942  [    0/   28]\n",
      "loss: 0.493813  [    0/   28]\n",
      "loss: 0.493685  [    0/   28]\n",
      "loss: 0.493557  [    0/   28]\n",
      "loss: 0.493429  [    0/   28]\n",
      "loss: 0.493301  [    0/   28]\n",
      "loss: 0.493173  [    0/   28]\n",
      "loss: 0.493046  [    0/   28]\n",
      "loss: 0.492917  [    0/   28]\n",
      "loss: 0.492789  [    0/   28]\n",
      "loss: 0.492661  [    0/   28]\n",
      "loss: 0.492532  [    0/   28]\n",
      "loss: 0.492404  [    0/   28]\n",
      "loss: 0.492276  [    0/   28]\n",
      "loss: 0.492147  [    0/   28]\n",
      "loss: 0.492019  [    0/   28]\n",
      "loss: 0.491890  [    0/   28]\n",
      "loss: 0.491762  [    0/   28]\n",
      "loss: 0.491633  [    0/   28]\n",
      "loss: 0.491505  [    0/   28]\n",
      "loss: 0.491376  [    0/   28]\n",
      "loss: 0.491247  [    0/   28]\n",
      "loss: 0.491120  [    0/   28]\n",
      "loss: 0.490991  [    0/   28]\n",
      "loss: 0.490862  [    0/   28]\n",
      "loss: 0.490733  [    0/   28]\n",
      "loss: 0.490605  [    0/   28]\n",
      "loss: 0.490475  [    0/   28]\n",
      "loss: 0.490347  [    0/   28]\n",
      "loss: 0.490219  [    0/   28]\n",
      "loss: 0.490089  [    0/   28]\n",
      "loss: 0.489960  [    0/   28]\n",
      "loss: 0.489832  [    0/   28]\n",
      "loss: 0.489702  [    0/   28]\n",
      "loss: 0.489573  [    0/   28]\n",
      "loss: 0.489444  [    0/   28]\n",
      "loss: 0.489315  [    0/   28]\n",
      "loss: 0.489185  [    0/   28]\n",
      "loss: 0.489056  [    0/   28]\n",
      "loss: 0.488928  [    0/   28]\n",
      "loss: 0.488797  [    0/   28]\n",
      "loss: 0.488668  [    0/   28]\n",
      "loss: 0.488539  [    0/   28]\n",
      "loss: 0.488409  [    0/   28]\n",
      "loss: 0.488280  [    0/   28]\n",
      "loss: 0.488150  [    0/   28]\n",
      "loss: 0.488020  [    0/   28]\n",
      "loss: 0.487890  [    0/   28]\n",
      "loss: 0.487760  [    0/   28]\n",
      "loss: 0.487632  [    0/   28]\n",
      "loss: 0.487502  [    0/   28]\n",
      "loss: 0.487373  [    0/   28]\n",
      "loss: 0.487242  [    0/   28]\n",
      "loss: 0.487113  [    0/   28]\n",
      "loss: 0.486982  [    0/   28]\n",
      "loss: 0.486852  [    0/   28]\n",
      "loss: 0.486723  [    0/   28]\n",
      "loss: 0.486592  [    0/   28]\n",
      "loss: 0.486463  [    0/   28]\n",
      "loss: 0.486333  [    0/   28]\n",
      "loss: 0.486202  [    0/   28]\n",
      "loss: 0.486072  [    0/   28]\n",
      "loss: 0.485942  [    0/   28]\n",
      "loss: 0.485812  [    0/   28]\n",
      "loss: 0.485682  [    0/   28]\n",
      "loss: 0.485552  [    0/   28]\n",
      "loss: 0.485421  [    0/   28]\n",
      "loss: 0.485291  [    0/   28]\n",
      "loss: 0.485161  [    0/   28]\n",
      "loss: 0.485030  [    0/   28]\n",
      "loss: 0.484900  [    0/   28]\n",
      "loss: 0.484769  [    0/   28]\n",
      "loss: 0.484638  [    0/   28]\n",
      "loss: 0.484509  [    0/   28]\n",
      "loss: 0.484377  [    0/   28]\n",
      "loss: 0.484246  [    0/   28]\n",
      "loss: 0.484117  [    0/   28]\n",
      "loss: 0.483985  [    0/   28]\n",
      "loss: 0.483855  [    0/   28]\n",
      "loss: 0.483724  [    0/   28]\n",
      "loss: 0.483593  [    0/   28]\n",
      "loss: 0.483462  [    0/   28]\n",
      "loss: 0.483332  [    0/   28]\n",
      "loss: 0.483201  [    0/   28]\n",
      "loss: 0.483069  [    0/   28]\n",
      "loss: 0.482938  [    0/   28]\n",
      "loss: 0.482808  [    0/   28]\n",
      "loss: 0.482677  [    0/   28]\n",
      "loss: 0.482546  [    0/   28]\n",
      "loss: 0.482414  [    0/   28]\n",
      "loss: 0.482283  [    0/   28]\n",
      "loss: 0.482152  [    0/   28]\n",
      "loss: 0.482021  [    0/   28]\n",
      "loss: 0.481890  [    0/   28]\n",
      "loss: 0.481759  [    0/   28]\n",
      "loss: 0.481628  [    0/   28]\n",
      "loss: 0.481496  [    0/   28]\n",
      "loss: 0.481366  [    0/   28]\n",
      "loss: 0.481234  [    0/   28]\n",
      "loss: 0.481103  [    0/   28]\n",
      "loss: 0.480971  [    0/   28]\n",
      "loss: 0.480840  [    0/   28]\n",
      "loss: 0.480709  [    0/   28]\n",
      "loss: 0.480578  [    0/   28]\n",
      "loss: 0.480446  [    0/   28]\n",
      "loss: 0.480315  [    0/   28]\n",
      "loss: 0.480183  [    0/   28]\n",
      "loss: 0.480051  [    0/   28]\n",
      "loss: 0.479921  [    0/   28]\n",
      "loss: 0.479789  [    0/   28]\n",
      "loss: 0.479658  [    0/   28]\n",
      "loss: 0.479525  [    0/   28]\n",
      "loss: 0.479394  [    0/   28]\n",
      "loss: 0.479263  [    0/   28]\n",
      "loss: 0.479132  [    0/   28]\n",
      "loss: 0.479000  [    0/   28]\n",
      "loss: 0.478869  [    0/   28]\n",
      "loss: 0.478738  [    0/   28]\n",
      "loss: 0.478606  [    0/   28]\n",
      "loss: 0.478474  [    0/   28]\n",
      "loss: 0.478343  [    0/   28]\n",
      "loss: 0.478211  [    0/   28]\n",
      "loss: 0.478079  [    0/   28]\n",
      "loss: 0.477948  [    0/   28]\n",
      "loss: 0.477816  [    0/   28]\n",
      "loss: 0.477685  [    0/   28]\n",
      "loss: 0.477552  [    0/   28]\n",
      "loss: 0.477421  [    0/   28]\n",
      "loss: 0.477289  [    0/   28]\n",
      "loss: 0.477158  [    0/   28]\n",
      "loss: 0.477025  [    0/   28]\n",
      "loss: 0.476893  [    0/   28]\n",
      "loss: 0.476761  [    0/   28]\n",
      "loss: 0.476630  [    0/   28]\n",
      "loss: 0.476498  [    0/   28]\n",
      "loss: 0.476365  [    0/   28]\n",
      "loss: 0.476234  [    0/   28]\n",
      "loss: 0.476101  [    0/   28]\n",
      "loss: 0.475969  [    0/   28]\n",
      "loss: 0.475837  [    0/   28]\n",
      "loss: 0.475706  [    0/   28]\n",
      "loss: 0.475572  [    0/   28]\n",
      "loss: 0.475441  [    0/   28]\n",
      "loss: 0.475308  [    0/   28]\n",
      "loss: 0.475175  [    0/   28]\n",
      "loss: 0.475043  [    0/   28]\n",
      "loss: 0.474911  [    0/   28]\n",
      "loss: 0.474778  [    0/   28]\n",
      "loss: 0.474645  [    0/   28]\n",
      "loss: 0.474513  [    0/   28]\n",
      "loss: 0.474380  [    0/   28]\n",
      "loss: 0.474247  [    0/   28]\n",
      "loss: 0.474116  [    0/   28]\n",
      "loss: 0.473982  [    0/   28]\n",
      "loss: 0.473851  [    0/   28]\n",
      "loss: 0.473716  [    0/   28]\n",
      "loss: 0.473584  [    0/   28]\n",
      "loss: 0.473451  [    0/   28]\n",
      "loss: 0.473318  [    0/   28]\n",
      "loss: 0.473186  [    0/   28]\n",
      "loss: 0.473052  [    0/   28]\n",
      "loss: 0.472920  [    0/   28]\n",
      "loss: 0.472786  [    0/   28]\n",
      "loss: 0.472654  [    0/   28]\n",
      "loss: 0.472521  [    0/   28]\n",
      "loss: 0.472387  [    0/   28]\n",
      "loss: 0.472254  [    0/   28]\n",
      "loss: 0.472121  [    0/   28]\n",
      "loss: 0.471987  [    0/   28]\n",
      "loss: 0.471854  [    0/   28]\n",
      "loss: 0.471720  [    0/   28]\n",
      "loss: 0.471587  [    0/   28]\n",
      "loss: 0.471452  [    0/   28]\n",
      "loss: 0.471320  [    0/   28]\n",
      "loss: 0.471185  [    0/   28]\n",
      "loss: 0.471052  [    0/   28]\n",
      "loss: 0.470919  [    0/   28]\n",
      "loss: 0.470785  [    0/   28]\n",
      "loss: 0.470650  [    0/   28]\n",
      "loss: 0.470517  [    0/   28]\n",
      "loss: 0.470383  [    0/   28]\n",
      "loss: 0.470250  [    0/   28]\n",
      "loss: 0.470116  [    0/   28]\n",
      "loss: 0.469982  [    0/   28]\n",
      "loss: 0.469849  [    0/   28]\n",
      "loss: 0.469714  [    0/   28]\n",
      "loss: 0.469580  [    0/   28]\n",
      "loss: 0.469446  [    0/   28]\n",
      "loss: 0.469313  [    0/   28]\n",
      "loss: 0.469177  [    0/   28]\n",
      "loss: 0.469044  [    0/   28]\n",
      "loss: 0.468910  [    0/   28]\n",
      "loss: 0.468775  [    0/   28]\n",
      "loss: 0.468641  [    0/   28]\n",
      "loss: 0.468508  [    0/   28]\n",
      "loss: 0.468374  [    0/   28]\n",
      "loss: 0.468239  [    0/   28]\n",
      "loss: 0.468106  [    0/   28]\n",
      "loss: 0.467971  [    0/   28]\n",
      "loss: 0.467837  [    0/   28]\n",
      "loss: 0.467702  [    0/   28]\n",
      "loss: 0.467568  [    0/   28]\n",
      "loss: 0.467434  [    0/   28]\n",
      "loss: 0.467299  [    0/   28]\n",
      "loss: 0.467165  [    0/   28]\n",
      "loss: 0.467031  [    0/   28]\n",
      "loss: 0.466896  [    0/   28]\n",
      "loss: 0.466761  [    0/   28]\n",
      "loss: 0.466627  [    0/   28]\n",
      "loss: 0.466491  [    0/   28]\n",
      "loss: 0.466358  [    0/   28]\n",
      "loss: 0.466223  [    0/   28]\n",
      "loss: 0.466088  [    0/   28]\n",
      "loss: 0.465954  [    0/   28]\n",
      "loss: 0.465818  [    0/   28]\n",
      "loss: 0.465683  [    0/   28]\n",
      "loss: 0.465549  [    0/   28]\n",
      "loss: 0.465414  [    0/   28]\n",
      "loss: 0.465279  [    0/   28]\n",
      "loss: 0.465143  [    0/   28]\n",
      "loss: 0.465009  [    0/   28]\n",
      "loss: 0.464873  [    0/   28]\n",
      "loss: 0.464738  [    0/   28]\n",
      "loss: 0.464603  [    0/   28]\n",
      "loss: 0.464468  [    0/   28]\n",
      "loss: 0.464334  [    0/   28]\n",
      "loss: 0.464197  [    0/   28]\n",
      "loss: 0.464063  [    0/   28]\n",
      "loss: 0.463928  [    0/   28]\n",
      "loss: 0.463792  [    0/   28]\n",
      "loss: 0.463656  [    0/   28]\n",
      "loss: 0.463521  [    0/   28]\n",
      "loss: 0.463385  [    0/   28]\n",
      "loss: 0.463250  [    0/   28]\n",
      "loss: 0.463115  [    0/   28]\n",
      "loss: 0.462979  [    0/   28]\n",
      "loss: 0.462844  [    0/   28]\n",
      "loss: 0.462708  [    0/   28]\n",
      "loss: 0.462573  [    0/   28]\n",
      "loss: 0.462438  [    0/   28]\n",
      "loss: 0.462302  [    0/   28]\n",
      "loss: 0.462166  [    0/   28]\n",
      "loss: 0.462030  [    0/   28]\n",
      "loss: 0.461895  [    0/   28]\n",
      "loss: 0.461759  [    0/   28]\n",
      "loss: 0.461624  [    0/   28]\n",
      "loss: 0.461487  [    0/   28]\n",
      "loss: 0.461353  [    0/   28]\n",
      "loss: 0.461216  [    0/   28]\n",
      "loss: 0.461080  [    0/   28]\n",
      "loss: 0.460945  [    0/   28]\n",
      "loss: 0.460809  [    0/   28]\n",
      "loss: 0.460673  [    0/   28]\n",
      "loss: 0.460538  [    0/   28]\n",
      "loss: 0.460403  [    0/   28]\n",
      "loss: 0.460266  [    0/   28]\n",
      "loss: 0.460131  [    0/   28]\n",
      "loss: 0.459994  [    0/   28]\n",
      "loss: 0.459859  [    0/   28]\n",
      "loss: 0.459723  [    0/   28]\n",
      "loss: 0.459587  [    0/   28]\n",
      "loss: 0.459451  [    0/   28]\n",
      "loss: 0.459314  [    0/   28]\n",
      "loss: 0.459178  [    0/   28]\n",
      "loss: 0.459043  [    0/   28]\n",
      "loss: 0.458906  [    0/   28]\n",
      "loss: 0.458770  [    0/   28]\n",
      "loss: 0.458634  [    0/   28]\n",
      "loss: 0.458497  [    0/   28]\n",
      "loss: 0.458361  [    0/   28]\n",
      "loss: 0.458225  [    0/   28]\n",
      "loss: 0.458087  [    0/   28]\n",
      "loss: 0.457952  [    0/   28]\n",
      "loss: 0.457815  [    0/   28]\n",
      "loss: 0.457680  [    0/   28]\n",
      "loss: 0.457542  [    0/   28]\n",
      "loss: 0.457405  [    0/   28]\n",
      "loss: 0.457269  [    0/   28]\n",
      "loss: 0.457134  [    0/   28]\n",
      "loss: 0.456995  [    0/   28]\n",
      "loss: 0.456859  [    0/   28]\n",
      "loss: 0.456723  [    0/   28]\n",
      "loss: 0.456586  [    0/   28]\n",
      "loss: 0.456450  [    0/   28]\n",
      "loss: 0.456313  [    0/   28]\n",
      "loss: 0.456175  [    0/   28]\n",
      "loss: 0.456040  [    0/   28]\n",
      "loss: 0.455902  [    0/   28]\n",
      "loss: 0.455765  [    0/   28]\n",
      "loss: 0.455628  [    0/   28]\n",
      "loss: 0.455491  [    0/   28]\n",
      "loss: 0.455353  [    0/   28]\n",
      "loss: 0.455217  [    0/   28]\n",
      "loss: 0.455080  [    0/   28]\n",
      "loss: 0.454941  [    0/   28]\n",
      "loss: 0.454804  [    0/   28]\n",
      "loss: 0.454668  [    0/   28]\n",
      "loss: 0.454531  [    0/   28]\n",
      "loss: 0.454393  [    0/   28]\n",
      "loss: 0.454255  [    0/   28]\n",
      "loss: 0.454117  [    0/   28]\n",
      "loss: 0.453981  [    0/   28]\n",
      "loss: 0.453843  [    0/   28]\n",
      "loss: 0.453705  [    0/   28]\n",
      "loss: 0.453568  [    0/   28]\n",
      "loss: 0.453431  [    0/   28]\n",
      "loss: 0.453292  [    0/   28]\n",
      "loss: 0.453154  [    0/   28]\n",
      "loss: 0.453018  [    0/   28]\n",
      "loss: 0.452880  [    0/   28]\n",
      "loss: 0.452742  [    0/   28]\n",
      "loss: 0.452606  [    0/   28]\n",
      "loss: 0.452467  [    0/   28]\n",
      "loss: 0.452329  [    0/   28]\n",
      "loss: 0.452192  [    0/   28]\n",
      "loss: 0.452055  [    0/   28]\n",
      "loss: 0.451917  [    0/   28]\n",
      "loss: 0.451779  [    0/   28]\n",
      "loss: 0.451642  [    0/   28]\n",
      "loss: 0.451504  [    0/   28]\n",
      "loss: 0.451366  [    0/   28]\n",
      "loss: 0.451230  [    0/   28]\n",
      "loss: 0.451092  [    0/   28]\n",
      "loss: 0.450953  [    0/   28]\n",
      "loss: 0.450817  [    0/   28]\n",
      "loss: 0.450677  [    0/   28]\n",
      "loss: 0.450540  [    0/   28]\n",
      "loss: 0.450401  [    0/   28]\n",
      "loss: 0.450263  [    0/   28]\n",
      "loss: 0.450126  [    0/   28]\n",
      "loss: 0.449988  [    0/   28]\n",
      "loss: 0.449850  [    0/   28]\n",
      "loss: 0.449712  [    0/   28]\n",
      "loss: 0.449573  [    0/   28]\n",
      "loss: 0.449436  [    0/   28]\n",
      "loss: 0.449298  [    0/   28]\n",
      "loss: 0.449159  [    0/   28]\n",
      "loss: 0.449021  [    0/   28]\n",
      "loss: 0.448883  [    0/   28]\n",
      "loss: 0.448745  [    0/   28]\n",
      "loss: 0.448607  [    0/   28]\n",
      "loss: 0.448468  [    0/   28]\n",
      "loss: 0.448330  [    0/   28]\n",
      "loss: 0.448192  [    0/   28]\n",
      "loss: 0.448054  [    0/   28]\n",
      "loss: 0.447915  [    0/   28]\n",
      "loss: 0.447777  [    0/   28]\n",
      "loss: 0.447638  [    0/   28]\n",
      "loss: 0.447500  [    0/   28]\n",
      "loss: 0.447361  [    0/   28]\n",
      "loss: 0.447223  [    0/   28]\n",
      "loss: 0.447083  [    0/   28]\n",
      "loss: 0.446946  [    0/   28]\n",
      "loss: 0.446807  [    0/   28]\n",
      "loss: 0.446669  [    0/   28]\n",
      "loss: 0.446528  [    0/   28]\n",
      "loss: 0.446391  [    0/   28]\n",
      "loss: 0.446251  [    0/   28]\n",
      "loss: 0.446113  [    0/   28]\n",
      "loss: 0.445974  [    0/   28]\n",
      "loss: 0.445835  [    0/   28]\n",
      "loss: 0.445696  [    0/   28]\n",
      "loss: 0.445557  [    0/   28]\n",
      "loss: 0.445419  [    0/   28]\n",
      "loss: 0.445279  [    0/   28]\n",
      "loss: 0.445140  [    0/   28]\n",
      "loss: 0.445000  [    0/   28]\n",
      "loss: 0.444862  [    0/   28]\n",
      "loss: 0.444723  [    0/   28]\n",
      "loss: 0.444584  [    0/   28]\n",
      "loss: 0.444445  [    0/   28]\n",
      "loss: 0.444305  [    0/   28]\n",
      "loss: 0.444166  [    0/   28]\n",
      "loss: 0.444027  [    0/   28]\n",
      "loss: 0.443888  [    0/   28]\n",
      "loss: 0.443749  [    0/   28]\n",
      "loss: 0.443609  [    0/   28]\n",
      "loss: 0.443470  [    0/   28]\n",
      "loss: 0.443331  [    0/   28]\n",
      "loss: 0.443191  [    0/   28]\n",
      "loss: 0.443051  [    0/   28]\n",
      "loss: 0.442912  [    0/   28]\n",
      "loss: 0.442774  [    0/   28]\n",
      "loss: 0.442633  [    0/   28]\n",
      "loss: 0.442493  [    0/   28]\n",
      "loss: 0.442354  [    0/   28]\n",
      "loss: 0.442214  [    0/   28]\n",
      "loss: 0.442073  [    0/   28]\n",
      "loss: 0.441934  [    0/   28]\n",
      "loss: 0.441794  [    0/   28]\n",
      "loss: 0.441656  [    0/   28]\n",
      "loss: 0.441515  [    0/   28]\n",
      "loss: 0.441376  [    0/   28]\n",
      "loss: 0.441235  [    0/   28]\n",
      "loss: 0.441095  [    0/   28]\n",
      "loss: 0.440956  [    0/   28]\n",
      "loss: 0.440816  [    0/   28]\n",
      "loss: 0.440674  [    0/   28]\n",
      "loss: 0.440536  [    0/   28]\n",
      "loss: 0.440395  [    0/   28]\n",
      "loss: 0.440255  [    0/   28]\n",
      "loss: 0.440115  [    0/   28]\n",
      "loss: 0.439975  [    0/   28]\n",
      "loss: 0.439836  [    0/   28]\n",
      "loss: 0.439694  [    0/   28]\n",
      "loss: 0.439554  [    0/   28]\n",
      "loss: 0.439415  [    0/   28]\n",
      "loss: 0.439274  [    0/   28]\n",
      "loss: 0.439135  [    0/   28]\n",
      "loss: 0.438995  [    0/   28]\n",
      "loss: 0.438853  [    0/   28]\n",
      "loss: 0.438713  [    0/   28]\n",
      "loss: 0.438574  [    0/   28]\n",
      "loss: 0.438433  [    0/   28]\n",
      "loss: 0.438293  [    0/   28]\n",
      "loss: 0.438152  [    0/   28]\n",
      "loss: 0.438012  [    0/   28]\n",
      "loss: 0.437871  [    0/   28]\n",
      "loss: 0.437731  [    0/   28]\n",
      "loss: 0.437590  [    0/   28]\n",
      "loss: 0.437451  [    0/   28]\n",
      "loss: 0.437309  [    0/   28]\n",
      "loss: 0.437170  [    0/   28]\n",
      "loss: 0.437028  [    0/   28]\n",
      "loss: 0.436889  [    0/   28]\n",
      "loss: 0.436747  [    0/   28]\n",
      "loss: 0.436608  [    0/   28]\n",
      "loss: 0.436466  [    0/   28]\n",
      "loss: 0.436327  [    0/   28]\n",
      "loss: 0.436186  [    0/   28]\n",
      "loss: 0.436045  [    0/   28]\n",
      "loss: 0.435904  [    0/   28]\n",
      "loss: 0.435764  [    0/   28]\n",
      "loss: 0.435623  [    0/   28]\n",
      "loss: 0.435482  [    0/   28]\n",
      "loss: 0.435342  [    0/   28]\n",
      "loss: 0.435200  [    0/   28]\n",
      "loss: 0.435060  [    0/   28]\n",
      "loss: 0.434918  [    0/   28]\n",
      "loss: 0.434779  [    0/   28]\n",
      "loss: 0.434636  [    0/   28]\n",
      "loss: 0.434495  [    0/   28]\n",
      "loss: 0.434357  [    0/   28]\n",
      "loss: 0.434214  [    0/   28]\n",
      "loss: 0.434074  [    0/   28]\n",
      "loss: 0.433931  [    0/   28]\n",
      "loss: 0.433790  [    0/   28]\n",
      "loss: 0.433649  [    0/   28]\n",
      "loss: 0.433510  [    0/   28]\n",
      "loss: 0.433368  [    0/   28]\n",
      "loss: 0.433226  [    0/   28]\n",
      "loss: 0.433087  [    0/   28]\n",
      "loss: 0.432943  [    0/   28]\n",
      "loss: 0.432803  [    0/   28]\n",
      "loss: 0.432662  [    0/   28]\n",
      "loss: 0.432520  [    0/   28]\n",
      "loss: 0.432380  [    0/   28]\n",
      "loss: 0.432237  [    0/   28]\n",
      "loss: 0.432095  [    0/   28]\n",
      "loss: 0.431956  [    0/   28]\n",
      "loss: 0.431812  [    0/   28]\n",
      "loss: 0.431671  [    0/   28]\n",
      "loss: 0.431530  [    0/   28]\n",
      "loss: 0.431390  [    0/   28]\n",
      "loss: 0.431247  [    0/   28]\n",
      "loss: 0.431107  [    0/   28]\n",
      "loss: 0.430965  [    0/   28]\n",
      "loss: 0.430823  [    0/   28]\n",
      "loss: 0.430682  [    0/   28]\n",
      "loss: 0.430541  [    0/   28]\n",
      "loss: 0.430398  [    0/   28]\n",
      "loss: 0.430258  [    0/   28]\n",
      "loss: 0.430115  [    0/   28]\n",
      "loss: 0.429974  [    0/   28]\n",
      "loss: 0.429832  [    0/   28]\n",
      "loss: 0.429691  [    0/   28]\n",
      "loss: 0.429549  [    0/   28]\n",
      "loss: 0.429407  [    0/   28]\n",
      "loss: 0.429266  [    0/   28]\n",
      "loss: 0.429125  [    0/   28]\n",
      "loss: 0.428983  [    0/   28]\n",
      "loss: 0.428841  [    0/   28]\n",
      "loss: 0.428699  [    0/   28]\n",
      "loss: 0.428558  [    0/   28]\n",
      "loss: 0.428416  [    0/   28]\n",
      "loss: 0.428274  [    0/   28]\n",
      "loss: 0.428131  [    0/   28]\n",
      "loss: 0.427989  [    0/   28]\n",
      "loss: 0.427848  [    0/   28]\n",
      "loss: 0.427707  [    0/   28]\n",
      "loss: 0.427565  [    0/   28]\n",
      "loss: 0.427422  [    0/   28]\n",
      "loss: 0.427282  [    0/   28]\n",
      "loss: 0.427139  [    0/   28]\n",
      "loss: 0.426997  [    0/   28]\n",
      "loss: 0.426855  [    0/   28]\n",
      "loss: 0.426713  [    0/   28]\n",
      "loss: 0.426571  [    0/   28]\n",
      "loss: 0.426430  [    0/   28]\n",
      "loss: 0.426288  [    0/   28]\n",
      "loss: 0.426145  [    0/   28]\n",
      "loss: 0.426004  [    0/   28]\n",
      "loss: 0.425861  [    0/   28]\n",
      "loss: 0.425720  [    0/   28]\n",
      "loss: 0.425577  [    0/   28]\n",
      "loss: 0.425435  [    0/   28]\n",
      "loss: 0.425294  [    0/   28]\n",
      "loss: 0.425150  [    0/   28]\n",
      "loss: 0.425010  [    0/   28]\n",
      "loss: 0.424867  [    0/   28]\n",
      "loss: 0.424724  [    0/   28]\n",
      "loss: 0.424583  [    0/   28]\n",
      "loss: 0.424440  [    0/   28]\n",
      "loss: 0.424298  [    0/   28]\n",
      "loss: 0.424155  [    0/   28]\n",
      "loss: 0.424015  [    0/   28]\n",
      "loss: 0.423871  [    0/   28]\n",
      "loss: 0.423729  [    0/   28]\n",
      "loss: 0.423589  [    0/   28]\n",
      "loss: 0.423446  [    0/   28]\n",
      "loss: 0.423304  [    0/   28]\n",
      "loss: 0.423161  [    0/   28]\n",
      "loss: 0.423020  [    0/   28]\n",
      "loss: 0.422878  [    0/   28]\n",
      "loss: 0.422735  [    0/   28]\n",
      "loss: 0.422593  [    0/   28]\n",
      "loss: 0.422452  [    0/   28]\n",
      "loss: 0.422308  [    0/   28]\n",
      "loss: 0.422167  [    0/   28]\n",
      "loss: 0.422023  [    0/   28]\n",
      "loss: 0.421882  [    0/   28]\n",
      "loss: 0.421738  [    0/   28]\n",
      "loss: 0.421597  [    0/   28]\n",
      "loss: 0.421456  [    0/   28]\n",
      "loss: 0.421312  [    0/   28]\n",
      "loss: 0.421170  [    0/   28]\n",
      "loss: 0.421028  [    0/   28]\n",
      "loss: 0.420885  [    0/   28]\n",
      "loss: 0.420742  [    0/   28]\n",
      "loss: 0.420601  [    0/   28]\n",
      "loss: 0.420458  [    0/   28]\n",
      "loss: 0.420315  [    0/   28]\n",
      "loss: 0.420172  [    0/   28]\n",
      "loss: 0.420030  [    0/   28]\n",
      "loss: 0.419886  [    0/   28]\n",
      "loss: 0.419746  [    0/   28]\n",
      "loss: 0.419602  [    0/   28]\n",
      "loss: 0.419459  [    0/   28]\n",
      "loss: 0.419317  [    0/   28]\n",
      "loss: 0.419174  [    0/   28]\n",
      "loss: 0.419032  [    0/   28]\n",
      "loss: 0.418890  [    0/   28]\n",
      "loss: 0.418748  [    0/   28]\n",
      "loss: 0.418604  [    0/   28]\n",
      "loss: 0.418460  [    0/   28]\n",
      "loss: 0.418318  [    0/   28]\n",
      "loss: 0.418176  [    0/   28]\n",
      "loss: 0.418035  [    0/   28]\n",
      "loss: 0.417890  [    0/   28]\n",
      "loss: 0.417748  [    0/   28]\n",
      "loss: 0.417606  [    0/   28]\n",
      "loss: 0.417462  [    0/   28]\n",
      "loss: 0.417320  [    0/   28]\n",
      "loss: 0.417177  [    0/   28]\n",
      "loss: 0.417035  [    0/   28]\n",
      "loss: 0.416891  [    0/   28]\n",
      "loss: 0.416748  [    0/   28]\n",
      "loss: 0.416605  [    0/   28]\n",
      "loss: 0.416463  [    0/   28]\n",
      "loss: 0.416321  [    0/   28]\n",
      "loss: 0.416176  [    0/   28]\n",
      "loss: 0.416033  [    0/   28]\n",
      "loss: 0.415890  [    0/   28]\n",
      "loss: 0.415748  [    0/   28]\n",
      "loss: 0.415604  [    0/   28]\n",
      "loss: 0.415462  [    0/   28]\n",
      "loss: 0.415318  [    0/   28]\n",
      "loss: 0.415175  [    0/   28]\n",
      "loss: 0.415032  [    0/   28]\n",
      "loss: 0.414890  [    0/   28]\n",
      "loss: 0.414745  [    0/   28]\n",
      "loss: 0.414602  [    0/   28]\n",
      "loss: 0.414460  [    0/   28]\n",
      "loss: 0.414316  [    0/   28]\n",
      "loss: 0.414174  [    0/   28]\n",
      "loss: 0.414030  [    0/   28]\n",
      "loss: 0.413888  [    0/   28]\n",
      "loss: 0.413743  [    0/   28]\n",
      "loss: 0.413602  [    0/   28]\n",
      "loss: 0.413457  [    0/   28]\n",
      "loss: 0.413315  [    0/   28]\n",
      "loss: 0.413171  [    0/   28]\n",
      "loss: 0.413028  [    0/   28]\n",
      "loss: 0.412883  [    0/   28]\n",
      "loss: 0.412739  [    0/   28]\n",
      "loss: 0.412597  [    0/   28]\n",
      "loss: 0.412456  [    0/   28]\n",
      "loss: 0.412310  [    0/   28]\n",
      "loss: 0.412168  [    0/   28]\n",
      "loss: 0.412025  [    0/   28]\n",
      "loss: 0.411882  [    0/   28]\n",
      "loss: 0.411737  [    0/   28]\n",
      "loss: 0.411595  [    0/   28]\n",
      "loss: 0.411452  [    0/   28]\n",
      "loss: 0.411308  [    0/   28]\n",
      "loss: 0.411165  [    0/   28]\n",
      "loss: 0.411022  [    0/   28]\n",
      "loss: 0.410879  [    0/   28]\n",
      "loss: 0.410735  [    0/   28]\n",
      "loss: 0.410592  [    0/   28]\n",
      "loss: 0.410450  [    0/   28]\n",
      "loss: 0.410307  [    0/   28]\n",
      "loss: 0.410163  [    0/   28]\n",
      "loss: 0.410020  [    0/   28]\n",
      "loss: 0.409878  [    0/   28]\n",
      "loss: 0.409734  [    0/   28]\n",
      "loss: 0.409590  [    0/   28]\n",
      "loss: 0.409447  [    0/   28]\n",
      "loss: 0.409304  [    0/   28]\n",
      "loss: 0.409162  [    0/   28]\n",
      "loss: 0.409017  [    0/   28]\n",
      "loss: 0.408875  [    0/   28]\n",
      "loss: 0.408732  [    0/   28]\n",
      "loss: 0.408589  [    0/   28]\n",
      "loss: 0.408445  [    0/   28]\n",
      "loss: 0.408302  [    0/   28]\n",
      "loss: 0.408157  [    0/   28]\n",
      "loss: 0.408014  [    0/   28]\n",
      "loss: 0.407872  [    0/   28]\n",
      "loss: 0.407730  [    0/   28]\n",
      "loss: 0.407584  [    0/   28]\n",
      "loss: 0.407443  [    0/   28]\n",
      "loss: 0.407300  [    0/   28]\n",
      "loss: 0.407155  [    0/   28]\n",
      "loss: 0.407012  [    0/   28]\n",
      "loss: 0.406869  [    0/   28]\n",
      "loss: 0.406726  [    0/   28]\n",
      "loss: 0.406582  [    0/   28]\n",
      "loss: 0.406440  [    0/   28]\n",
      "loss: 0.406294  [    0/   28]\n",
      "loss: 0.406151  [    0/   28]\n",
      "loss: 0.406009  [    0/   28]\n",
      "loss: 0.405865  [    0/   28]\n",
      "loss: 0.405722  [    0/   28]\n",
      "loss: 0.405578  [    0/   28]\n",
      "loss: 0.405434  [    0/   28]\n",
      "loss: 0.405291  [    0/   28]\n",
      "loss: 0.405148  [    0/   28]\n",
      "loss: 0.405004  [    0/   28]\n",
      "loss: 0.404860  [    0/   28]\n",
      "loss: 0.404717  [    0/   28]\n",
      "loss: 0.404576  [    0/   28]\n",
      "loss: 0.404429  [    0/   28]\n",
      "loss: 0.404286  [    0/   28]\n",
      "loss: 0.404143  [    0/   28]\n",
      "loss: 0.404000  [    0/   28]\n",
      "loss: 0.403857  [    0/   28]\n",
      "loss: 0.403712  [    0/   28]\n",
      "loss: 0.403569  [    0/   28]\n",
      "loss: 0.403425  [    0/   28]\n",
      "loss: 0.403283  [    0/   28]\n",
      "loss: 0.403138  [    0/   28]\n",
      "loss: 0.402994  [    0/   28]\n",
      "loss: 0.402852  [    0/   28]\n",
      "loss: 0.402707  [    0/   28]\n",
      "loss: 0.402566  [    0/   28]\n",
      "loss: 0.402420  [    0/   28]\n",
      "loss: 0.402278  [    0/   28]\n",
      "loss: 0.402134  [    0/   28]\n",
      "loss: 0.401992  [    0/   28]\n",
      "loss: 0.401845  [    0/   28]\n",
      "loss: 0.401703  [    0/   28]\n",
      "loss: 0.401559  [    0/   28]\n",
      "loss: 0.401415  [    0/   28]\n",
      "loss: 0.401271  [    0/   28]\n",
      "loss: 0.401129  [    0/   28]\n",
      "loss: 0.400984  [    0/   28]\n",
      "loss: 0.400840  [    0/   28]\n",
      "loss: 0.400698  [    0/   28]\n",
      "loss: 0.400552  [    0/   28]\n",
      "loss: 0.400408  [    0/   28]\n",
      "loss: 0.400265  [    0/   28]\n",
      "loss: 0.400123  [    0/   28]\n",
      "loss: 0.399977  [    0/   28]\n",
      "loss: 0.399834  [    0/   28]\n",
      "loss: 0.399690  [    0/   28]\n",
      "loss: 0.399547  [    0/   28]\n",
      "loss: 0.399404  [    0/   28]\n",
      "loss: 0.399259  [    0/   28]\n",
      "loss: 0.399114  [    0/   28]\n",
      "loss: 0.398971  [    0/   28]\n",
      "loss: 0.398828  [    0/   28]\n",
      "loss: 0.398685  [    0/   28]\n",
      "loss: 0.398540  [    0/   28]\n",
      "loss: 0.398397  [    0/   28]\n",
      "loss: 0.398253  [    0/   28]\n",
      "loss: 0.398108  [    0/   28]\n",
      "loss: 0.397964  [    0/   28]\n",
      "loss: 0.397820  [    0/   28]\n",
      "loss: 0.397676  [    0/   28]\n",
      "loss: 0.397530  [    0/   28]\n",
      "loss: 0.397389  [    0/   28]\n",
      "loss: 0.397244  [    0/   28]\n",
      "loss: 0.397099  [    0/   28]\n",
      "loss: 0.396956  [    0/   28]\n",
      "loss: 0.396812  [    0/   28]\n",
      "loss: 0.396667  [    0/   28]\n",
      "loss: 0.396523  [    0/   28]\n",
      "loss: 0.396380  [    0/   28]\n",
      "loss: 0.396236  [    0/   28]\n",
      "loss: 0.396092  [    0/   28]\n",
      "loss: 0.395947  [    0/   28]\n",
      "loss: 0.395803  [    0/   28]\n",
      "loss: 0.395659  [    0/   28]\n",
      "loss: 0.395516  [    0/   28]\n",
      "loss: 0.395373  [    0/   28]\n",
      "loss: 0.395229  [    0/   28]\n",
      "loss: 0.395084  [    0/   28]\n",
      "loss: 0.394942  [    0/   28]\n",
      "loss: 0.394796  [    0/   28]\n",
      "loss: 0.394653  [    0/   28]\n",
      "loss: 0.394509  [    0/   28]\n",
      "loss: 0.394366  [    0/   28]\n",
      "loss: 0.394221  [    0/   28]\n",
      "loss: 0.394077  [    0/   28]\n",
      "loss: 0.393933  [    0/   28]\n",
      "loss: 0.393788  [    0/   28]\n",
      "loss: 0.393645  [    0/   28]\n",
      "loss: 0.393503  [    0/   28]\n",
      "loss: 0.393355  [    0/   28]\n",
      "loss: 0.393214  [    0/   28]\n",
      "loss: 0.393070  [    0/   28]\n",
      "loss: 0.392924  [    0/   28]\n",
      "loss: 0.392781  [    0/   28]\n",
      "loss: 0.392636  [    0/   28]\n",
      "loss: 0.392491  [    0/   28]\n",
      "loss: 0.392349  [    0/   28]\n",
      "loss: 0.392204  [    0/   28]\n",
      "loss: 0.392062  [    0/   28]\n",
      "loss: 0.391915  [    0/   28]\n",
      "loss: 0.391773  [    0/   28]\n",
      "loss: 0.391628  [    0/   28]\n",
      "loss: 0.391484  [    0/   28]\n",
      "loss: 0.391339  [    0/   28]\n",
      "loss: 0.391195  [    0/   28]\n",
      "loss: 0.391051  [    0/   28]\n",
      "loss: 0.390908  [    0/   28]\n",
      "loss: 0.390761  [    0/   28]\n",
      "loss: 0.390618  [    0/   28]\n",
      "loss: 0.390476  [    0/   28]\n",
      "loss: 0.390330  [    0/   28]\n",
      "loss: 0.390186  [    0/   28]\n",
      "loss: 0.390043  [    0/   28]\n",
      "loss: 0.389899  [    0/   28]\n",
      "loss: 0.389755  [    0/   28]\n",
      "loss: 0.389610  [    0/   28]\n",
      "loss: 0.389467  [    0/   28]\n",
      "loss: 0.389322  [    0/   28]\n",
      "loss: 0.389178  [    0/   28]\n",
      "loss: 0.389036  [    0/   28]\n",
      "loss: 0.388890  [    0/   28]\n",
      "loss: 0.388745  [    0/   28]\n",
      "loss: 0.388602  [    0/   28]\n",
      "loss: 0.388459  [    0/   28]\n",
      "loss: 0.388315  [    0/   28]\n",
      "loss: 0.388170  [    0/   28]\n",
      "loss: 0.388025  [    0/   28]\n",
      "loss: 0.387882  [    0/   28]\n",
      "loss: 0.387740  [    0/   28]\n",
      "loss: 0.387594  [    0/   28]\n",
      "loss: 0.387450  [    0/   28]\n",
      "loss: 0.387307  [    0/   28]\n",
      "loss: 0.387162  [    0/   28]\n",
      "loss: 0.387017  [    0/   28]\n",
      "loss: 0.386874  [    0/   28]\n",
      "loss: 0.386730  [    0/   28]\n",
      "loss: 0.386589  [    0/   28]\n",
      "loss: 0.386443  [    0/   28]\n",
      "loss: 0.386300  [    0/   28]\n",
      "loss: 0.386155  [    0/   28]\n",
      "loss: 0.386011  [    0/   28]\n",
      "loss: 0.385866  [    0/   28]\n",
      "loss: 0.385722  [    0/   28]\n",
      "loss: 0.385580  [    0/   28]\n",
      "loss: 0.385435  [    0/   28]\n",
      "loss: 0.385292  [    0/   28]\n",
      "loss: 0.385147  [    0/   28]\n",
      "loss: 0.385005  [    0/   28]\n",
      "loss: 0.384859  [    0/   28]\n",
      "loss: 0.384715  [    0/   28]\n",
      "loss: 0.384574  [    0/   28]\n",
      "loss: 0.384428  [    0/   28]\n",
      "loss: 0.384286  [    0/   28]\n",
      "loss: 0.384142  [    0/   28]\n",
      "loss: 0.383998  [    0/   28]\n",
      "loss: 0.383855  [    0/   28]\n",
      "loss: 0.383711  [    0/   28]\n",
      "loss: 0.383567  [    0/   28]\n",
      "loss: 0.383425  [    0/   28]\n",
      "loss: 0.383279  [    0/   28]\n",
      "loss: 0.383137  [    0/   28]\n",
      "loss: 0.382996  [    0/   28]\n",
      "loss: 0.382849  [    0/   28]\n",
      "loss: 0.382708  [    0/   28]\n",
      "loss: 0.382563  [    0/   28]\n",
      "loss: 0.382422  [    0/   28]\n",
      "loss: 0.382278  [    0/   28]\n",
      "loss: 0.382134  [    0/   28]\n",
      "loss: 0.381991  [    0/   28]\n",
      "loss: 0.381850  [    0/   28]\n",
      "loss: 0.381705  [    0/   28]\n",
      "loss: 0.381564  [    0/   28]\n",
      "loss: 0.381420  [    0/   28]\n",
      "loss: 0.381276  [    0/   28]\n",
      "loss: 0.381135  [    0/   28]\n",
      "loss: 0.380990  [    0/   28]\n",
      "loss: 0.380847  [    0/   28]\n",
      "loss: 0.380703  [    0/   28]\n",
      "loss: 0.380563  [    0/   28]\n",
      "loss: 0.380418  [    0/   28]\n",
      "loss: 0.380274  [    0/   28]\n",
      "loss: 0.380131  [    0/   28]\n",
      "loss: 0.379988  [    0/   28]\n",
      "loss: 0.379845  [    0/   28]\n",
      "loss: 0.379701  [    0/   28]\n",
      "loss: 0.379559  [    0/   28]\n",
      "loss: 0.379416  [    0/   28]\n",
      "loss: 0.379275  [    0/   28]\n",
      "loss: 0.379131  [    0/   28]\n",
      "loss: 0.378987  [    0/   28]\n",
      "loss: 0.378843  [    0/   28]\n",
      "loss: 0.378702  [    0/   28]\n",
      "loss: 0.378558  [    0/   28]\n",
      "loss: 0.378414  [    0/   28]\n",
      "loss: 0.378271  [    0/   28]\n",
      "loss: 0.378129  [    0/   28]\n",
      "loss: 0.377985  [    0/   28]\n",
      "loss: 0.377843  [    0/   28]\n",
      "loss: 0.377700  [    0/   28]\n",
      "loss: 0.377556  [    0/   28]\n",
      "loss: 0.377414  [    0/   28]\n",
      "loss: 0.377270  [    0/   28]\n",
      "loss: 0.377128  [    0/   28]\n",
      "loss: 0.376983  [    0/   28]\n",
      "loss: 0.376841  [    0/   28]\n",
      "loss: 0.376698  [    0/   28]\n",
      "loss: 0.376555  [    0/   28]\n",
      "loss: 0.376411  [    0/   28]\n",
      "loss: 0.376269  [    0/   28]\n",
      "loss: 0.376125  [    0/   28]\n",
      "loss: 0.375982  [    0/   28]\n",
      "loss: 0.375841  [    0/   28]\n",
      "loss: 0.375696  [    0/   28]\n",
      "loss: 0.375554  [    0/   28]\n",
      "loss: 0.375410  [    0/   28]\n",
      "loss: 0.375269  [    0/   28]\n",
      "loss: 0.375123  [    0/   28]\n",
      "loss: 0.374981  [    0/   28]\n",
      "loss: 0.374837  [    0/   28]\n",
      "loss: 0.374695  [    0/   28]\n",
      "loss: 0.374552  [    0/   28]\n",
      "loss: 0.374408  [    0/   28]\n",
      "loss: 0.374265  [    0/   28]\n",
      "loss: 0.374123  [    0/   28]\n",
      "loss: 0.373980  [    0/   28]\n",
      "loss: 0.373837  [    0/   28]\n",
      "loss: 0.373694  [    0/   28]\n",
      "loss: 0.373551  [    0/   28]\n",
      "loss: 0.373407  [    0/   28]\n",
      "loss: 0.373267  [    0/   28]\n",
      "loss: 0.373121  [    0/   28]\n",
      "loss: 0.372979  [    0/   28]\n",
      "loss: 0.372836  [    0/   28]\n",
      "loss: 0.372694  [    0/   28]\n",
      "loss: 0.372549  [    0/   28]\n",
      "loss: 0.372407  [    0/   28]\n",
      "loss: 0.372263  [    0/   28]\n",
      "loss: 0.372123  [    0/   28]\n",
      "loss: 0.371978  [    0/   28]\n",
      "loss: 0.371835  [    0/   28]\n",
      "loss: 0.371692  [    0/   28]\n",
      "loss: 0.371549  [    0/   28]\n",
      "loss: 0.371406  [    0/   28]\n",
      "loss: 0.371262  [    0/   28]\n",
      "loss: 0.371123  [    0/   28]\n",
      "loss: 0.370976  [    0/   28]\n",
      "loss: 0.370835  [    0/   28]\n",
      "loss: 0.370694  [    0/   28]\n",
      "loss: 0.370550  [    0/   28]\n",
      "loss: 0.370406  [    0/   28]\n",
      "loss: 0.370263  [    0/   28]\n",
      "loss: 0.370121  [    0/   28]\n",
      "loss: 0.369978  [    0/   28]\n",
      "loss: 0.369835  [    0/   28]\n",
      "loss: 0.369691  [    0/   28]\n",
      "loss: 0.369549  [    0/   28]\n",
      "loss: 0.369409  [    0/   28]\n",
      "loss: 0.369263  [    0/   28]\n",
      "loss: 0.369122  [    0/   28]\n",
      "loss: 0.368979  [    0/   28]\n",
      "loss: 0.368836  [    0/   28]\n",
      "loss: 0.368694  [    0/   28]\n",
      "loss: 0.368551  [    0/   28]\n",
      "loss: 0.368408  [    0/   28]\n",
      "loss: 0.368265  [    0/   28]\n",
      "loss: 0.368122  [    0/   28]\n",
      "loss: 0.367982  [    0/   28]\n",
      "loss: 0.367836  [    0/   28]\n",
      "loss: 0.367695  [    0/   28]\n",
      "loss: 0.367552  [    0/   28]\n",
      "loss: 0.367411  [    0/   28]\n",
      "loss: 0.367266  [    0/   28]\n",
      "loss: 0.367124  [    0/   28]\n",
      "loss: 0.366982  [    0/   28]\n",
      "loss: 0.366839  [    0/   28]\n",
      "loss: 0.366696  [    0/   28]\n",
      "loss: 0.366554  [    0/   28]\n",
      "loss: 0.366411  [    0/   28]\n",
      "loss: 0.366267  [    0/   28]\n",
      "loss: 0.366125  [    0/   28]\n",
      "loss: 0.365985  [    0/   28]\n",
      "loss: 0.365840  [    0/   28]\n",
      "loss: 0.365697  [    0/   28]\n",
      "loss: 0.365556  [    0/   28]\n",
      "loss: 0.365412  [    0/   28]\n",
      "loss: 0.365270  [    0/   28]\n",
      "loss: 0.365127  [    0/   28]\n",
      "loss: 0.364983  [    0/   28]\n",
      "loss: 0.364840  [    0/   28]\n",
      "loss: 0.364700  [    0/   28]\n",
      "loss: 0.364556  [    0/   28]\n",
      "loss: 0.364413  [    0/   28]\n",
      "loss: 0.364272  [    0/   28]\n",
      "loss: 0.364128  [    0/   28]\n",
      "loss: 0.363984  [    0/   28]\n",
      "loss: 0.363841  [    0/   28]\n",
      "loss: 0.363698  [    0/   28]\n",
      "loss: 0.363557  [    0/   28]\n",
      "loss: 0.363414  [    0/   28]\n",
      "loss: 0.363270  [    0/   28]\n",
      "loss: 0.363126  [    0/   28]\n",
      "loss: 0.362984  [    0/   28]\n",
      "loss: 0.362844  [    0/   28]\n",
      "loss: 0.362699  [    0/   28]\n",
      "loss: 0.362556  [    0/   28]\n",
      "loss: 0.362415  [    0/   28]\n",
      "loss: 0.362270  [    0/   28]\n",
      "loss: 0.362129  [    0/   28]\n",
      "loss: 0.361985  [    0/   28]\n",
      "loss: 0.361843  [    0/   28]\n",
      "loss: 0.361700  [    0/   28]\n",
      "loss: 0.361558  [    0/   28]\n",
      "loss: 0.361415  [    0/   28]\n",
      "loss: 0.361272  [    0/   28]\n",
      "loss: 0.361129  [    0/   28]\n",
      "loss: 0.360986  [    0/   28]\n",
      "loss: 0.360846  [    0/   28]\n",
      "loss: 0.360700  [    0/   28]\n",
      "loss: 0.360558  [    0/   28]\n",
      "loss: 0.360415  [    0/   28]\n",
      "loss: 0.360274  [    0/   28]\n",
      "loss: 0.360131  [    0/   28]\n",
      "loss: 0.359988  [    0/   28]\n",
      "loss: 0.359844  [    0/   28]\n",
      "loss: 0.359703  [    0/   28]\n",
      "loss: 0.359560  [    0/   28]\n",
      "loss: 0.359418  [    0/   28]\n",
      "loss: 0.359274  [    0/   28]\n",
      "loss: 0.359131  [    0/   28]\n",
      "loss: 0.358989  [    0/   28]\n",
      "loss: 0.358848  [    0/   28]\n",
      "loss: 0.358706  [    0/   28]\n",
      "loss: 0.358561  [    0/   28]\n",
      "loss: 0.358419  [    0/   28]\n",
      "loss: 0.358278  [    0/   28]\n",
      "loss: 0.358134  [    0/   28]\n",
      "loss: 0.357993  [    0/   28]\n",
      "loss: 0.357850  [    0/   28]\n",
      "loss: 0.357710  [    0/   28]\n",
      "loss: 0.357565  [    0/   28]\n",
      "loss: 0.357424  [    0/   28]\n",
      "loss: 0.357281  [    0/   28]\n",
      "loss: 0.357138  [    0/   28]\n",
      "loss: 0.356995  [    0/   28]\n",
      "loss: 0.356856  [    0/   28]\n",
      "loss: 0.356711  [    0/   28]\n",
      "loss: 0.356570  [    0/   28]\n",
      "loss: 0.356426  [    0/   28]\n",
      "loss: 0.356287  [    0/   28]\n",
      "loss: 0.356143  [    0/   28]\n",
      "loss: 0.356002  [    0/   28]\n",
      "loss: 0.355858  [    0/   28]\n",
      "loss: 0.355718  [    0/   28]\n",
      "loss: 0.355575  [    0/   28]\n",
      "loss: 0.355435  [    0/   28]\n",
      "loss: 0.355290  [    0/   28]\n",
      "loss: 0.355148  [    0/   28]\n",
      "loss: 0.355007  [    0/   28]\n",
      "loss: 0.354867  [    0/   28]\n",
      "loss: 0.354722  [    0/   28]\n",
      "loss: 0.354580  [    0/   28]\n",
      "loss: 0.354440  [    0/   28]\n",
      "loss: 0.354300  [    0/   28]\n",
      "loss: 0.354155  [    0/   28]\n",
      "loss: 0.354014  [    0/   28]\n",
      "loss: 0.353872  [    0/   28]\n",
      "loss: 0.353732  [    0/   28]\n",
      "loss: 0.353588  [    0/   28]\n",
      "loss: 0.353449  [    0/   28]\n",
      "loss: 0.353304  [    0/   28]\n",
      "loss: 0.353162  [    0/   28]\n",
      "loss: 0.353020  [    0/   28]\n",
      "loss: 0.352881  [    0/   28]\n",
      "loss: 0.352739  [    0/   28]\n",
      "loss: 0.352596  [    0/   28]\n",
      "loss: 0.352454  [    0/   28]\n",
      "loss: 0.352313  [    0/   28]\n",
      "loss: 0.352171  [    0/   28]\n",
      "loss: 0.352030  [    0/   28]\n",
      "loss: 0.351888  [    0/   28]\n",
      "loss: 0.351747  [    0/   28]\n",
      "loss: 0.351605  [    0/   28]\n",
      "loss: 0.351463  [    0/   28]\n",
      "loss: 0.351321  [    0/   28]\n",
      "loss: 0.351180  [    0/   28]\n",
      "loss: 0.351039  [    0/   28]\n",
      "loss: 0.350898  [    0/   28]\n",
      "loss: 0.350755  [    0/   28]\n",
      "loss: 0.350614  [    0/   28]\n",
      "loss: 0.350473  [    0/   28]\n",
      "loss: 0.350330  [    0/   28]\n",
      "loss: 0.350190  [    0/   28]\n",
      "loss: 0.350048  [    0/   28]\n",
      "loss: 0.349905  [    0/   28]\n",
      "loss: 0.349764  [    0/   28]\n",
      "loss: 0.349624  [    0/   28]\n",
      "loss: 0.349483  [    0/   28]\n",
      "loss: 0.349341  [    0/   28]\n",
      "loss: 0.349200  [    0/   28]\n",
      "loss: 0.349057  [    0/   28]\n",
      "loss: 0.348917  [    0/   28]\n",
      "loss: 0.348774  [    0/   28]\n",
      "loss: 0.348633  [    0/   28]\n",
      "loss: 0.348493  [    0/   28]\n",
      "loss: 0.348350  [    0/   28]\n",
      "loss: 0.348208  [    0/   28]\n",
      "loss: 0.348068  [    0/   28]\n",
      "loss: 0.347927  [    0/   28]\n",
      "loss: 0.347786  [    0/   28]\n",
      "loss: 0.347645  [    0/   28]\n",
      "loss: 0.347503  [    0/   28]\n",
      "loss: 0.347362  [    0/   28]\n",
      "loss: 0.347220  [    0/   28]\n",
      "loss: 0.347078  [    0/   28]\n",
      "loss: 0.346940  [    0/   28]\n",
      "loss: 0.346797  [    0/   28]\n",
      "loss: 0.346657  [    0/   28]\n",
      "loss: 0.346515  [    0/   28]\n",
      "loss: 0.346375  [    0/   28]\n",
      "loss: 0.346233  [    0/   28]\n",
      "loss: 0.346091  [    0/   28]\n",
      "loss: 0.345950  [    0/   28]\n",
      "loss: 0.345812  [    0/   28]\n",
      "loss: 0.345668  [    0/   28]\n",
      "loss: 0.345526  [    0/   28]\n",
      "loss: 0.345385  [    0/   28]\n",
      "loss: 0.345246  [    0/   28]\n",
      "loss: 0.345104  [    0/   28]\n",
      "loss: 0.344965  [    0/   28]\n",
      "loss: 0.344823  [    0/   28]\n",
      "loss: 0.344681  [    0/   28]\n",
      "loss: 0.344542  [    0/   28]\n",
      "loss: 0.344402  [    0/   28]\n",
      "loss: 0.344261  [    0/   28]\n",
      "loss: 0.344120  [    0/   28]\n",
      "loss: 0.343977  [    0/   28]\n",
      "loss: 0.343840  [    0/   28]\n",
      "loss: 0.343696  [    0/   28]\n",
      "loss: 0.343557  [    0/   28]\n",
      "loss: 0.343417  [    0/   28]\n",
      "loss: 0.343275  [    0/   28]\n",
      "loss: 0.343135  [    0/   28]\n",
      "loss: 0.342994  [    0/   28]\n",
      "loss: 0.342854  [    0/   28]\n",
      "loss: 0.342712  [    0/   28]\n",
      "loss: 0.342573  [    0/   28]\n",
      "loss: 0.342432  [    0/   28]\n",
      "loss: 0.342291  [    0/   28]\n",
      "loss: 0.342151  [    0/   28]\n",
      "loss: 0.342009  [    0/   28]\n",
      "loss: 0.341869  [    0/   28]\n",
      "loss: 0.341729  [    0/   28]\n",
      "loss: 0.341589  [    0/   28]\n",
      "loss: 0.341450  [    0/   28]\n",
      "loss: 0.341309  [    0/   28]\n",
      "loss: 0.341171  [    0/   28]\n",
      "loss: 0.341027  [    0/   28]\n",
      "loss: 0.340888  [    0/   28]\n",
      "loss: 0.340747  [    0/   28]\n",
      "loss: 0.340609  [    0/   28]\n",
      "loss: 0.340470  [    0/   28]\n",
      "loss: 0.340329  [    0/   28]\n",
      "loss: 0.340188  [    0/   28]\n",
      "loss: 0.340051  [    0/   28]\n",
      "loss: 0.339910  [    0/   28]\n",
      "loss: 0.339770  [    0/   28]\n",
      "loss: 0.339633  [    0/   28]\n",
      "loss: 0.339490  [    0/   28]\n",
      "loss: 0.339352  [    0/   28]\n",
      "loss: 0.339213  [    0/   28]\n",
      "loss: 0.339074  [    0/   28]\n",
      "loss: 0.338933  [    0/   28]\n",
      "loss: 0.338792  [    0/   28]\n",
      "loss: 0.338655  [    0/   28]\n",
      "loss: 0.338516  [    0/   28]\n",
      "loss: 0.338376  [    0/   28]\n",
      "loss: 0.338236  [    0/   28]\n",
      "loss: 0.338097  [    0/   28]\n",
      "loss: 0.337958  [    0/   28]\n",
      "loss: 0.337822  [    0/   28]\n",
      "loss: 0.337678  [    0/   28]\n",
      "loss: 0.337539  [    0/   28]\n",
      "loss: 0.337401  [    0/   28]\n",
      "loss: 0.337263  [    0/   28]\n",
      "loss: 0.337123  [    0/   28]\n",
      "loss: 0.336984  [    0/   28]\n",
      "loss: 0.336845  [    0/   28]\n",
      "loss: 0.336704  [    0/   28]\n",
      "loss: 0.336566  [    0/   28]\n",
      "loss: 0.336429  [    0/   28]\n",
      "loss: 0.336288  [    0/   28]\n",
      "loss: 0.336150  [    0/   28]\n",
      "loss: 0.336012  [    0/   28]\n",
      "loss: 0.335872  [    0/   28]\n",
      "loss: 0.335733  [    0/   28]\n",
      "loss: 0.335594  [    0/   28]\n",
      "loss: 0.335453  [    0/   28]\n",
      "loss: 0.335317  [    0/   28]\n",
      "loss: 0.335179  [    0/   28]\n",
      "loss: 0.335037  [    0/   28]\n",
      "loss: 0.334900  [    0/   28]\n",
      "loss: 0.334760  [    0/   28]\n",
      "loss: 0.334624  [    0/   28]\n",
      "loss: 0.334483  [    0/   28]\n",
      "loss: 0.334345  [    0/   28]\n",
      "loss: 0.334206  [    0/   28]\n",
      "loss: 0.334068  [    0/   28]\n",
      "loss: 0.333929  [    0/   28]\n",
      "loss: 0.333789  [    0/   28]\n",
      "loss: 0.333651  [    0/   28]\n",
      "loss: 0.333513  [    0/   28]\n",
      "loss: 0.333376  [    0/   28]\n",
      "loss: 0.333236  [    0/   28]\n",
      "loss: 0.333097  [    0/   28]\n",
      "loss: 0.332959  [    0/   28]\n",
      "loss: 0.332820  [    0/   28]\n",
      "loss: 0.332684  [    0/   28]\n",
      "loss: 0.332544  [    0/   28]\n",
      "loss: 0.332404  [    0/   28]\n",
      "loss: 0.332265  [    0/   28]\n",
      "loss: 0.332127  [    0/   28]\n",
      "loss: 0.331992  [    0/   28]\n",
      "loss: 0.331851  [    0/   28]\n",
      "loss: 0.331713  [    0/   28]\n",
      "loss: 0.331575  [    0/   28]\n",
      "loss: 0.331438  [    0/   28]\n",
      "loss: 0.331299  [    0/   28]\n",
      "loss: 0.331158  [    0/   28]\n",
      "loss: 0.331023  [    0/   28]\n",
      "loss: 0.330883  [    0/   28]\n",
      "loss: 0.330748  [    0/   28]\n",
      "loss: 0.330606  [    0/   28]\n",
      "loss: 0.330470  [    0/   28]\n",
      "loss: 0.330332  [    0/   28]\n",
      "loss: 0.330193  [    0/   28]\n",
      "loss: 0.330054  [    0/   28]\n",
      "loss: 0.329920  [    0/   28]\n",
      "loss: 0.329778  [    0/   28]\n",
      "loss: 0.329640  [    0/   28]\n",
      "loss: 0.329502  [    0/   28]\n",
      "loss: 0.329366  [    0/   28]\n",
      "loss: 0.329229  [    0/   28]\n",
      "loss: 0.329090  [    0/   28]\n",
      "loss: 0.328953  [    0/   28]\n",
      "loss: 0.328814  [    0/   28]\n",
      "loss: 0.328677  [    0/   28]\n",
      "loss: 0.328539  [    0/   28]\n",
      "loss: 0.328401  [    0/   28]\n",
      "loss: 0.328264  [    0/   28]\n",
      "loss: 0.328126  [    0/   28]\n",
      "loss: 0.327987  [    0/   28]\n",
      "loss: 0.327850  [    0/   28]\n",
      "loss: 0.327715  [    0/   28]\n",
      "loss: 0.327577  [    0/   28]\n",
      "loss: 0.327438  [    0/   28]\n",
      "loss: 0.327302  [    0/   28]\n",
      "loss: 0.327164  [    0/   28]\n",
      "loss: 0.327027  [    0/   28]\n",
      "loss: 0.326890  [    0/   28]\n",
      "loss: 0.326752  [    0/   28]\n",
      "loss: 0.326616  [    0/   28]\n",
      "loss: 0.326477  [    0/   28]\n",
      "loss: 0.326340  [    0/   28]\n",
      "loss: 0.326203  [    0/   28]\n",
      "loss: 0.326067  [    0/   28]\n",
      "loss: 0.325932  [    0/   28]\n",
      "loss: 0.325791  [    0/   28]\n",
      "loss: 0.325658  [    0/   28]\n",
      "loss: 0.325518  [    0/   28]\n",
      "loss: 0.325382  [    0/   28]\n",
      "loss: 0.325245  [    0/   28]\n",
      "loss: 0.325109  [    0/   28]\n",
      "loss: 0.324973  [    0/   28]\n",
      "loss: 0.324837  [    0/   28]\n",
      "loss: 0.324699  [    0/   28]\n",
      "loss: 0.324561  [    0/   28]\n",
      "loss: 0.324426  [    0/   28]\n",
      "loss: 0.324289  [    0/   28]\n",
      "loss: 0.324154  [    0/   28]\n",
      "loss: 0.324016  [    0/   28]\n",
      "loss: 0.323879  [    0/   28]\n",
      "loss: 0.323744  [    0/   28]\n",
      "loss: 0.323608  [    0/   28]\n",
      "loss: 0.323472  [    0/   28]\n",
      "loss: 0.323334  [    0/   28]\n",
      "loss: 0.323198  [    0/   28]\n",
      "loss: 0.323062  [    0/   28]\n",
      "loss: 0.322927  [    0/   28]\n",
      "loss: 0.322790  [    0/   28]\n",
      "loss: 0.322652  [    0/   28]\n",
      "loss: 0.322517  [    0/   28]\n",
      "loss: 0.322382  [    0/   28]\n",
      "loss: 0.322245  [    0/   28]\n",
      "loss: 0.322109  [    0/   28]\n",
      "loss: 0.321972  [    0/   28]\n",
      "loss: 0.321834  [    0/   28]\n",
      "loss: 0.321700  [    0/   28]\n",
      "loss: 0.321566  [    0/   28]\n",
      "loss: 0.321428  [    0/   28]\n",
      "loss: 0.321293  [    0/   28]\n",
      "loss: 0.321156  [    0/   28]\n",
      "loss: 0.321022  [    0/   28]\n",
      "loss: 0.320884  [    0/   28]\n",
      "loss: 0.320748  [    0/   28]\n",
      "loss: 0.320612  [    0/   28]\n",
      "loss: 0.320479  [    0/   28]\n",
      "loss: 0.320341  [    0/   28]\n",
      "loss: 0.320206  [    0/   28]\n",
      "loss: 0.320068  [    0/   28]\n",
      "loss: 0.319933  [    0/   28]\n",
      "loss: 0.319798  [    0/   28]\n",
      "loss: 0.319664  [    0/   28]\n",
      "loss: 0.319527  [    0/   28]\n",
      "loss: 0.319392  [    0/   28]\n",
      "loss: 0.319255  [    0/   28]\n",
      "loss: 0.319120  [    0/   28]\n",
      "loss: 0.318986  [    0/   28]\n",
      "loss: 0.318847  [    0/   28]\n",
      "loss: 0.318714  [    0/   28]\n",
      "loss: 0.318579  [    0/   28]\n",
      "loss: 0.318441  [    0/   28]\n",
      "loss: 0.318307  [    0/   28]\n",
      "loss: 0.318170  [    0/   28]\n",
      "loss: 0.318035  [    0/   28]\n",
      "loss: 0.317899  [    0/   28]\n",
      "loss: 0.317764  [    0/   28]\n",
      "loss: 0.317630  [    0/   28]\n",
      "loss: 0.317495  [    0/   28]\n",
      "loss: 0.317358  [    0/   28]\n",
      "loss: 0.317224  [    0/   28]\n",
      "loss: 0.317090  [    0/   28]\n",
      "loss: 0.316954  [    0/   28]\n",
      "loss: 0.316817  [    0/   28]\n",
      "loss: 0.316683  [    0/   28]\n",
      "loss: 0.316548  [    0/   28]\n",
      "loss: 0.316414  [    0/   28]\n",
      "loss: 0.316276  [    0/   28]\n",
      "loss: 0.316142  [    0/   28]\n",
      "loss: 0.316007  [    0/   28]\n",
      "loss: 0.315871  [    0/   28]\n",
      "loss: 0.315738  [    0/   28]\n",
      "loss: 0.315602  [    0/   28]\n",
      "loss: 0.315467  [    0/   28]\n",
      "loss: 0.315332  [    0/   28]\n",
      "loss: 0.315197  [    0/   28]\n",
      "loss: 0.315064  [    0/   28]\n",
      "loss: 0.314928  [    0/   28]\n",
      "loss: 0.314792  [    0/   28]\n",
      "loss: 0.314657  [    0/   28]\n",
      "loss: 0.314524  [    0/   28]\n",
      "loss: 0.314386  [    0/   28]\n",
      "loss: 0.314252  [    0/   28]\n",
      "loss: 0.314118  [    0/   28]\n",
      "loss: 0.313984  [    0/   28]\n",
      "loss: 0.313850  [    0/   28]\n",
      "loss: 0.313715  [    0/   28]\n",
      "loss: 0.313578  [    0/   28]\n",
      "loss: 0.313445  [    0/   28]\n",
      "loss: 0.313311  [    0/   28]\n",
      "loss: 0.313178  [    0/   28]\n",
      "loss: 0.313040  [    0/   28]\n",
      "loss: 0.312909  [    0/   28]\n",
      "loss: 0.312773  [    0/   28]\n",
      "loss: 0.312640  [    0/   28]\n",
      "loss: 0.312503  [    0/   28]\n",
      "loss: 0.312370  [    0/   28]\n",
      "loss: 0.312236  [    0/   28]\n",
      "loss: 0.312103  [    0/   28]\n",
      "loss: 0.311966  [    0/   28]\n",
      "loss: 0.311832  [    0/   28]\n",
      "loss: 0.311698  [    0/   28]\n",
      "loss: 0.311564  [    0/   28]\n",
      "loss: 0.311429  [    0/   28]\n",
      "loss: 0.311295  [    0/   28]\n",
      "loss: 0.311162  [    0/   28]\n",
      "loss: 0.311027  [    0/   28]\n",
      "loss: 0.310895  [    0/   28]\n",
      "loss: 0.310758  [    0/   28]\n",
      "loss: 0.310626  [    0/   28]\n",
      "loss: 0.310492  [    0/   28]\n",
      "loss: 0.310356  [    0/   28]\n",
      "loss: 0.310224  [    0/   28]\n",
      "loss: 0.310088  [    0/   28]\n",
      "loss: 0.309957  [    0/   28]\n",
      "loss: 0.309822  [    0/   28]\n",
      "loss: 0.309685  [    0/   28]\n",
      "loss: 0.309554  [    0/   28]\n",
      "loss: 0.309420  [    0/   28]\n",
      "loss: 0.309286  [    0/   28]\n",
      "loss: 0.309151  [    0/   28]\n",
      "loss: 0.309019  [    0/   28]\n",
      "loss: 0.308884  [    0/   28]\n",
      "loss: 0.308750  [    0/   28]\n",
      "loss: 0.308617  [    0/   28]\n",
      "loss: 0.308482  [    0/   28]\n",
      "loss: 0.308348  [    0/   28]\n",
      "loss: 0.308216  [    0/   28]\n",
      "loss: 0.308084  [    0/   28]\n",
      "loss: 0.307949  [    0/   28]\n",
      "loss: 0.307816  [    0/   28]\n",
      "loss: 0.307682  [    0/   28]\n",
      "loss: 0.307547  [    0/   28]\n",
      "loss: 0.307415  [    0/   28]\n",
      "loss: 0.307280  [    0/   28]\n",
      "loss: 0.307148  [    0/   28]\n",
      "loss: 0.307014  [    0/   28]\n",
      "loss: 0.306883  [    0/   28]\n",
      "loss: 0.306749  [    0/   28]\n",
      "loss: 0.306615  [    0/   28]\n",
      "loss: 0.306482  [    0/   28]\n",
      "loss: 0.306348  [    0/   28]\n",
      "loss: 0.306217  [    0/   28]\n",
      "loss: 0.306083  [    0/   28]\n",
      "loss: 0.305949  [    0/   28]\n",
      "loss: 0.305817  [    0/   28]\n",
      "loss: 0.305683  [    0/   28]\n",
      "loss: 0.305553  [    0/   28]\n",
      "loss: 0.305417  [    0/   28]\n",
      "loss: 0.305285  [    0/   28]\n",
      "loss: 0.305152  [    0/   28]\n",
      "loss: 0.305020  [    0/   28]\n",
      "loss: 0.304885  [    0/   28]\n",
      "loss: 0.304752  [    0/   28]\n",
      "loss: 0.304619  [    0/   28]\n",
      "loss: 0.304489  [    0/   28]\n",
      "loss: 0.304356  [    0/   28]\n",
      "loss: 0.304221  [    0/   28]\n",
      "loss: 0.304092  [    0/   28]\n",
      "loss: 0.303958  [    0/   28]\n",
      "loss: 0.303827  [    0/   28]\n",
      "loss: 0.303691  [    0/   28]\n",
      "loss: 0.303559  [    0/   28]\n",
      "loss: 0.303426  [    0/   28]\n",
      "loss: 0.303296  [    0/   28]\n",
      "loss: 0.303165  [    0/   28]\n",
      "loss: 0.303032  [    0/   28]\n",
      "loss: 0.302898  [    0/   28]\n",
      "loss: 0.302764  [    0/   28]\n",
      "loss: 0.302635  [    0/   28]\n",
      "loss: 0.302501  [    0/   28]\n",
      "loss: 0.302369  [    0/   28]\n",
      "loss: 0.302239  [    0/   28]\n",
      "loss: 0.302103  [    0/   28]\n",
      "loss: 0.301973  [    0/   28]\n",
      "loss: 0.301842  [    0/   28]\n",
      "loss: 0.301713  [    0/   28]\n",
      "loss: 0.301578  [    0/   28]\n",
      "loss: 0.301447  [    0/   28]\n",
      "loss: 0.301316  [    0/   28]\n",
      "loss: 0.301184  [    0/   28]\n",
      "loss: 0.301051  [    0/   28]\n",
      "loss: 0.300920  [    0/   28]\n",
      "loss: 0.300789  [    0/   28]\n",
      "loss: 0.300656  [    0/   28]\n",
      "loss: 0.300525  [    0/   28]\n",
      "loss: 0.300393  [    0/   28]\n",
      "loss: 0.300263  [    0/   28]\n",
      "loss: 0.300131  [    0/   28]\n",
      "loss: 0.300002  [    0/   28]\n",
      "loss: 0.299867  [    0/   28]\n",
      "loss: 0.299738  [    0/   28]\n",
      "loss: 0.299606  [    0/   28]\n",
      "loss: 0.299477  [    0/   28]\n",
      "loss: 0.299344  [    0/   28]\n",
      "loss: 0.299214  [    0/   28]\n",
      "loss: 0.299082  [    0/   28]\n",
      "loss: 0.298952  [    0/   28]\n",
      "loss: 0.298819  [    0/   28]\n",
      "loss: 0.298689  [    0/   28]\n",
      "loss: 0.298562  [    0/   28]\n",
      "loss: 0.298428  [    0/   28]\n",
      "loss: 0.298296  [    0/   28]\n",
      "loss: 0.298170  [    0/   28]\n",
      "loss: 0.298035  [    0/   28]\n",
      "loss: 0.297906  [    0/   28]\n",
      "loss: 0.297774  [    0/   28]\n",
      "loss: 0.297644  [    0/   28]\n",
      "loss: 0.297513  [    0/   28]\n",
      "loss: 0.297384  [    0/   28]\n",
      "loss: 0.297251  [    0/   28]\n",
      "loss: 0.297121  [    0/   28]\n",
      "loss: 0.296990  [    0/   28]\n",
      "loss: 0.296863  [    0/   28]\n",
      "loss: 0.296729  [    0/   28]\n",
      "loss: 0.296598  [    0/   28]\n",
      "loss: 0.296470  [    0/   28]\n",
      "loss: 0.296337  [    0/   28]\n",
      "loss: 0.296209  [    0/   28]\n",
      "loss: 0.296078  [    0/   28]\n",
      "loss: 0.295950  [    0/   28]\n",
      "loss: 0.295817  [    0/   28]\n",
      "loss: 0.295689  [    0/   28]\n",
      "loss: 0.295557  [    0/   28]\n",
      "loss: 0.295427  [    0/   28]\n",
      "loss: 0.295298  [    0/   28]\n",
      "loss: 0.295166  [    0/   28]\n",
      "loss: 0.295039  [    0/   28]\n",
      "loss: 0.294910  [    0/   28]\n",
      "loss: 0.294778  [    0/   28]\n",
      "loss: 0.294646  [    0/   28]\n",
      "loss: 0.294520  [    0/   28]\n",
      "loss: 0.294389  [    0/   28]\n",
      "loss: 0.294258  [    0/   28]\n",
      "loss: 0.294129  [    0/   28]\n",
      "loss: 0.293997  [    0/   28]\n",
      "loss: 0.293866  [    0/   28]\n",
      "loss: 0.293737  [    0/   28]\n",
      "loss: 0.293607  [    0/   28]\n",
      "loss: 0.293481  [    0/   28]\n",
      "loss: 0.293350  [    0/   28]\n",
      "loss: 0.293219  [    0/   28]\n",
      "loss: 0.293092  [    0/   28]\n",
      "loss: 0.292961  [    0/   28]\n",
      "loss: 0.292834  [    0/   28]\n",
      "loss: 0.292701  [    0/   28]\n",
      "loss: 0.292573  [    0/   28]\n",
      "loss: 0.292445  [    0/   28]\n",
      "loss: 0.292314  [    0/   28]\n",
      "loss: 0.292183  [    0/   28]\n",
      "loss: 0.292057  [    0/   28]\n",
      "loss: 0.291929  [    0/   28]\n",
      "loss: 0.291799  [    0/   28]\n",
      "loss: 0.291667  [    0/   28]\n",
      "loss: 0.291537  [    0/   28]\n",
      "loss: 0.291411  [    0/   28]\n",
      "loss: 0.291283  [    0/   28]\n",
      "loss: 0.291152  [    0/   28]\n",
      "loss: 0.291023  [    0/   28]\n",
      "loss: 0.290896  [    0/   28]\n",
      "loss: 0.290764  [    0/   28]\n",
      "loss: 0.290637  [    0/   28]\n",
      "loss: 0.290507  [    0/   28]\n",
      "loss: 0.290382  [    0/   28]\n",
      "loss: 0.290250  [    0/   28]\n",
      "loss: 0.290122  [    0/   28]\n",
      "loss: 0.289994  [    0/   28]\n",
      "loss: 0.289867  [    0/   28]\n",
      "loss: 0.289736  [    0/   28]\n",
      "loss: 0.289608  [    0/   28]\n",
      "loss: 0.289480  [    0/   28]\n",
      "loss: 0.289350  [    0/   28]\n",
      "loss: 0.289224  [    0/   28]\n",
      "loss: 0.289096  [    0/   28]\n",
      "loss: 0.288966  [    0/   28]\n",
      "loss: 0.288837  [    0/   28]\n",
      "loss: 0.288710  [    0/   28]\n",
      "loss: 0.288583  [    0/   28]\n",
      "loss: 0.288454  [    0/   28]\n",
      "loss: 0.288324  [    0/   28]\n",
      "loss: 0.288197  [    0/   28]\n",
      "loss: 0.288070  [    0/   28]\n",
      "loss: 0.287944  [    0/   28]\n",
      "loss: 0.287813  [    0/   28]\n",
      "loss: 0.287686  [    0/   28]\n",
      "loss: 0.287562  [    0/   28]\n",
      "loss: 0.287431  [    0/   28]\n",
      "loss: 0.287303  [    0/   28]\n",
      "loss: 0.287176  [    0/   28]\n",
      "loss: 0.287050  [    0/   28]\n",
      "loss: 0.286921  [    0/   28]\n",
      "loss: 0.286793  [    0/   28]\n",
      "loss: 0.286668  [    0/   28]\n",
      "loss: 0.286538  [    0/   28]\n",
      "loss: 0.286411  [    0/   28]\n",
      "loss: 0.286283  [    0/   28]\n",
      "loss: 0.286157  [    0/   28]\n",
      "loss: 0.286030  [    0/   28]\n",
      "loss: 0.285902  [    0/   28]\n",
      "loss: 0.285773  [    0/   28]\n",
      "loss: 0.285647  [    0/   28]\n",
      "loss: 0.285519  [    0/   28]\n",
      "loss: 0.285394  [    0/   28]\n",
      "loss: 0.285266  [    0/   28]\n",
      "loss: 0.285140  [    0/   28]\n",
      "loss: 0.285013  [    0/   28]\n",
      "loss: 0.284884  [    0/   28]\n",
      "loss: 0.284759  [    0/   28]\n",
      "loss: 0.284632  [    0/   28]\n",
      "loss: 0.284504  [    0/   28]\n",
      "loss: 0.284376  [    0/   28]\n",
      "loss: 0.284252  [    0/   28]\n",
      "loss: 0.284123  [    0/   28]\n",
      "loss: 0.283997  [    0/   28]\n",
      "loss: 0.283872  [    0/   28]\n",
      "loss: 0.283744  [    0/   28]\n",
      "loss: 0.283618  [    0/   28]\n",
      "loss: 0.283489  [    0/   28]\n",
      "loss: 0.283365  [    0/   28]\n",
      "loss: 0.283237  [    0/   28]\n",
      "loss: 0.283111  [    0/   28]\n",
      "loss: 0.282983  [    0/   28]\n",
      "loss: 0.282856  [    0/   28]\n",
      "loss: 0.282729  [    0/   28]\n",
      "loss: 0.282606  [    0/   28]\n",
      "loss: 0.282477  [    0/   28]\n",
      "loss: 0.282350  [    0/   28]\n",
      "loss: 0.282224  [    0/   28]\n",
      "loss: 0.282099  [    0/   28]\n",
      "loss: 0.281968  [    0/   28]\n",
      "loss: 0.281844  [    0/   28]\n",
      "loss: 0.281717  [    0/   28]\n",
      "loss: 0.281594  [    0/   28]\n",
      "loss: 0.281466  [    0/   28]\n",
      "loss: 0.281339  [    0/   28]\n",
      "loss: 0.281213  [    0/   28]\n",
      "loss: 0.281089  [    0/   28]\n",
      "loss: 0.280962  [    0/   28]\n",
      "loss: 0.280837  [    0/   28]\n",
      "loss: 0.280711  [    0/   28]\n",
      "loss: 0.280585  [    0/   28]\n",
      "loss: 0.280459  [    0/   28]\n",
      "loss: 0.280334  [    0/   28]\n",
      "loss: 0.280207  [    0/   28]\n",
      "loss: 0.280079  [    0/   28]\n",
      "loss: 0.279956  [    0/   28]\n",
      "loss: 0.279831  [    0/   28]\n",
      "loss: 0.279704  [    0/   28]\n",
      "loss: 0.279578  [    0/   28]\n",
      "loss: 0.279452  [    0/   28]\n",
      "loss: 0.279330  [    0/   28]\n",
      "loss: 0.279202  [    0/   28]\n",
      "loss: 0.279079  [    0/   28]\n",
      "loss: 0.278950  [    0/   28]\n",
      "loss: 0.278825  [    0/   28]\n",
      "loss: 0.278701  [    0/   28]\n",
      "loss: 0.278577  [    0/   28]\n",
      "loss: 0.278450  [    0/   28]\n",
      "loss: 0.278324  [    0/   28]\n",
      "loss: 0.278199  [    0/   28]\n",
      "loss: 0.278074  [    0/   28]\n",
      "loss: 0.277952  [    0/   28]\n",
      "loss: 0.277826  [    0/   28]\n",
      "loss: 0.277702  [    0/   28]\n",
      "loss: 0.277574  [    0/   28]\n",
      "loss: 0.277451  [    0/   28]\n",
      "loss: 0.277326  [    0/   28]\n",
      "loss: 0.277201  [    0/   28]\n",
      "loss: 0.277075  [    0/   28]\n",
      "loss: 0.276953  [    0/   28]\n",
      "loss: 0.276827  [    0/   28]\n",
      "loss: 0.276705  [    0/   28]\n",
      "loss: 0.276577  [    0/   28]\n",
      "loss: 0.276452  [    0/   28]\n",
      "loss: 0.276330  [    0/   28]\n",
      "loss: 0.276206  [    0/   28]\n",
      "loss: 0.276081  [    0/   28]\n",
      "loss: 0.275959  [    0/   28]\n",
      "loss: 0.275832  [    0/   28]\n",
      "loss: 0.275707  [    0/   28]\n",
      "loss: 0.275582  [    0/   28]\n",
      "loss: 0.275459  [    0/   28]\n",
      "loss: 0.275335  [    0/   28]\n",
      "loss: 0.275211  [    0/   28]\n",
      "loss: 0.275085  [    0/   28]\n",
      "loss: 0.274961  [    0/   28]\n",
      "loss: 0.274840  [    0/   28]\n",
      "loss: 0.274712  [    0/   28]\n",
      "loss: 0.274593  [    0/   28]\n",
      "loss: 0.274466  [    0/   28]\n",
      "loss: 0.274343  [    0/   28]\n",
      "loss: 0.274219  [    0/   28]\n",
      "loss: 0.274096  [    0/   28]\n",
      "loss: 0.273973  [    0/   28]\n",
      "loss: 0.273847  [    0/   28]\n",
      "loss: 0.273724  [    0/   28]\n",
      "loss: 0.273599  [    0/   28]\n",
      "loss: 0.273477  [    0/   28]\n",
      "loss: 0.273354  [    0/   28]\n",
      "loss: 0.273229  [    0/   28]\n",
      "loss: 0.273108  [    0/   28]\n",
      "loss: 0.272983  [    0/   28]\n",
      "loss: 0.272858  [    0/   28]\n",
      "loss: 0.272737  [    0/   28]\n",
      "loss: 0.272614  [    0/   28]\n",
      "loss: 0.272489  [    0/   28]\n",
      "loss: 0.272365  [    0/   28]\n",
      "loss: 0.272244  [    0/   28]\n",
      "loss: 0.272119  [    0/   28]\n",
      "loss: 0.272001  [    0/   28]\n",
      "loss: 0.271873  [    0/   28]\n",
      "loss: 0.271751  [    0/   28]\n",
      "loss: 0.271628  [    0/   28]\n",
      "loss: 0.271506  [    0/   28]\n",
      "loss: 0.271385  [    0/   28]\n",
      "loss: 0.271259  [    0/   28]\n",
      "loss: 0.271138  [    0/   28]\n",
      "loss: 0.271012  [    0/   28]\n",
      "loss: 0.270891  [    0/   28]\n",
      "loss: 0.270771  [    0/   28]\n",
      "loss: 0.270647  [    0/   28]\n",
      "loss: 0.270526  [    0/   28]\n",
      "loss: 0.270401  [    0/   28]\n",
      "loss: 0.270279  [    0/   28]\n",
      "loss: 0.270156  [    0/   28]\n",
      "loss: 0.270036  [    0/   28]\n",
      "loss: 0.269912  [    0/   28]\n",
      "loss: 0.269790  [    0/   28]\n",
      "loss: 0.269667  [    0/   28]\n",
      "loss: 0.269547  [    0/   28]\n",
      "loss: 0.269425  [    0/   28]\n",
      "loss: 0.269301  [    0/   28]\n",
      "loss: 0.269179  [    0/   28]\n",
      "loss: 0.269061  [    0/   28]\n",
      "loss: 0.268937  [    0/   28]\n",
      "loss: 0.268812  [    0/   28]\n",
      "loss: 0.268691  [    0/   28]\n",
      "loss: 0.268571  [    0/   28]\n",
      "loss: 0.268449  [    0/   28]\n",
      "loss: 0.268328  [    0/   28]\n",
      "loss: 0.268206  [    0/   28]\n",
      "loss: 0.268085  [    0/   28]\n",
      "loss: 0.267962  [    0/   28]\n",
      "loss: 0.267839  [    0/   28]\n",
      "loss: 0.267720  [    0/   28]\n",
      "loss: 0.267598  [    0/   28]\n",
      "loss: 0.267475  [    0/   28]\n",
      "loss: 0.267354  [    0/   28]\n",
      "loss: 0.267236  [    0/   28]\n",
      "loss: 0.267111  [    0/   28]\n",
      "loss: 0.266991  [    0/   28]\n",
      "loss: 0.266871  [    0/   28]\n",
      "loss: 0.266748  [    0/   28]\n",
      "loss: 0.266629  [    0/   28]\n",
      "loss: 0.266507  [    0/   28]\n",
      "loss: 0.266386  [    0/   28]\n",
      "loss: 0.266269  [    0/   28]\n",
      "loss: 0.266146  [    0/   28]\n",
      "loss: 0.266024  [    0/   28]\n",
      "loss: 0.265902  [    0/   28]\n",
      "loss: 0.265783  [    0/   28]\n",
      "loss: 0.265661  [    0/   28]\n",
      "loss: 0.265543  [    0/   28]\n",
      "loss: 0.265420  [    0/   28]\n",
      "loss: 0.265302  [    0/   28]\n",
      "loss: 0.265178  [    0/   28]\n",
      "loss: 0.265061  [    0/   28]\n",
      "loss: 0.264941  [    0/   28]\n",
      "loss: 0.264820  [    0/   28]\n",
      "loss: 0.264698  [    0/   28]\n",
      "loss: 0.264577  [    0/   28]\n",
      "loss: 0.264460  [    0/   28]\n",
      "loss: 0.264340  [    0/   28]\n",
      "loss: 0.264219  [    0/   28]\n",
      "loss: 0.264097  [    0/   28]\n",
      "loss: 0.263978  [    0/   28]\n",
      "loss: 0.263861  [    0/   28]\n",
      "loss: 0.263737  [    0/   28]\n",
      "loss: 0.263620  [    0/   28]\n",
      "loss: 0.263500  [    0/   28]\n",
      "loss: 0.263377  [    0/   28]\n",
      "loss: 0.263261  [    0/   28]\n",
      "loss: 0.263139  [    0/   28]\n",
      "loss: 0.263021  [    0/   28]\n",
      "loss: 0.262900  [    0/   28]\n",
      "loss: 0.262782  [    0/   28]\n",
      "loss: 0.262662  [    0/   28]\n",
      "loss: 0.262541  [    0/   28]\n",
      "loss: 0.262419  [    0/   28]\n",
      "loss: 0.262301  [    0/   28]\n",
      "loss: 0.262186  [    0/   28]\n",
      "loss: 0.262065  [    0/   28]\n",
      "loss: 0.261942  [    0/   28]\n",
      "loss: 0.261825  [    0/   28]\n",
      "loss: 0.261709  [    0/   28]\n",
      "loss: 0.261588  [    0/   28]\n",
      "loss: 0.261466  [    0/   28]\n",
      "loss: 0.261350  [    0/   28]\n",
      "loss: 0.261231  [    0/   28]\n",
      "loss: 0.261110  [    0/   28]\n",
      "loss: 0.260992  [    0/   28]\n",
      "loss: 0.260874  [    0/   28]\n",
      "loss: 0.260754  [    0/   28]\n",
      "loss: 0.260635  [    0/   28]\n",
      "loss: 0.260515  [    0/   28]\n",
      "loss: 0.260395  [    0/   28]\n",
      "loss: 0.260282  [    0/   28]\n",
      "loss: 0.260163  [    0/   28]\n",
      "loss: 0.260042  [    0/   28]\n",
      "loss: 0.259923  [    0/   28]\n",
      "loss: 0.259805  [    0/   28]\n",
      "loss: 0.259687  [    0/   28]\n",
      "loss: 0.259567  [    0/   28]\n",
      "loss: 0.259450  [    0/   28]\n",
      "loss: 0.259332  [    0/   28]\n",
      "loss: 0.259212  [    0/   28]\n",
      "loss: 0.259094  [    0/   28]\n",
      "loss: 0.258976  [    0/   28]\n",
      "loss: 0.258858  [    0/   28]\n",
      "loss: 0.258741  [    0/   28]\n",
      "loss: 0.258622  [    0/   28]\n",
      "loss: 0.258503  [    0/   28]\n",
      "loss: 0.258386  [    0/   28]\n",
      "loss: 0.258267  [    0/   28]\n",
      "loss: 0.258153  [    0/   28]\n",
      "loss: 0.258032  [    0/   28]\n",
      "loss: 0.257914  [    0/   28]\n",
      "loss: 0.257798  [    0/   28]\n",
      "loss: 0.257680  [    0/   28]\n",
      "loss: 0.257561  [    0/   28]\n",
      "loss: 0.257444  [    0/   28]\n",
      "loss: 0.257327  [    0/   28]\n",
      "loss: 0.257207  [    0/   28]\n",
      "loss: 0.257091  [    0/   28]\n",
      "loss: 0.256974  [    0/   28]\n",
      "loss: 0.256854  [    0/   28]\n",
      "loss: 0.256738  [    0/   28]\n",
      "loss: 0.256621  [    0/   28]\n",
      "loss: 0.256506  [    0/   28]\n",
      "loss: 0.256388  [    0/   28]\n",
      "loss: 0.256269  [    0/   28]\n",
      "loss: 0.256153  [    0/   28]\n",
      "loss: 0.256039  [    0/   28]\n",
      "loss: 0.255919  [    0/   28]\n",
      "loss: 0.255800  [    0/   28]\n",
      "loss: 0.255685  [    0/   28]\n",
      "loss: 0.255572  [    0/   28]\n",
      "loss: 0.255452  [    0/   28]\n",
      "loss: 0.255337  [    0/   28]\n",
      "loss: 0.255219  [    0/   28]\n",
      "loss: 0.255104  [    0/   28]\n",
      "loss: 0.254984  [    0/   28]\n",
      "loss: 0.254869  [    0/   28]\n",
      "loss: 0.254750  [    0/   28]\n",
      "loss: 0.254634  [    0/   28]\n",
      "loss: 0.254519  [    0/   28]\n",
      "loss: 0.254402  [    0/   28]\n",
      "loss: 0.254288  [    0/   28]\n",
      "loss: 0.254169  [    0/   28]\n",
      "loss: 0.254055  [    0/   28]\n",
      "loss: 0.253935  [    0/   28]\n",
      "loss: 0.253821  [    0/   28]\n",
      "loss: 0.253704  [    0/   28]\n",
      "loss: 0.253586  [    0/   28]\n",
      "loss: 0.253471  [    0/   28]\n",
      "loss: 0.253354  [    0/   28]\n",
      "loss: 0.253243  [    0/   28]\n",
      "loss: 0.253122  [    0/   28]\n",
      "loss: 0.253006  [    0/   28]\n",
      "loss: 0.252889  [    0/   28]\n",
      "loss: 0.252775  [    0/   28]\n",
      "loss: 0.252660  [    0/   28]\n",
      "loss: 0.252544  [    0/   28]\n",
      "loss: 0.252430  [    0/   28]\n",
      "loss: 0.252310  [    0/   28]\n",
      "loss: 0.252195  [    0/   28]\n",
      "loss: 0.252078  [    0/   28]\n",
      "loss: 0.251965  [    0/   28]\n",
      "loss: 0.251851  [    0/   28]\n",
      "loss: 0.251733  [    0/   28]\n",
      "loss: 0.251619  [    0/   28]\n",
      "loss: 0.251502  [    0/   28]\n",
      "loss: 0.251386  [    0/   28]\n",
      "loss: 0.251272  [    0/   28]\n",
      "loss: 0.251158  [    0/   28]\n",
      "loss: 0.251042  [    0/   28]\n",
      "loss: 0.250925  [    0/   28]\n",
      "loss: 0.250810  [    0/   28]\n",
      "loss: 0.250695  [    0/   28]\n",
      "loss: 0.250580  [    0/   28]\n",
      "loss: 0.250467  [    0/   28]\n",
      "loss: 0.250349  [    0/   28]\n",
      "loss: 0.250236  [    0/   28]\n",
      "loss: 0.250123  [    0/   28]\n",
      "loss: 0.250006  [    0/   28]\n",
      "loss: 0.249891  [    0/   28]\n",
      "loss: 0.249774  [    0/   28]\n",
      "loss: 0.249661  [    0/   28]\n",
      "loss: 0.249546  [    0/   28]\n",
      "loss: 0.249432  [    0/   28]\n",
      "loss: 0.249320  [    0/   28]\n",
      "loss: 0.249205  [    0/   28]\n",
      "loss: 0.249087  [    0/   28]\n",
      "loss: 0.248972  [    0/   28]\n",
      "loss: 0.248861  [    0/   28]\n",
      "loss: 0.248745  [    0/   28]\n",
      "loss: 0.248630  [    0/   28]\n",
      "loss: 0.248516  [    0/   28]\n",
      "loss: 0.248402  [    0/   28]\n",
      "loss: 0.248289  [    0/   28]\n",
      "loss: 0.248172  [    0/   28]\n",
      "loss: 0.248059  [    0/   28]\n",
      "loss: 0.247945  [    0/   28]\n",
      "loss: 0.247830  [    0/   28]\n",
      "loss: 0.247718  [    0/   28]\n",
      "loss: 0.247604  [    0/   28]\n",
      "loss: 0.247490  [    0/   28]\n",
      "loss: 0.247375  [    0/   28]\n",
      "loss: 0.247263  [    0/   28]\n",
      "loss: 0.247148  [    0/   28]\n",
      "loss: 0.247034  [    0/   28]\n",
      "loss: 0.246922  [    0/   28]\n",
      "loss: 0.246809  [    0/   28]\n",
      "loss: 0.246695  [    0/   28]\n",
      "loss: 0.246578  [    0/   28]\n",
      "loss: 0.246464  [    0/   28]\n",
      "loss: 0.246354  [    0/   28]\n",
      "loss: 0.246243  [    0/   28]\n",
      "loss: 0.246128  [    0/   28]\n",
      "loss: 0.246018  [    0/   28]\n",
      "loss: 0.245902  [    0/   28]\n",
      "loss: 0.245786  [    0/   28]\n",
      "loss: 0.245674  [    0/   28]\n",
      "loss: 0.245563  [    0/   28]\n",
      "loss: 0.245449  [    0/   28]\n",
      "loss: 0.245337  [    0/   28]\n",
      "loss: 0.245224  [    0/   28]\n",
      "loss: 0.245111  [    0/   28]\n",
      "loss: 0.244997  [    0/   28]\n",
      "loss: 0.244885  [    0/   28]\n",
      "loss: 0.244772  [    0/   28]\n",
      "loss: 0.244656  [    0/   28]\n",
      "loss: 0.244544  [    0/   28]\n",
      "loss: 0.244435  [    0/   28]\n",
      "loss: 0.244324  [    0/   28]\n",
      "loss: 0.244209  [    0/   28]\n",
      "loss: 0.244097  [    0/   28]\n",
      "loss: 0.243985  [    0/   28]\n",
      "loss: 0.243871  [    0/   28]\n",
      "loss: 0.243758  [    0/   28]\n",
      "loss: 0.243649  [    0/   28]\n",
      "loss: 0.243536  [    0/   28]\n",
      "loss: 0.243424  [    0/   28]\n",
      "loss: 0.243308  [    0/   28]\n",
      "loss: 0.243198  [    0/   28]\n",
      "loss: 0.243086  [    0/   28]\n",
      "loss: 0.242974  [    0/   28]\n",
      "loss: 0.242863  [    0/   28]\n",
      "loss: 0.242753  [    0/   28]\n",
      "loss: 0.242638  [    0/   28]\n",
      "loss: 0.242525  [    0/   28]\n",
      "loss: 0.242417  [    0/   28]\n",
      "loss: 0.242303  [    0/   28]\n",
      "loss: 0.242192  [    0/   28]\n",
      "loss: 0.242080  [    0/   28]\n",
      "loss: 0.241970  [    0/   28]\n",
      "loss: 0.241857  [    0/   28]\n",
      "loss: 0.241745  [    0/   28]\n",
      "loss: 0.241632  [    0/   28]\n",
      "loss: 0.241523  [    0/   28]\n",
      "loss: 0.241414  [    0/   28]\n",
      "loss: 0.241300  [    0/   28]\n",
      "loss: 0.241191  [    0/   28]\n",
      "loss: 0.241077  [    0/   28]\n",
      "loss: 0.240966  [    0/   28]\n",
      "loss: 0.240857  [    0/   28]\n",
      "loss: 0.240748  [    0/   28]\n",
      "loss: 0.240634  [    0/   28]\n",
      "loss: 0.240523  [    0/   28]\n",
      "loss: 0.240413  [    0/   28]\n",
      "loss: 0.240303  [    0/   28]\n",
      "loss: 0.240193  [    0/   28]\n",
      "loss: 0.240079  [    0/   28]\n",
      "loss: 0.239970  [    0/   28]\n",
      "loss: 0.239860  [    0/   28]\n",
      "loss: 0.239752  [    0/   28]\n",
      "loss: 0.239637  [    0/   28]\n",
      "loss: 0.239528  [    0/   28]\n",
      "loss: 0.239417  [    0/   28]\n",
      "loss: 0.239307  [    0/   28]\n",
      "loss: 0.239197  [    0/   28]\n",
      "loss: 0.239091  [    0/   28]\n",
      "loss: 0.238979  [    0/   28]\n",
      "loss: 0.238867  [    0/   28]\n",
      "loss: 0.238759  [    0/   28]\n",
      "loss: 0.238649  [    0/   28]\n",
      "loss: 0.238538  [    0/   28]\n",
      "loss: 0.238429  [    0/   28]\n",
      "loss: 0.238317  [    0/   28]\n",
      "loss: 0.238209  [    0/   28]\n",
      "loss: 0.238100  [    0/   28]\n",
      "loss: 0.237992  [    0/   28]\n",
      "loss: 0.237879  [    0/   28]\n",
      "loss: 0.237771  [    0/   28]\n",
      "loss: 0.237659  [    0/   28]\n",
      "loss: 0.237552  [    0/   28]\n",
      "loss: 0.237441  [    0/   28]\n",
      "loss: 0.237332  [    0/   28]\n",
      "loss: 0.237223  [    0/   28]\n",
      "loss: 0.237114  [    0/   28]\n",
      "loss: 0.237006  [    0/   28]\n",
      "loss: 0.236895  [    0/   28]\n",
      "loss: 0.236784  [    0/   28]\n",
      "loss: 0.236673  [    0/   28]\n",
      "loss: 0.236567  [    0/   28]\n",
      "loss: 0.236463  [    0/   28]\n",
      "loss: 0.236350  [    0/   28]\n",
      "loss: 0.236241  [    0/   28]\n",
      "loss: 0.236133  [    0/   28]\n",
      "loss: 0.236023  [    0/   28]\n",
      "loss: 0.235912  [    0/   28]\n",
      "loss: 0.235804  [    0/   28]\n",
      "loss: 0.235698  [    0/   28]\n",
      "loss: 0.235586  [    0/   28]\n",
      "loss: 0.235480  [    0/   28]\n",
      "loss: 0.235372  [    0/   28]\n",
      "loss: 0.235262  [    0/   28]\n",
      "loss: 0.235156  [    0/   28]\n",
      "loss: 0.235044  [    0/   28]\n",
      "loss: 0.234937  [    0/   28]\n",
      "loss: 0.234827  [    0/   28]\n",
      "loss: 0.234720  [    0/   28]\n",
      "loss: 0.234612  [    0/   28]\n",
      "loss: 0.234506  [    0/   28]\n",
      "loss: 0.234394  [    0/   28]\n",
      "loss: 0.234286  [    0/   28]\n",
      "loss: 0.234178  [    0/   28]\n",
      "loss: 0.234069  [    0/   28]\n",
      "loss: 0.233959  [    0/   28]\n",
      "loss: 0.233852  [    0/   28]\n",
      "loss: 0.233746  [    0/   28]\n",
      "loss: 0.233643  [    0/   28]\n",
      "loss: 0.233531  [    0/   28]\n",
      "loss: 0.233425  [    0/   28]\n",
      "loss: 0.233316  [    0/   28]\n",
      "loss: 0.233208  [    0/   28]\n",
      "loss: 0.233100  [    0/   28]\n",
      "loss: 0.232992  [    0/   28]\n",
      "loss: 0.232886  [    0/   28]\n",
      "loss: 0.232779  [    0/   28]\n",
      "loss: 0.232673  [    0/   28]\n",
      "loss: 0.232563  [    0/   28]\n",
      "loss: 0.232457  [    0/   28]\n",
      "loss: 0.232351  [    0/   28]\n",
      "loss: 0.232242  [    0/   28]\n",
      "loss: 0.232134  [    0/   28]\n",
      "loss: 0.232028  [    0/   28]\n",
      "loss: 0.231922  [    0/   28]\n",
      "loss: 0.231816  [    0/   28]\n",
      "loss: 0.231708  [    0/   28]\n",
      "loss: 0.231600  [    0/   28]\n",
      "loss: 0.231494  [    0/   28]\n",
      "loss: 0.231387  [    0/   28]\n",
      "loss: 0.231280  [    0/   28]\n",
      "loss: 0.231173  [    0/   28]\n",
      "loss: 0.231066  [    0/   28]\n",
      "loss: 0.230961  [    0/   28]\n",
      "loss: 0.230853  [    0/   28]\n",
      "loss: 0.230746  [    0/   28]\n",
      "loss: 0.230640  [    0/   28]\n",
      "loss: 0.230535  [    0/   28]\n",
      "loss: 0.230430  [    0/   28]\n",
      "loss: 0.230322  [    0/   28]\n",
      "loss: 0.230218  [    0/   28]\n",
      "loss: 0.230110  [    0/   28]\n",
      "loss: 0.230001  [    0/   28]\n",
      "loss: 0.229898  [    0/   28]\n",
      "loss: 0.229792  [    0/   28]\n",
      "loss: 0.229688  [    0/   28]\n",
      "loss: 0.229578  [    0/   28]\n",
      "loss: 0.229473  [    0/   28]\n",
      "loss: 0.229367  [    0/   28]\n",
      "loss: 0.229263  [    0/   28]\n",
      "loss: 0.229157  [    0/   28]\n",
      "loss: 0.229053  [    0/   28]\n",
      "loss: 0.228946  [    0/   28]\n",
      "loss: 0.228841  [    0/   28]\n",
      "loss: 0.228736  [    0/   28]\n",
      "loss: 0.228629  [    0/   28]\n",
      "loss: 0.228525  [    0/   28]\n",
      "loss: 0.228417  [    0/   28]\n",
      "loss: 0.228312  [    0/   28]\n",
      "loss: 0.228211  [    0/   28]\n",
      "loss: 0.228106  [    0/   28]\n",
      "loss: 0.227998  [    0/   28]\n",
      "loss: 0.227893  [    0/   28]\n",
      "loss: 0.227788  [    0/   28]\n",
      "loss: 0.227685  [    0/   28]\n",
      "loss: 0.227577  [    0/   28]\n",
      "loss: 0.227474  [    0/   28]\n",
      "loss: 0.227371  [    0/   28]\n",
      "loss: 0.227264  [    0/   28]\n",
      "loss: 0.227160  [    0/   28]\n",
      "loss: 0.227056  [    0/   28]\n",
      "loss: 0.226949  [    0/   28]\n",
      "loss: 0.226844  [    0/   28]\n",
      "loss: 0.226745  [    0/   28]\n",
      "loss: 0.226638  [    0/   28]\n",
      "loss: 0.226532  [    0/   28]\n",
      "loss: 0.226429  [    0/   28]\n",
      "loss: 0.226324  [    0/   28]\n",
      "loss: 0.226218  [    0/   28]\n",
      "loss: 0.226114  [    0/   28]\n",
      "loss: 0.226009  [    0/   28]\n",
      "loss: 0.225907  [    0/   28]\n",
      "loss: 0.225800  [    0/   28]\n",
      "loss: 0.225698  [    0/   28]\n",
      "loss: 0.225592  [    0/   28]\n",
      "loss: 0.225487  [    0/   28]\n",
      "loss: 0.225381  [    0/   28]\n",
      "loss: 0.225279  [    0/   28]\n",
      "loss: 0.225175  [    0/   28]\n",
      "loss: 0.225075  [    0/   28]\n",
      "loss: 0.224966  [    0/   28]\n",
      "loss: 0.224863  [    0/   28]\n",
      "loss: 0.224759  [    0/   28]\n",
      "loss: 0.224658  [    0/   28]\n",
      "loss: 0.224551  [    0/   28]\n",
      "loss: 0.224451  [    0/   28]\n",
      "loss: 0.224344  [    0/   28]\n",
      "loss: 0.224242  [    0/   28]\n",
      "loss: 0.224136  [    0/   28]\n",
      "loss: 0.224032  [    0/   28]\n",
      "loss: 0.223928  [    0/   28]\n",
      "loss: 0.223825  [    0/   28]\n",
      "loss: 0.223725  [    0/   28]\n",
      "loss: 0.223619  [    0/   28]\n",
      "loss: 0.223514  [    0/   28]\n",
      "loss: 0.223413  [    0/   28]\n",
      "loss: 0.223308  [    0/   28]\n",
      "loss: 0.223203  [    0/   28]\n",
      "loss: 0.223100  [    0/   28]\n",
      "loss: 0.222996  [    0/   28]\n",
      "loss: 0.222896  [    0/   28]\n",
      "loss: 0.222792  [    0/   28]\n",
      "loss: 0.222688  [    0/   28]\n",
      "loss: 0.222584  [    0/   28]\n",
      "loss: 0.222480  [    0/   28]\n",
      "loss: 0.222377  [    0/   28]\n",
      "loss: 0.222275  [    0/   28]\n",
      "loss: 0.222172  [    0/   28]\n",
      "loss: 0.222069  [    0/   28]\n",
      "loss: 0.221966  [    0/   28]\n",
      "loss: 0.221862  [    0/   28]\n",
      "loss: 0.221761  [    0/   28]\n",
      "loss: 0.221656  [    0/   28]\n",
      "loss: 0.221552  [    0/   28]\n",
      "loss: 0.221451  [    0/   28]\n",
      "loss: 0.221349  [    0/   28]\n",
      "loss: 0.221249  [    0/   28]\n",
      "loss: 0.221143  [    0/   28]\n",
      "loss: 0.221041  [    0/   28]\n",
      "loss: 0.220939  [    0/   28]\n",
      "loss: 0.220835  [    0/   28]\n",
      "loss: 0.220734  [    0/   28]\n",
      "loss: 0.220630  [    0/   28]\n",
      "loss: 0.220525  [    0/   28]\n",
      "loss: 0.220426  [    0/   28]\n",
      "loss: 0.220326  [    0/   28]\n",
      "loss: 0.220223  [    0/   28]\n",
      "loss: 0.220118  [    0/   28]\n",
      "loss: 0.220017  [    0/   28]\n",
      "loss: 0.219914  [    0/   28]\n",
      "loss: 0.219816  [    0/   28]\n",
      "loss: 0.219709  [    0/   28]\n",
      "loss: 0.219607  [    0/   28]\n",
      "loss: 0.219507  [    0/   28]\n",
      "loss: 0.219406  [    0/   28]\n",
      "loss: 0.219306  [    0/   28]\n",
      "loss: 0.219201  [    0/   28]\n",
      "loss: 0.219098  [    0/   28]\n",
      "loss: 0.219000  [    0/   28]\n",
      "loss: 0.218896  [    0/   28]\n",
      "loss: 0.218795  [    0/   28]\n",
      "loss: 0.218693  [    0/   28]\n",
      "loss: 0.218591  [    0/   28]\n",
      "loss: 0.218490  [    0/   28]\n",
      "loss: 0.218391  [    0/   28]\n",
      "loss: 0.218287  [    0/   28]\n",
      "loss: 0.218187  [    0/   28]\n",
      "loss: 0.218087  [    0/   28]\n",
      "loss: 0.217984  [    0/   28]\n",
      "loss: 0.217883  [    0/   28]\n",
      "loss: 0.217780  [    0/   28]\n",
      "loss: 0.217681  [    0/   28]\n",
      "loss: 0.217583  [    0/   28]\n",
      "loss: 0.217480  [    0/   28]\n",
      "loss: 0.217379  [    0/   28]\n",
      "loss: 0.217276  [    0/   28]\n",
      "loss: 0.217176  [    0/   28]\n",
      "loss: 0.217075  [    0/   28]\n",
      "loss: 0.216974  [    0/   28]\n",
      "loss: 0.216874  [    0/   28]\n",
      "loss: 0.216776  [    0/   28]\n",
      "loss: 0.216674  [    0/   28]\n",
      "loss: 0.216575  [    0/   28]\n",
      "loss: 0.216475  [    0/   28]\n",
      "loss: 0.216371  [    0/   28]\n",
      "loss: 0.216269  [    0/   28]\n",
      "loss: 0.216171  [    0/   28]\n",
      "loss: 0.216072  [    0/   28]\n",
      "loss: 0.215972  [    0/   28]\n",
      "loss: 0.215870  [    0/   28]\n",
      "loss: 0.215772  [    0/   28]\n",
      "loss: 0.215671  [    0/   28]\n",
      "loss: 0.215571  [    0/   28]\n",
      "loss: 0.215469  [    0/   28]\n",
      "loss: 0.215371  [    0/   28]\n",
      "loss: 0.215270  [    0/   28]\n",
      "loss: 0.215171  [    0/   28]\n",
      "loss: 0.215069  [    0/   28]\n",
      "loss: 0.214974  [    0/   28]\n",
      "loss: 0.214870  [    0/   28]\n",
      "loss: 0.214774  [    0/   28]\n",
      "loss: 0.214672  [    0/   28]\n",
      "loss: 0.214575  [    0/   28]\n",
      "loss: 0.214473  [    0/   28]\n",
      "loss: 0.214373  [    0/   28]\n",
      "loss: 0.214275  [    0/   28]\n",
      "loss: 0.214173  [    0/   28]\n",
      "loss: 0.214077  [    0/   28]\n",
      "loss: 0.213978  [    0/   28]\n",
      "loss: 0.213879  [    0/   28]\n",
      "loss: 0.213777  [    0/   28]\n",
      "loss: 0.213680  [    0/   28]\n",
      "loss: 0.213580  [    0/   28]\n",
      "loss: 0.213481  [    0/   28]\n",
      "loss: 0.213384  [    0/   28]\n",
      "loss: 0.213285  [    0/   28]\n",
      "loss: 0.213185  [    0/   28]\n",
      "loss: 0.213085  [    0/   28]\n",
      "loss: 0.212987  [    0/   28]\n",
      "loss: 0.212890  [    0/   28]\n",
      "loss: 0.212790  [    0/   28]\n",
      "loss: 0.212694  [    0/   28]\n",
      "loss: 0.212591  [    0/   28]\n",
      "loss: 0.212495  [    0/   28]\n",
      "loss: 0.212394  [    0/   28]\n",
      "loss: 0.212298  [    0/   28]\n",
      "loss: 0.212197  [    0/   28]\n",
      "loss: 0.212102  [    0/   28]\n",
      "loss: 0.212002  [    0/   28]\n",
      "loss: 0.211904  [    0/   28]\n",
      "loss: 0.211804  [    0/   28]\n",
      "loss: 0.211707  [    0/   28]\n",
      "loss: 0.211608  [    0/   28]\n",
      "loss: 0.211510  [    0/   28]\n",
      "loss: 0.211412  [    0/   28]\n",
      "loss: 0.211315  [    0/   28]\n",
      "loss: 0.211220  [    0/   28]\n",
      "loss: 0.211119  [    0/   28]\n",
      "loss: 0.211022  [    0/   28]\n",
      "loss: 0.210923  [    0/   28]\n",
      "loss: 0.210825  [    0/   28]\n",
      "loss: 0.210730  [    0/   28]\n",
      "loss: 0.210632  [    0/   28]\n",
      "loss: 0.210532  [    0/   28]\n",
      "loss: 0.210433  [    0/   28]\n",
      "loss: 0.210336  [    0/   28]\n",
      "loss: 0.210238  [    0/   28]\n",
      "loss: 0.210143  [    0/   28]\n",
      "loss: 0.210047  [    0/   28]\n",
      "loss: 0.209949  [    0/   28]\n",
      "loss: 0.209852  [    0/   28]\n",
      "loss: 0.209754  [    0/   28]\n",
      "loss: 0.209657  [    0/   28]\n",
      "loss: 0.209561  [    0/   28]\n",
      "loss: 0.209463  [    0/   28]\n",
      "loss: 0.209364  [    0/   28]\n",
      "loss: 0.209268  [    0/   28]\n",
      "loss: 0.209172  [    0/   28]\n",
      "loss: 0.209080  [    0/   28]\n",
      "loss: 0.208976  [    0/   28]\n",
      "loss: 0.208883  [    0/   28]\n",
      "loss: 0.208786  [    0/   28]\n",
      "loss: 0.208693  [    0/   28]\n",
      "loss: 0.208590  [    0/   28]\n",
      "loss: 0.208495  [    0/   28]\n",
      "loss: 0.208399  [    0/   28]\n",
      "loss: 0.208306  [    0/   28]\n",
      "loss: 0.208206  [    0/   28]\n",
      "loss: 0.208109  [    0/   28]\n",
      "loss: 0.208013  [    0/   28]\n",
      "loss: 0.207917  [    0/   28]\n",
      "loss: 0.207823  [    0/   28]\n",
      "loss: 0.207728  [    0/   28]\n",
      "loss: 0.207629  [    0/   28]\n",
      "loss: 0.207532  [    0/   28]\n",
      "loss: 0.207436  [    0/   28]\n",
      "loss: 0.207344  [    0/   28]\n",
      "loss: 0.207246  [    0/   28]\n",
      "loss: 0.207150  [    0/   28]\n",
      "loss: 0.207056  [    0/   28]\n",
      "loss: 0.206959  [    0/   28]\n",
      "loss: 0.206864  [    0/   28]\n",
      "loss: 0.206767  [    0/   28]\n",
      "loss: 0.206670  [    0/   28]\n",
      "loss: 0.206575  [    0/   28]\n",
      "loss: 0.206480  [    0/   28]\n",
      "loss: 0.206388  [    0/   28]\n",
      "loss: 0.206290  [    0/   28]\n",
      "loss: 0.206194  [    0/   28]\n",
      "loss: 0.206097  [    0/   28]\n",
      "loss: 0.206001  [    0/   28]\n",
      "loss: 0.205908  [    0/   28]\n",
      "loss: 0.205818  [    0/   28]\n",
      "loss: 0.205718  [    0/   28]\n",
      "loss: 0.205622  [    0/   28]\n",
      "loss: 0.205527  [    0/   28]\n",
      "loss: 0.205434  [    0/   28]\n",
      "loss: 0.205336  [    0/   28]\n",
      "loss: 0.205241  [    0/   28]\n",
      "loss: 0.205146  [    0/   28]\n",
      "loss: 0.205052  [    0/   28]\n",
      "loss: 0.204959  [    0/   28]\n",
      "loss: 0.204867  [    0/   28]\n",
      "loss: 0.204767  [    0/   28]\n",
      "loss: 0.204673  [    0/   28]\n",
      "loss: 0.204580  [    0/   28]\n",
      "loss: 0.204487  [    0/   28]\n",
      "loss: 0.204391  [    0/   28]\n",
      "loss: 0.204295  [    0/   28]\n",
      "loss: 0.204199  [    0/   28]\n",
      "loss: 0.204110  [    0/   28]\n",
      "loss: 0.204013  [    0/   28]\n",
      "loss: 0.203918  [    0/   28]\n",
      "loss: 0.203825  [    0/   28]\n",
      "loss: 0.203732  [    0/   28]\n",
      "loss: 0.203636  [    0/   28]\n",
      "loss: 0.203539  [    0/   28]\n",
      "loss: 0.203447  [    0/   28]\n",
      "loss: 0.203353  [    0/   28]\n",
      "loss: 0.203260  [    0/   28]\n",
      "loss: 0.203166  [    0/   28]\n",
      "loss: 0.203071  [    0/   28]\n",
      "loss: 0.202976  [    0/   28]\n",
      "loss: 0.202882  [    0/   28]\n",
      "loss: 0.202790  [    0/   28]\n",
      "loss: 0.202696  [    0/   28]\n",
      "loss: 0.202605  [    0/   28]\n",
      "loss: 0.202508  [    0/   28]\n",
      "loss: 0.202414  [    0/   28]\n",
      "loss: 0.202321  [    0/   28]\n",
      "loss: 0.202230  [    0/   28]\n",
      "loss: 0.202135  [    0/   28]\n",
      "loss: 0.202039  [    0/   28]\n",
      "loss: 0.201949  [    0/   28]\n",
      "loss: 0.201854  [    0/   28]\n",
      "loss: 0.201760  [    0/   28]\n",
      "loss: 0.201668  [    0/   28]\n",
      "loss: 0.201576  [    0/   28]\n",
      "loss: 0.201483  [    0/   28]\n",
      "loss: 0.201388  [    0/   28]\n",
      "loss: 0.201295  [    0/   28]\n",
      "loss: 0.201200  [    0/   28]\n",
      "loss: 0.201109  [    0/   28]\n",
      "loss: 0.201018  [    0/   28]\n",
      "loss: 0.200924  [    0/   28]\n",
      "loss: 0.200830  [    0/   28]\n",
      "loss: 0.200735  [    0/   28]\n",
      "loss: 0.200645  [    0/   28]\n",
      "loss: 0.200553  [    0/   28]\n",
      "loss: 0.200459  [    0/   28]\n",
      "loss: 0.200367  [    0/   28]\n",
      "loss: 0.200274  [    0/   28]\n",
      "loss: 0.200180  [    0/   28]\n",
      "loss: 0.200090  [    0/   28]\n",
      "loss: 0.199999  [    0/   28]\n",
      "loss: 0.199905  [    0/   28]\n",
      "loss: 0.199810  [    0/   28]\n",
      "loss: 0.199719  [    0/   28]\n",
      "loss: 0.199627  [    0/   28]\n",
      "loss: 0.199536  [    0/   28]\n",
      "loss: 0.199442  [    0/   28]\n",
      "loss: 0.199351  [    0/   28]\n",
      "loss: 0.199259  [    0/   28]\n",
      "loss: 0.199166  [    0/   28]\n",
      "loss: 0.199074  [    0/   28]\n",
      "loss: 0.198983  [    0/   28]\n",
      "loss: 0.198892  [    0/   28]\n",
      "loss: 0.198799  [    0/   28]\n",
      "loss: 0.198707  [    0/   28]\n",
      "loss: 0.198616  [    0/   28]\n",
      "loss: 0.198523  [    0/   28]\n",
      "loss: 0.198432  [    0/   28]\n",
      "loss: 0.198340  [    0/   28]\n",
      "loss: 0.198249  [    0/   28]\n",
      "loss: 0.198159  [    0/   28]\n",
      "loss: 0.198065  [    0/   28]\n",
      "loss: 0.197973  [    0/   28]\n",
      "loss: 0.197883  [    0/   28]\n",
      "loss: 0.197790  [    0/   28]\n",
      "loss: 0.197701  [    0/   28]\n",
      "loss: 0.197607  [    0/   28]\n",
      "loss: 0.197519  [    0/   28]\n",
      "loss: 0.197426  [    0/   28]\n",
      "loss: 0.197334  [    0/   28]\n",
      "loss: 0.197242  [    0/   28]\n",
      "loss: 0.197150  [    0/   28]\n",
      "loss: 0.197059  [    0/   28]\n",
      "loss: 0.196968  [    0/   28]\n",
      "loss: 0.196880  [    0/   28]\n",
      "loss: 0.196787  [    0/   28]\n",
      "loss: 0.196695  [    0/   28]\n",
      "loss: 0.196604  [    0/   28]\n",
      "loss: 0.196516  [    0/   28]\n",
      "loss: 0.196425  [    0/   28]\n",
      "loss: 0.196332  [    0/   28]\n",
      "loss: 0.196243  [    0/   28]\n",
      "loss: 0.196152  [    0/   28]\n",
      "loss: 0.196062  [    0/   28]\n",
      "loss: 0.195970  [    0/   28]\n",
      "loss: 0.195881  [    0/   28]\n",
      "loss: 0.195790  [    0/   28]\n",
      "loss: 0.195698  [    0/   28]\n",
      "loss: 0.195611  [    0/   28]\n",
      "loss: 0.195522  [    0/   28]\n",
      "loss: 0.195430  [    0/   28]\n",
      "loss: 0.195338  [    0/   28]\n",
      "loss: 0.195249  [    0/   28]\n",
      "loss: 0.195158  [    0/   28]\n",
      "loss: 0.195068  [    0/   28]\n",
      "loss: 0.194982  [    0/   28]\n",
      "loss: 0.194890  [    0/   28]\n",
      "loss: 0.194801  [    0/   28]\n",
      "loss: 0.194712  [    0/   28]\n",
      "loss: 0.194621  [    0/   28]\n",
      "loss: 0.194531  [    0/   28]\n",
      "loss: 0.194441  [    0/   28]\n",
      "loss: 0.194351  [    0/   28]\n",
      "loss: 0.194263  [    0/   28]\n",
      "loss: 0.194176  [    0/   28]\n",
      "loss: 0.194084  [    0/   28]\n",
      "loss: 0.193995  [    0/   28]\n",
      "loss: 0.193906  [    0/   28]\n",
      "loss: 0.193815  [    0/   28]\n",
      "loss: 0.193727  [    0/   28]\n",
      "loss: 0.193637  [    0/   28]\n",
      "loss: 0.193550  [    0/   28]\n",
      "loss: 0.193463  [    0/   28]\n",
      "loss: 0.193371  [    0/   28]\n",
      "loss: 0.193282  [    0/   28]\n",
      "loss: 0.193192  [    0/   28]\n",
      "loss: 0.193105  [    0/   28]\n",
      "loss: 0.193015  [    0/   28]\n",
      "loss: 0.192929  [    0/   28]\n",
      "loss: 0.192839  [    0/   28]\n",
      "loss: 0.192752  [    0/   28]\n",
      "loss: 0.192660  [    0/   28]\n",
      "loss: 0.192572  [    0/   28]\n",
      "loss: 0.192484  [    0/   28]\n",
      "loss: 0.192396  [    0/   28]\n",
      "loss: 0.192308  [    0/   28]\n",
      "loss: 0.192220  [    0/   28]\n",
      "loss: 0.192132  [    0/   28]\n",
      "loss: 0.192043  [    0/   28]\n",
      "loss: 0.191955  [    0/   28]\n",
      "loss: 0.191866  [    0/   28]\n",
      "loss: 0.191778  [    0/   28]\n",
      "loss: 0.191690  [    0/   28]\n",
      "loss: 0.191603  [    0/   28]\n",
      "loss: 0.191514  [    0/   28]\n",
      "loss: 0.191425  [    0/   28]\n",
      "loss: 0.191338  [    0/   28]\n",
      "loss: 0.191250  [    0/   28]\n",
      "loss: 0.191163  [    0/   28]\n",
      "loss: 0.191076  [    0/   28]\n",
      "loss: 0.190989  [    0/   28]\n",
      "loss: 0.190899  [    0/   28]\n",
      "loss: 0.190812  [    0/   28]\n",
      "loss: 0.190725  [    0/   28]\n",
      "loss: 0.190639  [    0/   28]\n",
      "loss: 0.190550  [    0/   28]\n",
      "loss: 0.190466  [    0/   28]\n",
      "loss: 0.190376  [    0/   28]\n",
      "loss: 0.190289  [    0/   28]\n",
      "loss: 0.190199  [    0/   28]\n",
      "loss: 0.190112  [    0/   28]\n",
      "loss: 0.190025  [    0/   28]\n",
      "loss: 0.189942  [    0/   28]\n",
      "loss: 0.189852  [    0/   28]\n",
      "loss: 0.189767  [    0/   28]\n",
      "loss: 0.189676  [    0/   28]\n",
      "loss: 0.189590  [    0/   28]\n",
      "loss: 0.189503  [    0/   28]\n",
      "loss: 0.189421  [    0/   28]\n",
      "loss: 0.189330  [    0/   28]\n",
      "loss: 0.189244  [    0/   28]\n",
      "loss: 0.189158  [    0/   28]\n",
      "loss: 0.189071  [    0/   28]\n",
      "loss: 0.188983  [    0/   28]\n",
      "loss: 0.188897  [    0/   28]\n",
      "loss: 0.188810  [    0/   28]\n",
      "loss: 0.188726  [    0/   28]\n",
      "loss: 0.188637  [    0/   28]\n",
      "loss: 0.188550  [    0/   28]\n",
      "loss: 0.188463  [    0/   28]\n",
      "loss: 0.188377  [    0/   28]\n",
      "loss: 0.188292  [    0/   28]\n",
      "loss: 0.188205  [    0/   28]\n",
      "loss: 0.188117  [    0/   28]\n",
      "loss: 0.188032  [    0/   28]\n",
      "loss: 0.187947  [    0/   28]\n",
      "loss: 0.187860  [    0/   28]\n",
      "loss: 0.187772  [    0/   28]\n",
      "loss: 0.187686  [    0/   28]\n",
      "loss: 0.187601  [    0/   28]\n",
      "loss: 0.187515  [    0/   28]\n",
      "loss: 0.187429  [    0/   28]\n",
      "loss: 0.187345  [    0/   28]\n",
      "loss: 0.187257  [    0/   28]\n",
      "loss: 0.187170  [    0/   28]\n",
      "loss: 0.187086  [    0/   28]\n",
      "loss: 0.187000  [    0/   28]\n",
      "loss: 0.186913  [    0/   28]\n",
      "loss: 0.186828  [    0/   28]\n",
      "loss: 0.186742  [    0/   28]\n",
      "loss: 0.186655  [    0/   28]\n",
      "loss: 0.186571  [    0/   28]\n",
      "loss: 0.186488  [    0/   28]\n",
      "loss: 0.186401  [    0/   28]\n",
      "loss: 0.186313  [    0/   28]\n",
      "loss: 0.186231  [    0/   28]\n",
      "loss: 0.186142  [    0/   28]\n",
      "loss: 0.186058  [    0/   28]\n",
      "loss: 0.185973  [    0/   28]\n",
      "loss: 0.185887  [    0/   28]\n",
      "loss: 0.185802  [    0/   28]\n",
      "loss: 0.185720  [    0/   28]\n",
      "loss: 0.185632  [    0/   28]\n",
      "loss: 0.185548  [    0/   28]\n",
      "loss: 0.185464  [    0/   28]\n",
      "loss: 0.185377  [    0/   28]\n",
      "loss: 0.185291  [    0/   28]\n",
      "loss: 0.185208  [    0/   28]\n",
      "loss: 0.185122  [    0/   28]\n",
      "loss: 0.185038  [    0/   28]\n",
      "loss: 0.184954  [    0/   28]\n",
      "loss: 0.184867  [    0/   28]\n",
      "loss: 0.184783  [    0/   28]\n",
      "loss: 0.184698  [    0/   28]\n",
      "loss: 0.184613  [    0/   28]\n",
      "loss: 0.184531  [    0/   28]\n",
      "loss: 0.184444  [    0/   28]\n",
      "loss: 0.184363  [    0/   28]\n",
      "loss: 0.184276  [    0/   28]\n",
      "loss: 0.184190  [    0/   28]\n",
      "loss: 0.184106  [    0/   28]\n",
      "loss: 0.184021  [    0/   28]\n",
      "loss: 0.183937  [    0/   28]\n",
      "loss: 0.183852  [    0/   28]\n",
      "loss: 0.183771  [    0/   28]\n",
      "loss: 0.183686  [    0/   28]\n",
      "loss: 0.183601  [    0/   28]\n",
      "loss: 0.183515  [    0/   28]\n",
      "loss: 0.183434  [    0/   28]\n",
      "loss: 0.183349  [    0/   28]\n",
      "loss: 0.183264  [    0/   28]\n",
      "loss: 0.183180  [    0/   28]\n",
      "loss: 0.183096  [    0/   28]\n",
      "loss: 0.183013  [    0/   28]\n",
      "loss: 0.182928  [    0/   28]\n",
      "loss: 0.182847  [    0/   28]\n",
      "loss: 0.182760  [    0/   28]\n",
      "loss: 0.182677  [    0/   28]\n",
      "loss: 0.182592  [    0/   28]\n",
      "loss: 0.182510  [    0/   28]\n",
      "loss: 0.182425  [    0/   28]\n",
      "loss: 0.182343  [    0/   28]\n",
      "loss: 0.182258  [    0/   28]\n",
      "loss: 0.182176  [    0/   28]\n",
      "loss: 0.182095  [    0/   28]\n",
      "loss: 0.182011  [    0/   28]\n",
      "loss: 0.181928  [    0/   28]\n",
      "loss: 0.181843  [    0/   28]\n",
      "loss: 0.181762  [    0/   28]\n",
      "loss: 0.181678  [    0/   28]\n",
      "loss: 0.181594  [    0/   28]\n",
      "loss: 0.181510  [    0/   28]\n",
      "loss: 0.181430  [    0/   28]\n",
      "loss: 0.181346  [    0/   28]\n",
      "loss: 0.181263  [    0/   28]\n",
      "loss: 0.181182  [    0/   28]\n",
      "loss: 0.181098  [    0/   28]\n",
      "loss: 0.181015  [    0/   28]\n",
      "loss: 0.180931  [    0/   28]\n",
      "loss: 0.180850  [    0/   28]\n",
      "loss: 0.180767  [    0/   28]\n",
      "loss: 0.180684  [    0/   28]\n",
      "loss: 0.180601  [    0/   28]\n",
      "loss: 0.180516  [    0/   28]\n",
      "loss: 0.180439  [    0/   28]\n",
      "loss: 0.180353  [    0/   28]\n",
      "loss: 0.180271  [    0/   28]\n",
      "loss: 0.180189  [    0/   28]\n",
      "loss: 0.180110  [    0/   28]\n",
      "loss: 0.180024  [    0/   28]\n",
      "loss: 0.179944  [    0/   28]\n",
      "loss: 0.179860  [    0/   28]\n",
      "loss: 0.179778  [    0/   28]\n",
      "loss: 0.179697  [    0/   28]\n",
      "loss: 0.179615  [    0/   28]\n",
      "loss: 0.179536  [    0/   28]\n",
      "loss: 0.179450  [    0/   28]\n",
      "loss: 0.179370  [    0/   28]\n",
      "loss: 0.179290  [    0/   28]\n",
      "loss: 0.179208  [    0/   28]\n",
      "loss: 0.179126  [    0/   28]\n",
      "loss: 0.179043  [    0/   28]\n",
      "loss: 0.178960  [    0/   28]\n",
      "loss: 0.178880  [    0/   28]\n",
      "loss: 0.178798  [    0/   28]\n",
      "loss: 0.178719  [    0/   28]\n",
      "loss: 0.178638  [    0/   28]\n",
      "loss: 0.178555  [    0/   28]\n",
      "loss: 0.178474  [    0/   28]\n",
      "loss: 0.178391  [    0/   28]\n",
      "loss: 0.178311  [    0/   28]\n",
      "loss: 0.178229  [    0/   28]\n",
      "loss: 0.178147  [    0/   28]\n",
      "loss: 0.178067  [    0/   28]\n",
      "loss: 0.177987  [    0/   28]\n",
      "loss: 0.177904  [    0/   28]\n",
      "loss: 0.177826  [    0/   28]\n",
      "loss: 0.177746  [    0/   28]\n",
      "loss: 0.177663  [    0/   28]\n",
      "loss: 0.177584  [    0/   28]\n",
      "loss: 0.177502  [    0/   28]\n",
      "loss: 0.177423  [    0/   28]\n",
      "loss: 0.177340  [    0/   28]\n",
      "loss: 0.177262  [    0/   28]\n",
      "loss: 0.177178  [    0/   28]\n",
      "loss: 0.177099  [    0/   28]\n",
      "loss: 0.177018  [    0/   28]\n",
      "loss: 0.176939  [    0/   28]\n",
      "loss: 0.176858  [    0/   28]\n",
      "loss: 0.176778  [    0/   28]\n",
      "loss: 0.176698  [    0/   28]\n",
      "loss: 0.176617  [    0/   28]\n",
      "loss: 0.176537  [    0/   28]\n",
      "loss: 0.176458  [    0/   28]\n",
      "loss: 0.176378  [    0/   28]\n",
      "loss: 0.176296  [    0/   28]\n",
      "loss: 0.176215  [    0/   28]\n",
      "loss: 0.176135  [    0/   28]\n",
      "loss: 0.176057  [    0/   28]\n",
      "loss: 0.175975  [    0/   28]\n",
      "loss: 0.175898  [    0/   28]\n",
      "loss: 0.175819  [    0/   28]\n",
      "loss: 0.175739  [    0/   28]\n",
      "loss: 0.175657  [    0/   28]\n",
      "loss: 0.175578  [    0/   28]\n",
      "loss: 0.175499  [    0/   28]\n",
      "loss: 0.175419  [    0/   28]\n",
      "loss: 0.175338  [    0/   28]\n",
      "loss: 0.175260  [    0/   28]\n",
      "loss: 0.175181  [    0/   28]\n",
      "loss: 0.175102  [    0/   28]\n",
      "loss: 0.175021  [    0/   28]\n",
      "loss: 0.174942  [    0/   28]\n",
      "loss: 0.174863  [    0/   28]\n",
      "loss: 0.174785  [    0/   28]\n",
      "loss: 0.174703  [    0/   28]\n",
      "loss: 0.174626  [    0/   28]\n",
      "loss: 0.174547  [    0/   28]\n",
      "loss: 0.174468  [    0/   28]\n",
      "loss: 0.174387  [    0/   28]\n",
      "loss: 0.174309  [    0/   28]\n",
      "loss: 0.174230  [    0/   28]\n",
      "loss: 0.174152  [    0/   28]\n",
      "loss: 0.174072  [    0/   28]\n",
      "loss: 0.173994  [    0/   28]\n",
      "loss: 0.173917  [    0/   28]\n",
      "loss: 0.173835  [    0/   28]\n",
      "loss: 0.173758  [    0/   28]\n",
      "loss: 0.173678  [    0/   28]\n",
      "loss: 0.173598  [    0/   28]\n",
      "loss: 0.173524  [    0/   28]\n",
      "loss: 0.173446  [    0/   28]\n",
      "loss: 0.173366  [    0/   28]\n",
      "loss: 0.173286  [    0/   28]\n",
      "loss: 0.173213  [    0/   28]\n",
      "loss: 0.173130  [    0/   28]\n",
      "loss: 0.173051  [    0/   28]\n",
      "loss: 0.172973  [    0/   28]\n",
      "loss: 0.172897  [    0/   28]\n",
      "loss: 0.172817  [    0/   28]\n",
      "loss: 0.172740  [    0/   28]\n",
      "loss: 0.172660  [    0/   28]\n",
      "loss: 0.172584  [    0/   28]\n",
      "loss: 0.172508  [    0/   28]\n",
      "loss: 0.172428  [    0/   28]\n",
      "loss: 0.172351  [    0/   28]\n",
      "loss: 0.172274  [    0/   28]\n",
      "loss: 0.172195  [    0/   28]\n",
      "loss: 0.172117  [    0/   28]\n",
      "loss: 0.172039  [    0/   28]\n",
      "loss: 0.171960  [    0/   28]\n",
      "loss: 0.171886  [    0/   28]\n",
      "loss: 0.171807  [    0/   28]\n",
      "loss: 0.171729  [    0/   28]\n",
      "loss: 0.171655  [    0/   28]\n",
      "loss: 0.171575  [    0/   28]\n",
      "loss: 0.171497  [    0/   28]\n",
      "loss: 0.171421  [    0/   28]\n",
      "loss: 0.171345  [    0/   28]\n",
      "loss: 0.171266  [    0/   28]\n",
      "loss: 0.171188  [    0/   28]\n",
      "loss: 0.171112  [    0/   28]\n",
      "loss: 0.171034  [    0/   28]\n",
      "loss: 0.170958  [    0/   28]\n",
      "loss: 0.170881  [    0/   28]\n",
      "loss: 0.170804  [    0/   28]\n",
      "loss: 0.170728  [    0/   28]\n",
      "loss: 0.170651  [    0/   28]\n",
      "loss: 0.170573  [    0/   28]\n",
      "loss: 0.170495  [    0/   28]\n",
      "loss: 0.170419  [    0/   28]\n",
      "loss: 0.170342  [    0/   28]\n",
      "loss: 0.170266  [    0/   28]\n",
      "loss: 0.170193  [    0/   28]\n",
      "loss: 0.170113  [    0/   28]\n",
      "loss: 0.170037  [    0/   28]\n",
      "loss: 0.169961  [    0/   28]\n",
      "loss: 0.169883  [    0/   28]\n",
      "loss: 0.169808  [    0/   28]\n",
      "loss: 0.169730  [    0/   28]\n",
      "loss: 0.169653  [    0/   28]\n",
      "loss: 0.169578  [    0/   28]\n",
      "loss: 0.169503  [    0/   28]\n",
      "loss: 0.169426  [    0/   28]\n",
      "loss: 0.169350  [    0/   28]\n",
      "loss: 0.169274  [    0/   28]\n",
      "loss: 0.169195  [    0/   28]\n",
      "loss: 0.169121  [    0/   28]\n",
      "loss: 0.169046  [    0/   28]\n",
      "loss: 0.168970  [    0/   28]\n",
      "loss: 0.168891  [    0/   28]\n",
      "loss: 0.168819  [    0/   28]\n",
      "loss: 0.168742  [    0/   28]\n",
      "loss: 0.168667  [    0/   28]\n",
      "loss: 0.168589  [    0/   28]\n",
      "loss: 0.168515  [    0/   28]\n",
      "loss: 0.168438  [    0/   28]\n",
      "loss: 0.168362  [    0/   28]\n",
      "loss: 0.168290  [    0/   28]\n",
      "loss: 0.168212  [    0/   28]\n",
      "loss: 0.168135  [    0/   28]\n",
      "loss: 0.168061  [    0/   28]\n",
      "loss: 0.167986  [    0/   28]\n",
      "loss: 0.167909  [    0/   28]\n",
      "loss: 0.167835  [    0/   28]\n",
      "loss: 0.167761  [    0/   28]\n",
      "loss: 0.167686  [    0/   28]\n",
      "loss: 0.167610  [    0/   28]\n",
      "loss: 0.167534  [    0/   28]\n",
      "loss: 0.167459  [    0/   28]\n",
      "loss: 0.167384  [    0/   28]\n",
      "loss: 0.167308  [    0/   28]\n",
      "loss: 0.167235  [    0/   28]\n",
      "loss: 0.167160  [    0/   28]\n",
      "loss: 0.167085  [    0/   28]\n",
      "loss: 0.167009  [    0/   28]\n",
      "loss: 0.166934  [    0/   28]\n",
      "loss: 0.166861  [    0/   28]\n",
      "loss: 0.166783  [    0/   28]\n",
      "loss: 0.166710  [    0/   28]\n",
      "loss: 0.166634  [    0/   28]\n",
      "loss: 0.166561  [    0/   28]\n",
      "loss: 0.166486  [    0/   28]\n",
      "loss: 0.166412  [    0/   28]\n",
      "loss: 0.166337  [    0/   28]\n",
      "loss: 0.166263  [    0/   28]\n",
      "loss: 0.166191  [    0/   28]\n",
      "loss: 0.166114  [    0/   28]\n",
      "loss: 0.166040  [    0/   28]\n",
      "loss: 0.165965  [    0/   28]\n",
      "loss: 0.165889  [    0/   28]\n",
      "loss: 0.165817  [    0/   28]\n",
      "loss: 0.165745  [    0/   28]\n",
      "loss: 0.165670  [    0/   28]\n",
      "loss: 0.165596  [    0/   28]\n",
      "loss: 0.165522  [    0/   28]\n",
      "loss: 0.165446  [    0/   28]\n",
      "loss: 0.165372  [    0/   28]\n",
      "loss: 0.165299  [    0/   28]\n",
      "loss: 0.165224  [    0/   28]\n",
      "loss: 0.165151  [    0/   28]\n",
      "loss: 0.165079  [    0/   28]\n",
      "loss: 0.165003  [    0/   28]\n",
      "loss: 0.164930  [    0/   28]\n",
      "loss: 0.164856  [    0/   28]\n",
      "loss: 0.164783  [    0/   28]\n",
      "loss: 0.164709  [    0/   28]\n",
      "loss: 0.164635  [    0/   28]\n",
      "loss: 0.164561  [    0/   28]\n",
      "loss: 0.164489  [    0/   28]\n",
      "loss: 0.164417  [    0/   28]\n",
      "loss: 0.164341  [    0/   28]\n",
      "loss: 0.164268  [    0/   28]\n",
      "loss: 0.164193  [    0/   28]\n",
      "loss: 0.164120  [    0/   28]\n",
      "loss: 0.164047  [    0/   28]\n",
      "loss: 0.163975  [    0/   28]\n",
      "loss: 0.163902  [    0/   28]\n",
      "loss: 0.163831  [    0/   28]\n",
      "loss: 0.163753  [    0/   28]\n",
      "loss: 0.163683  [    0/   28]\n",
      "loss: 0.163611  [    0/   28]\n",
      "loss: 0.163537  [    0/   28]\n",
      "loss: 0.163464  [    0/   28]\n",
      "loss: 0.163392  [    0/   28]\n",
      "loss: 0.163318  [    0/   28]\n",
      "loss: 0.163246  [    0/   28]\n",
      "loss: 0.163173  [    0/   28]\n",
      "loss: 0.163097  [    0/   28]\n",
      "loss: 0.163025  [    0/   28]\n",
      "loss: 0.162952  [    0/   28]\n",
      "loss: 0.162885  [    0/   28]\n",
      "loss: 0.162807  [    0/   28]\n",
      "loss: 0.162736  [    0/   28]\n",
      "loss: 0.162663  [    0/   28]\n",
      "loss: 0.162594  [    0/   28]\n",
      "loss: 0.162518  [    0/   28]\n",
      "loss: 0.162445  [    0/   28]\n",
      "loss: 0.162373  [    0/   28]\n",
      "loss: 0.162302  [    0/   28]\n",
      "loss: 0.162228  [    0/   28]\n",
      "loss: 0.162156  [    0/   28]\n",
      "loss: 0.162084  [    0/   28]\n",
      "loss: 0.162011  [    0/   28]\n",
      "loss: 0.161939  [    0/   28]\n",
      "loss: 0.161870  [    0/   28]\n",
      "loss: 0.161797  [    0/   28]\n",
      "loss: 0.161722  [    0/   28]\n",
      "loss: 0.161652  [    0/   28]\n",
      "loss: 0.161578  [    0/   28]\n",
      "loss: 0.161506  [    0/   28]\n",
      "loss: 0.161437  [    0/   28]\n",
      "loss: 0.161364  [    0/   28]\n",
      "loss: 0.161291  [    0/   28]\n",
      "loss: 0.161220  [    0/   28]\n",
      "loss: 0.161149  [    0/   28]\n",
      "loss: 0.161077  [    0/   28]\n",
      "loss: 0.161004  [    0/   28]\n",
      "loss: 0.160934  [    0/   28]\n",
      "loss: 0.160862  [    0/   28]\n",
      "loss: 0.160790  [    0/   28]\n",
      "loss: 0.160717  [    0/   28]\n",
      "loss: 0.160646  [    0/   28]\n",
      "loss: 0.160575  [    0/   28]\n",
      "loss: 0.160504  [    0/   28]\n",
      "loss: 0.160433  [    0/   28]\n",
      "loss: 0.160361  [    0/   28]\n",
      "loss: 0.160288  [    0/   28]\n",
      "loss: 0.160220  [    0/   28]\n",
      "loss: 0.160145  [    0/   28]\n",
      "loss: 0.160076  [    0/   28]\n",
      "loss: 0.160004  [    0/   28]\n",
      "loss: 0.159934  [    0/   28]\n",
      "loss: 0.159864  [    0/   28]\n",
      "loss: 0.159790  [    0/   28]\n",
      "loss: 0.159722  [    0/   28]\n",
      "loss: 0.159650  [    0/   28]\n",
      "loss: 0.159580  [    0/   28]\n",
      "loss: 0.159507  [    0/   28]\n",
      "loss: 0.159437  [    0/   28]\n",
      "loss: 0.159366  [    0/   28]\n",
      "loss: 0.159295  [    0/   28]\n",
      "loss: 0.159223  [    0/   28]\n",
      "loss: 0.159156  [    0/   28]\n",
      "loss: 0.159084  [    0/   28]\n",
      "loss: 0.159015  [    0/   28]\n",
      "loss: 0.158943  [    0/   28]\n",
      "loss: 0.158871  [    0/   28]\n",
      "loss: 0.158802  [    0/   28]\n",
      "loss: 0.158731  [    0/   28]\n",
      "loss: 0.158660  [    0/   28]\n",
      "loss: 0.158591  [    0/   28]\n",
      "loss: 0.158520  [    0/   28]\n",
      "loss: 0.158450  [    0/   28]\n",
      "loss: 0.158379  [    0/   28]\n",
      "loss: 0.158311  [    0/   28]\n",
      "loss: 0.158238  [    0/   28]\n",
      "loss: 0.158171  [    0/   28]\n",
      "loss: 0.158099  [    0/   28]\n",
      "loss: 0.158030  [    0/   28]\n",
      "loss: 0.157959  [    0/   28]\n",
      "loss: 0.157889  [    0/   28]\n",
      "loss: 0.157818  [    0/   28]\n",
      "loss: 0.157750  [    0/   28]\n",
      "loss: 0.157680  [    0/   28]\n",
      "loss: 0.157611  [    0/   28]\n",
      "loss: 0.157541  [    0/   28]\n",
      "loss: 0.157472  [    0/   28]\n",
      "loss: 0.157402  [    0/   28]\n",
      "loss: 0.157332  [    0/   28]\n",
      "loss: 0.157262  [    0/   28]\n",
      "loss: 0.157192  [    0/   28]\n",
      "loss: 0.157123  [    0/   28]\n",
      "loss: 0.157056  [    0/   28]\n",
      "loss: 0.156983  [    0/   28]\n",
      "loss: 0.156916  [    0/   28]\n",
      "loss: 0.156848  [    0/   28]\n",
      "loss: 0.156778  [    0/   28]\n",
      "loss: 0.156706  [    0/   28]\n",
      "loss: 0.156641  [    0/   28]\n",
      "loss: 0.156571  [    0/   28]\n",
      "loss: 0.156501  [    0/   28]\n",
      "loss: 0.156429  [    0/   28]\n",
      "loss: 0.156363  [    0/   28]\n",
      "loss: 0.156293  [    0/   28]\n",
      "loss: 0.156224  [    0/   28]\n",
      "loss: 0.156155  [    0/   28]\n",
      "loss: 0.156085  [    0/   28]\n",
      "loss: 0.156019  [    0/   28]\n",
      "loss: 0.155951  [    0/   28]\n",
      "loss: 0.155881  [    0/   28]\n",
      "loss: 0.155811  [    0/   28]\n",
      "loss: 0.155744  [    0/   28]\n",
      "loss: 0.155674  [    0/   28]\n",
      "loss: 0.155605  [    0/   28]\n",
      "loss: 0.155536  [    0/   28]\n",
      "loss: 0.155467  [    0/   28]\n",
      "loss: 0.155399  [    0/   28]\n",
      "loss: 0.155331  [    0/   28]\n",
      "loss: 0.155267  [    0/   28]\n",
      "loss: 0.155196  [    0/   28]\n",
      "loss: 0.155127  [    0/   28]\n",
      "loss: 0.155059  [    0/   28]\n",
      "loss: 0.154990  [    0/   28]\n",
      "loss: 0.154922  [    0/   28]\n",
      "loss: 0.154854  [    0/   28]\n",
      "loss: 0.154787  [    0/   28]\n",
      "loss: 0.154718  [    0/   28]\n",
      "loss: 0.154649  [    0/   28]\n",
      "loss: 0.154582  [    0/   28]\n",
      "loss: 0.154513  [    0/   28]\n",
      "loss: 0.154447  [    0/   28]\n",
      "loss: 0.154378  [    0/   28]\n",
      "loss: 0.154309  [    0/   28]\n",
      "loss: 0.154243  [    0/   28]\n",
      "loss: 0.154172  [    0/   28]\n",
      "loss: 0.154106  [    0/   28]\n",
      "loss: 0.154038  [    0/   28]\n",
      "loss: 0.153973  [    0/   28]\n",
      "loss: 0.153902  [    0/   28]\n",
      "loss: 0.153835  [    0/   28]\n",
      "loss: 0.153767  [    0/   28]\n",
      "loss: 0.153700  [    0/   28]\n",
      "loss: 0.153634  [    0/   28]\n",
      "loss: 0.153564  [    0/   28]\n",
      "loss: 0.153497  [    0/   28]\n",
      "loss: 0.153432  [    0/   28]\n",
      "loss: 0.153363  [    0/   28]\n",
      "loss: 0.153294  [    0/   28]\n",
      "loss: 0.153228  [    0/   28]\n",
      "loss: 0.153161  [    0/   28]\n",
      "loss: 0.153093  [    0/   28]\n",
      "loss: 0.153026  [    0/   28]\n",
      "loss: 0.152958  [    0/   28]\n",
      "loss: 0.152892  [    0/   28]\n",
      "loss: 0.152823  [    0/   28]\n",
      "loss: 0.152757  [    0/   28]\n",
      "loss: 0.152692  [    0/   28]\n",
      "loss: 0.152623  [    0/   28]\n",
      "loss: 0.152556  [    0/   28]\n",
      "loss: 0.152488  [    0/   28]\n",
      "loss: 0.152422  [    0/   28]\n",
      "loss: 0.152354  [    0/   28]\n",
      "loss: 0.152288  [    0/   28]\n",
      "loss: 0.152221  [    0/   28]\n",
      "loss: 0.152154  [    0/   28]\n",
      "loss: 0.152091  [    0/   28]\n",
      "loss: 0.152020  [    0/   28]\n",
      "loss: 0.151954  [    0/   28]\n",
      "loss: 0.151887  [    0/   28]\n",
      "loss: 0.151822  [    0/   28]\n",
      "loss: 0.151757  [    0/   28]\n",
      "loss: 0.151689  [    0/   28]\n",
      "loss: 0.151622  [    0/   28]\n",
      "loss: 0.151555  [    0/   28]\n",
      "loss: 0.151488  [    0/   28]\n",
      "loss: 0.151425  [    0/   28]\n",
      "loss: 0.151355  [    0/   28]\n",
      "loss: 0.151289  [    0/   28]\n",
      "loss: 0.151224  [    0/   28]\n",
      "loss: 0.151158  [    0/   28]\n",
      "loss: 0.151092  [    0/   28]\n",
      "loss: 0.151027  [    0/   28]\n",
      "loss: 0.150959  [    0/   28]\n",
      "loss: 0.150893  [    0/   28]\n",
      "loss: 0.150827  [    0/   28]\n",
      "loss: 0.150760  [    0/   28]\n",
      "loss: 0.150694  [    0/   28]\n",
      "loss: 0.150629  [    0/   28]\n",
      "loss: 0.150563  [    0/   28]\n",
      "loss: 0.150498  [    0/   28]\n",
      "loss: 0.150430  [    0/   28]\n",
      "loss: 0.150366  [    0/   28]\n",
      "loss: 0.150298  [    0/   28]\n",
      "loss: 0.150233  [    0/   28]\n",
      "loss: 0.150170  [    0/   28]\n",
      "loss: 0.150104  [    0/   28]\n",
      "loss: 0.150036  [    0/   28]\n",
      "loss: 0.149970  [    0/   28]\n",
      "loss: 0.149905  [    0/   28]\n",
      "loss: 0.149840  [    0/   28]\n",
      "loss: 0.149775  [    0/   28]\n",
      "loss: 0.149711  [    0/   28]\n",
      "loss: 0.149645  [    0/   28]\n",
      "loss: 0.149577  [    0/   28]\n",
      "loss: 0.149514  [    0/   28]\n",
      "loss: 0.149448  [    0/   28]\n",
      "loss: 0.149385  [    0/   28]\n",
      "loss: 0.149316  [    0/   28]\n",
      "loss: 0.149252  [    0/   28]\n",
      "loss: 0.149186  [    0/   28]\n",
      "loss: 0.149123  [    0/   28]\n",
      "loss: 0.149056  [    0/   28]\n",
      "loss: 0.148992  [    0/   28]\n",
      "loss: 0.148926  [    0/   28]\n",
      "loss: 0.148861  [    0/   28]\n",
      "loss: 0.148798  [    0/   28]\n",
      "loss: 0.148733  [    0/   28]\n",
      "loss: 0.148669  [    0/   28]\n",
      "loss: 0.148604  [    0/   28]\n",
      "loss: 0.148539  [    0/   28]\n",
      "loss: 0.148471  [    0/   28]\n",
      "loss: 0.148409  [    0/   28]\n",
      "loss: 0.148343  [    0/   28]\n",
      "loss: 0.148279  [    0/   28]\n",
      "loss: 0.148212  [    0/   28]\n",
      "loss: 0.148148  [    0/   28]\n",
      "loss: 0.148087  [    0/   28]\n",
      "loss: 0.148021  [    0/   28]\n",
      "loss: 0.147958  [    0/   28]\n",
      "loss: 0.147892  [    0/   28]\n",
      "loss: 0.147828  [    0/   28]\n",
      "loss: 0.147762  [    0/   28]\n",
      "loss: 0.147698  [    0/   28]\n",
      "loss: 0.147636  [    0/   28]\n",
      "loss: 0.147571  [    0/   28]\n",
      "loss: 0.147505  [    0/   28]\n",
      "loss: 0.147441  [    0/   28]\n",
      "loss: 0.147377  [    0/   28]\n",
      "loss: 0.147311  [    0/   28]\n",
      "loss: 0.147249  [    0/   28]\n",
      "loss: 0.147184  [    0/   28]\n",
      "loss: 0.147122  [    0/   28]\n",
      "loss: 0.147057  [    0/   28]\n",
      "loss: 0.146994  [    0/   28]\n",
      "loss: 0.146928  [    0/   28]\n",
      "loss: 0.146865  [    0/   28]\n",
      "loss: 0.146800  [    0/   28]\n",
      "loss: 0.146738  [    0/   28]\n",
      "loss: 0.146673  [    0/   28]\n",
      "loss: 0.146610  [    0/   28]\n",
      "loss: 0.146547  [    0/   28]\n",
      "loss: 0.146483  [    0/   28]\n",
      "loss: 0.146420  [    0/   28]\n",
      "loss: 0.146355  [    0/   28]\n",
      "loss: 0.146292  [    0/   28]\n",
      "loss: 0.146228  [    0/   28]\n",
      "loss: 0.146163  [    0/   28]\n",
      "loss: 0.146099  [    0/   28]\n",
      "loss: 0.146038  [    0/   28]\n",
      "loss: 0.145974  [    0/   28]\n",
      "loss: 0.145911  [    0/   28]\n",
      "loss: 0.145849  [    0/   28]\n",
      "loss: 0.145784  [    0/   28]\n",
      "loss: 0.145722  [    0/   28]\n",
      "loss: 0.145657  [    0/   28]\n",
      "loss: 0.145593  [    0/   28]\n",
      "loss: 0.145531  [    0/   28]\n",
      "loss: 0.145469  [    0/   28]\n",
      "loss: 0.145405  [    0/   28]\n",
      "loss: 0.145342  [    0/   28]\n",
      "loss: 0.145280  [    0/   28]\n",
      "loss: 0.145216  [    0/   28]\n",
      "loss: 0.145152  [    0/   28]\n",
      "loss: 0.145088  [    0/   28]\n",
      "loss: 0.145026  [    0/   28]\n",
      "loss: 0.144965  [    0/   28]\n",
      "loss: 0.144902  [    0/   28]\n",
      "loss: 0.144837  [    0/   28]\n",
      "loss: 0.144776  [    0/   28]\n",
      "loss: 0.144713  [    0/   28]\n",
      "loss: 0.144651  [    0/   28]\n",
      "loss: 0.144587  [    0/   28]\n",
      "loss: 0.144525  [    0/   28]\n",
      "loss: 0.144461  [    0/   28]\n",
      "loss: 0.144398  [    0/   28]\n",
      "loss: 0.144337  [    0/   28]\n",
      "loss: 0.144276  [    0/   28]\n",
      "loss: 0.144211  [    0/   28]\n",
      "loss: 0.144150  [    0/   28]\n",
      "loss: 0.144087  [    0/   28]\n",
      "loss: 0.144025  [    0/   28]\n",
      "loss: 0.143964  [    0/   28]\n",
      "loss: 0.143900  [    0/   28]\n",
      "loss: 0.143838  [    0/   28]\n",
      "loss: 0.143776  [    0/   28]\n",
      "loss: 0.143714  [    0/   28]\n",
      "loss: 0.143652  [    0/   28]\n",
      "loss: 0.143591  [    0/   28]\n",
      "loss: 0.143529  [    0/   28]\n",
      "loss: 0.143466  [    0/   28]\n",
      "loss: 0.143402  [    0/   28]\n",
      "loss: 0.143342  [    0/   28]\n",
      "loss: 0.143280  [    0/   28]\n",
      "loss: 0.143219  [    0/   28]\n",
      "loss: 0.143156  [    0/   28]\n",
      "loss: 0.143095  [    0/   28]\n",
      "loss: 0.143031  [    0/   28]\n",
      "loss: 0.142970  [    0/   28]\n",
      "loss: 0.142910  [    0/   28]\n",
      "loss: 0.142849  [    0/   28]\n",
      "loss: 0.142786  [    0/   28]\n",
      "loss: 0.142725  [    0/   28]\n",
      "loss: 0.142664  [    0/   28]\n",
      "loss: 0.142603  [    0/   28]\n",
      "loss: 0.142540  [    0/   28]\n",
      "loss: 0.142479  [    0/   28]\n",
      "loss: 0.142416  [    0/   28]\n",
      "loss: 0.142355  [    0/   28]\n",
      "loss: 0.142294  [    0/   28]\n",
      "loss: 0.142234  [    0/   28]\n",
      "loss: 0.142171  [    0/   28]\n",
      "loss: 0.142111  [    0/   28]\n",
      "loss: 0.142050  [    0/   28]\n",
      "loss: 0.141990  [    0/   28]\n",
      "loss: 0.141925  [    0/   28]\n",
      "loss: 0.141867  [    0/   28]\n",
      "loss: 0.141806  [    0/   28]\n",
      "loss: 0.141743  [    0/   28]\n",
      "loss: 0.141682  [    0/   28]\n",
      "loss: 0.141621  [    0/   28]\n",
      "loss: 0.141559  [    0/   28]\n",
      "loss: 0.141499  [    0/   28]\n",
      "loss: 0.141439  [    0/   28]\n",
      "loss: 0.141379  [    0/   28]\n",
      "loss: 0.141317  [    0/   28]\n",
      "loss: 0.141257  [    0/   28]\n",
      "loss: 0.141195  [    0/   28]\n",
      "loss: 0.141135  [    0/   28]\n",
      "loss: 0.141073  [    0/   28]\n",
      "loss: 0.141015  [    0/   28]\n",
      "loss: 0.140954  [    0/   28]\n",
      "loss: 0.140892  [    0/   28]\n",
      "loss: 0.140832  [    0/   28]\n",
      "loss: 0.140771  [    0/   28]\n",
      "loss: 0.140709  [    0/   28]\n",
      "loss: 0.140649  [    0/   28]\n",
      "loss: 0.140591  [    0/   28]\n",
      "loss: 0.140529  [    0/   28]\n",
      "loss: 0.140470  [    0/   28]\n",
      "loss: 0.140409  [    0/   28]\n",
      "loss: 0.140347  [    0/   28]\n",
      "loss: 0.140288  [    0/   28]\n",
      "loss: 0.140226  [    0/   28]\n",
      "loss: 0.140168  [    0/   28]\n",
      "loss: 0.140109  [    0/   28]\n",
      "loss: 0.140047  [    0/   28]\n",
      "loss: 0.139987  [    0/   28]\n",
      "loss: 0.139928  [    0/   28]\n",
      "loss: 0.139866  [    0/   28]\n",
      "loss: 0.139806  [    0/   28]\n",
      "loss: 0.139747  [    0/   28]\n",
      "loss: 0.139688  [    0/   28]\n",
      "loss: 0.139628  [    0/   28]\n",
      "loss: 0.139565  [    0/   28]\n",
      "loss: 0.139507  [    0/   28]\n",
      "loss: 0.139449  [    0/   28]\n",
      "loss: 0.139386  [    0/   28]\n",
      "loss: 0.139330  [    0/   28]\n",
      "loss: 0.139268  [    0/   28]\n",
      "loss: 0.139210  [    0/   28]\n",
      "loss: 0.139150  [    0/   28]\n",
      "loss: 0.139089  [    0/   28]\n",
      "loss: 0.139030  [    0/   28]\n",
      "loss: 0.138970  [    0/   28]\n",
      "loss: 0.138909  [    0/   28]\n",
      "loss: 0.138852  [    0/   28]\n",
      "loss: 0.138792  [    0/   28]\n",
      "loss: 0.138732  [    0/   28]\n",
      "loss: 0.138672  [    0/   28]\n",
      "loss: 0.138614  [    0/   28]\n",
      "loss: 0.138555  [    0/   28]\n",
      "loss: 0.138496  [    0/   28]\n",
      "loss: 0.138436  [    0/   28]\n",
      "loss: 0.138376  [    0/   28]\n",
      "loss: 0.138317  [    0/   28]\n",
      "loss: 0.138258  [    0/   28]\n",
      "loss: 0.138201  [    0/   28]\n",
      "loss: 0.138140  [    0/   28]\n",
      "loss: 0.138082  [    0/   28]\n",
      "loss: 0.138022  [    0/   28]\n",
      "loss: 0.137961  [    0/   28]\n",
      "loss: 0.137903  [    0/   28]\n",
      "loss: 0.137846  [    0/   28]\n",
      "loss: 0.137788  [    0/   28]\n",
      "loss: 0.137729  [    0/   28]\n",
      "loss: 0.137669  [    0/   28]\n",
      "loss: 0.137610  [    0/   28]\n",
      "loss: 0.137551  [    0/   28]\n",
      "loss: 0.137493  [    0/   28]\n",
      "loss: 0.137434  [    0/   28]\n",
      "loss: 0.137376  [    0/   28]\n",
      "loss: 0.137316  [    0/   28]\n",
      "loss: 0.137258  [    0/   28]\n",
      "loss: 0.137198  [    0/   28]\n",
      "loss: 0.137141  [    0/   28]\n",
      "loss: 0.137085  [    0/   28]\n",
      "loss: 0.137025  [    0/   28]\n",
      "loss: 0.136966  [    0/   28]\n",
      "loss: 0.136908  [    0/   28]\n",
      "loss: 0.136848  [    0/   28]\n",
      "loss: 0.136789  [    0/   28]\n",
      "loss: 0.136735  [    0/   28]\n",
      "loss: 0.136675  [    0/   28]\n",
      "loss: 0.136615  [    0/   28]\n",
      "loss: 0.136558  [    0/   28]\n",
      "loss: 0.136501  [    0/   28]\n",
      "loss: 0.136441  [    0/   28]\n",
      "loss: 0.136382  [    0/   28]\n",
      "loss: 0.136324  [    0/   28]\n",
      "loss: 0.136269  [    0/   28]\n",
      "loss: 0.136210  [    0/   28]\n",
      "loss: 0.136151  [    0/   28]\n",
      "loss: 0.136093  [    0/   28]\n",
      "loss: 0.136035  [    0/   28]\n",
      "loss: 0.135977  [    0/   28]\n",
      "loss: 0.135919  [    0/   28]\n",
      "loss: 0.135860  [    0/   28]\n",
      "loss: 0.135804  [    0/   28]\n",
      "loss: 0.135748  [    0/   28]\n",
      "loss: 0.135688  [    0/   28]\n",
      "loss: 0.135631  [    0/   28]\n",
      "loss: 0.135573  [    0/   28]\n",
      "loss: 0.135515  [    0/   28]\n",
      "loss: 0.135458  [    0/   28]\n",
      "loss: 0.135400  [    0/   28]\n",
      "loss: 0.135344  [    0/   28]\n",
      "loss: 0.135285  [    0/   28]\n",
      "loss: 0.135227  [    0/   28]\n",
      "loss: 0.135169  [    0/   28]\n",
      "loss: 0.135113  [    0/   28]\n",
      "loss: 0.135056  [    0/   28]\n",
      "loss: 0.134998  [    0/   28]\n",
      "loss: 0.134941  [    0/   28]\n",
      "loss: 0.134883  [    0/   28]\n",
      "loss: 0.134827  [    0/   28]\n",
      "loss: 0.134769  [    0/   28]\n",
      "loss: 0.134713  [    0/   28]\n",
      "loss: 0.134653  [    0/   28]\n",
      "loss: 0.134597  [    0/   28]\n",
      "loss: 0.134541  [    0/   28]\n",
      "loss: 0.134482  [    0/   28]\n",
      "loss: 0.134427  [    0/   28]\n",
      "loss: 0.134369  [    0/   28]\n",
      "loss: 0.134314  [    0/   28]\n",
      "loss: 0.134255  [    0/   28]\n",
      "loss: 0.134198  [    0/   28]\n",
      "loss: 0.134142  [    0/   28]\n",
      "loss: 0.134086  [    0/   28]\n",
      "loss: 0.134026  [    0/   28]\n",
      "loss: 0.133970  [    0/   28]\n",
      "loss: 0.133914  [    0/   28]\n",
      "loss: 0.133861  [    0/   28]\n",
      "loss: 0.133801  [    0/   28]\n",
      "loss: 0.133744  [    0/   28]\n",
      "loss: 0.133687  [    0/   28]\n",
      "loss: 0.133631  [    0/   28]\n",
      "loss: 0.133575  [    0/   28]\n",
      "loss: 0.133518  [    0/   28]\n",
      "loss: 0.133461  [    0/   28]\n",
      "loss: 0.133405  [    0/   28]\n",
      "loss: 0.133349  [    0/   28]\n",
      "loss: 0.133294  [    0/   28]\n",
      "loss: 0.133236  [    0/   28]\n",
      "loss: 0.133179  [    0/   28]\n",
      "loss: 0.133123  [    0/   28]\n",
      "loss: 0.133068  [    0/   28]\n",
      "loss: 0.133010  [    0/   28]\n",
      "loss: 0.132955  [    0/   28]\n",
      "loss: 0.132898  [    0/   28]\n",
      "loss: 0.132842  [    0/   28]\n",
      "loss: 0.132785  [    0/   28]\n",
      "loss: 0.132729  [    0/   28]\n",
      "loss: 0.132675  [    0/   28]\n",
      "loss: 0.132618  [    0/   28]\n",
      "loss: 0.132561  [    0/   28]\n",
      "loss: 0.132505  [    0/   28]\n",
      "loss: 0.132449  [    0/   28]\n",
      "loss: 0.132394  [    0/   28]\n",
      "loss: 0.132337  [    0/   28]\n",
      "loss: 0.132282  [    0/   28]\n",
      "loss: 0.132225  [    0/   28]\n",
      "loss: 0.132172  [    0/   28]\n",
      "loss: 0.132114  [    0/   28]\n",
      "loss: 0.132060  [    0/   28]\n",
      "loss: 0.132001  [    0/   28]\n",
      "loss: 0.131946  [    0/   28]\n",
      "loss: 0.131892  [    0/   28]\n",
      "loss: 0.131836  [    0/   28]\n",
      "loss: 0.131781  [    0/   28]\n",
      "loss: 0.131723  [    0/   28]\n",
      "loss: 0.131671  [    0/   28]\n",
      "loss: 0.131612  [    0/   28]\n",
      "loss: 0.131558  [    0/   28]\n",
      "loss: 0.131503  [    0/   28]\n",
      "loss: 0.131448  [    0/   28]\n",
      "loss: 0.131391  [    0/   28]\n",
      "loss: 0.131336  [    0/   28]\n",
      "loss: 0.131282  [    0/   28]\n",
      "loss: 0.131225  [    0/   28]\n",
      "loss: 0.131170  [    0/   28]\n",
      "loss: 0.131114  [    0/   28]\n",
      "loss: 0.131059  [    0/   28]\n",
      "loss: 0.131006  [    0/   28]\n",
      "loss: 0.130949  [    0/   28]\n",
      "loss: 0.130896  [    0/   28]\n",
      "loss: 0.130840  [    0/   28]\n",
      "loss: 0.130785  [    0/   28]\n",
      "loss: 0.130729  [    0/   28]\n",
      "loss: 0.130673  [    0/   28]\n",
      "loss: 0.130619  [    0/   28]\n",
      "loss: 0.130565  [    0/   28]\n",
      "loss: 0.130509  [    0/   28]\n",
      "loss: 0.130456  [    0/   28]\n",
      "loss: 0.130400  [    0/   28]\n",
      "loss: 0.130346  [    0/   28]\n",
      "loss: 0.130289  [    0/   28]\n",
      "loss: 0.130236  [    0/   28]\n",
      "loss: 0.130182  [    0/   28]\n",
      "loss: 0.130127  [    0/   28]\n",
      "loss: 0.130072  [    0/   28]\n",
      "loss: 0.130017  [    0/   28]\n",
      "loss: 0.129963  [    0/   28]\n",
      "loss: 0.129907  [    0/   28]\n",
      "loss: 0.129853  [    0/   28]\n",
      "loss: 0.129799  [    0/   28]\n",
      "loss: 0.129745  [    0/   28]\n",
      "loss: 0.129691  [    0/   28]\n",
      "loss: 0.129635  [    0/   28]\n",
      "loss: 0.129582  [    0/   28]\n",
      "loss: 0.129527  [    0/   28]\n",
      "loss: 0.129472  [    0/   28]\n",
      "loss: 0.129418  [    0/   28]\n",
      "loss: 0.129365  [    0/   28]\n",
      "loss: 0.129310  [    0/   28]\n",
      "loss: 0.129256  [    0/   28]\n",
      "loss: 0.129202  [    0/   28]\n",
      "loss: 0.129147  [    0/   28]\n",
      "loss: 0.129092  [    0/   28]\n",
      "loss: 0.129038  [    0/   28]\n",
      "loss: 0.128985  [    0/   28]\n",
      "loss: 0.128932  [    0/   28]\n",
      "loss: 0.128877  [    0/   28]\n",
      "loss: 0.128823  [    0/   28]\n",
      "loss: 0.128768  [    0/   28]\n",
      "loss: 0.128714  [    0/   28]\n",
      "loss: 0.128661  [    0/   28]\n",
      "loss: 0.128609  [    0/   28]\n",
      "loss: 0.128554  [    0/   28]\n",
      "loss: 0.128499  [    0/   28]\n",
      "loss: 0.128446  [    0/   28]\n",
      "loss: 0.128392  [    0/   28]\n",
      "loss: 0.128336  [    0/   28]\n",
      "loss: 0.128284  [    0/   28]\n",
      "loss: 0.128232  [    0/   28]\n",
      "loss: 0.128178  [    0/   28]\n",
      "loss: 0.128123  [    0/   28]\n",
      "loss: 0.128070  [    0/   28]\n",
      "loss: 0.128016  [    0/   28]\n",
      "loss: 0.127963  [    0/   28]\n",
      "loss: 0.127910  [    0/   28]\n",
      "loss: 0.127855  [    0/   28]\n",
      "loss: 0.127802  [    0/   28]\n",
      "loss: 0.127749  [    0/   28]\n",
      "loss: 0.127698  [    0/   28]\n",
      "loss: 0.127641  [    0/   28]\n",
      "loss: 0.127589  [    0/   28]\n",
      "loss: 0.127536  [    0/   28]\n",
      "loss: 0.127484  [    0/   28]\n",
      "loss: 0.127429  [    0/   28]\n",
      "loss: 0.127376  [    0/   28]\n",
      "loss: 0.127323  [    0/   28]\n",
      "loss: 0.127270  [    0/   28]\n",
      "loss: 0.127218  [    0/   28]\n",
      "loss: 0.127162  [    0/   28]\n",
      "loss: 0.127111  [    0/   28]\n",
      "loss: 0.127060  [    0/   28]\n",
      "loss: 0.127006  [    0/   28]\n",
      "loss: 0.126953  [    0/   28]\n",
      "loss: 0.126898  [    0/   28]\n",
      "loss: 0.126846  [    0/   28]\n",
      "loss: 0.126794  [    0/   28]\n",
      "loss: 0.126740  [    0/   28]\n",
      "loss: 0.126688  [    0/   28]\n",
      "loss: 0.126634  [    0/   28]\n",
      "loss: 0.126582  [    0/   28]\n",
      "loss: 0.126530  [    0/   28]\n",
      "loss: 0.126478  [    0/   28]\n",
      "loss: 0.126425  [    0/   28]\n",
      "loss: 0.126373  [    0/   28]\n",
      "loss: 0.126319  [    0/   28]\n",
      "loss: 0.126266  [    0/   28]\n",
      "loss: 0.126214  [    0/   28]\n",
      "loss: 0.126161  [    0/   28]\n",
      "loss: 0.126109  [    0/   28]\n",
      "loss: 0.126056  [    0/   28]\n",
      "loss: 0.126006  [    0/   28]\n",
      "loss: 0.125953  [    0/   28]\n",
      "loss: 0.125902  [    0/   28]\n",
      "loss: 0.125849  [    0/   28]\n",
      "loss: 0.125796  [    0/   28]\n",
      "loss: 0.125743  [    0/   28]\n",
      "loss: 0.125690  [    0/   28]\n",
      "loss: 0.125639  [    0/   28]\n",
      "loss: 0.125587  [    0/   28]\n",
      "loss: 0.125534  [    0/   28]\n",
      "loss: 0.125482  [    0/   28]\n",
      "loss: 0.125431  [    0/   28]\n",
      "loss: 0.125379  [    0/   28]\n",
      "loss: 0.125327  [    0/   28]\n",
      "loss: 0.125275  [    0/   28]\n",
      "loss: 0.125223  [    0/   28]\n",
      "loss: 0.125171  [    0/   28]\n",
      "loss: 0.125118  [    0/   28]\n",
      "loss: 0.125066  [    0/   28]\n",
      "loss: 0.125016  [    0/   28]\n",
      "loss: 0.124964  [    0/   28]\n",
      "loss: 0.124912  [    0/   28]\n",
      "loss: 0.124860  [    0/   28]\n",
      "loss: 0.124809  [    0/   28]\n",
      "loss: 0.124756  [    0/   28]\n",
      "loss: 0.124705  [    0/   28]\n",
      "loss: 0.124654  [    0/   28]\n",
      "loss: 0.124604  [    0/   28]\n",
      "loss: 0.124551  [    0/   28]\n",
      "loss: 0.124499  [    0/   28]\n",
      "loss: 0.124446  [    0/   28]\n",
      "loss: 0.124394  [    0/   28]\n",
      "loss: 0.124345  [    0/   28]\n",
      "loss: 0.124294  [    0/   28]\n",
      "loss: 0.124242  [    0/   28]\n",
      "loss: 0.124192  [    0/   28]\n",
      "loss: 0.124140  [    0/   28]\n",
      "loss: 0.124088  [    0/   28]\n",
      "loss: 0.124037  [    0/   28]\n",
      "loss: 0.123986  [    0/   28]\n",
      "loss: 0.123935  [    0/   28]\n",
      "loss: 0.123883  [    0/   28]\n",
      "loss: 0.123832  [    0/   28]\n",
      "loss: 0.123781  [    0/   28]\n",
      "loss: 0.123729  [    0/   28]\n",
      "loss: 0.123680  [    0/   28]\n",
      "loss: 0.123627  [    0/   28]\n",
      "loss: 0.123577  [    0/   28]\n",
      "loss: 0.123525  [    0/   28]\n",
      "loss: 0.123474  [    0/   28]\n",
      "loss: 0.123425  [    0/   28]\n",
      "loss: 0.123372  [    0/   28]\n",
      "loss: 0.123322  [    0/   28]\n",
      "loss: 0.123271  [    0/   28]\n",
      "loss: 0.123220  [    0/   28]\n",
      "loss: 0.123170  [    0/   28]\n",
      "loss: 0.123120  [    0/   28]\n",
      "loss: 0.123068  [    0/   28]\n",
      "loss: 0.123018  [    0/   28]\n",
      "loss: 0.122967  [    0/   28]\n",
      "loss: 0.122917  [    0/   28]\n",
      "loss: 0.122865  [    0/   28]\n",
      "loss: 0.122815  [    0/   28]\n",
      "loss: 0.122765  [    0/   28]\n",
      "loss: 0.122715  [    0/   28]\n",
      "loss: 0.122663  [    0/   28]\n",
      "loss: 0.122612  [    0/   28]\n",
      "loss: 0.122562  [    0/   28]\n",
      "loss: 0.122514  [    0/   28]\n",
      "loss: 0.122462  [    0/   28]\n",
      "loss: 0.122412  [    0/   28]\n",
      "loss: 0.122360  [    0/   28]\n",
      "loss: 0.122311  [    0/   28]\n",
      "loss: 0.122261  [    0/   28]\n",
      "loss: 0.122210  [    0/   28]\n",
      "loss: 0.122158  [    0/   28]\n",
      "loss: 0.122110  [    0/   28]\n",
      "loss: 0.122059  [    0/   28]\n",
      "loss: 0.122009  [    0/   28]\n",
      "loss: 0.121959  [    0/   28]\n",
      "loss: 0.121910  [    0/   28]\n",
      "loss: 0.121857  [    0/   28]\n",
      "loss: 0.121808  [    0/   28]\n",
      "loss: 0.121758  [    0/   28]\n",
      "loss: 0.121709  [    0/   28]\n",
      "loss: 0.121660  [    0/   28]\n",
      "loss: 0.121607  [    0/   28]\n",
      "loss: 0.121557  [    0/   28]\n",
      "loss: 0.121509  [    0/   28]\n",
      "loss: 0.121460  [    0/   28]\n",
      "loss: 0.121408  [    0/   28]\n",
      "loss: 0.121358  [    0/   28]\n",
      "loss: 0.121310  [    0/   28]\n",
      "loss: 0.121258  [    0/   28]\n",
      "loss: 0.121209  [    0/   28]\n",
      "loss: 0.121162  [    0/   28]\n",
      "loss: 0.121110  [    0/   28]\n",
      "loss: 0.121058  [    0/   28]\n",
      "loss: 0.121011  [    0/   28]\n",
      "loss: 0.120963  [    0/   28]\n",
      "loss: 0.120911  [    0/   28]\n",
      "loss: 0.120861  [    0/   28]\n",
      "loss: 0.120813  [    0/   28]\n",
      "loss: 0.120762  [    0/   28]\n",
      "loss: 0.120713  [    0/   28]\n",
      "loss: 0.120665  [    0/   28]\n",
      "loss: 0.120615  [    0/   28]\n",
      "loss: 0.120565  [    0/   28]\n",
      "loss: 0.120516  [    0/   28]\n",
      "loss: 0.120465  [    0/   28]\n",
      "loss: 0.120419  [    0/   28]\n",
      "loss: 0.120367  [    0/   28]\n",
      "loss: 0.120318  [    0/   28]\n",
      "loss: 0.120269  [    0/   28]\n",
      "loss: 0.120220  [    0/   28]\n",
      "loss: 0.120171  [    0/   28]\n",
      "loss: 0.120121  [    0/   28]\n",
      "loss: 0.120071  [    0/   28]\n",
      "loss: 0.120022  [    0/   28]\n",
      "loss: 0.119974  [    0/   28]\n",
      "loss: 0.119924  [    0/   28]\n",
      "loss: 0.119878  [    0/   28]\n",
      "loss: 0.119828  [    0/   28]\n",
      "loss: 0.119778  [    0/   28]\n",
      "loss: 0.119731  [    0/   28]\n",
      "loss: 0.119681  [    0/   28]\n",
      "loss: 0.119631  [    0/   28]\n",
      "loss: 0.119583  [    0/   28]\n",
      "loss: 0.119533  [    0/   28]\n",
      "loss: 0.119485  [    0/   28]\n",
      "loss: 0.119438  [    0/   28]\n",
      "loss: 0.119388  [    0/   28]\n",
      "loss: 0.119339  [    0/   28]\n",
      "loss: 0.119290  [    0/   28]\n",
      "loss: 0.119243  [    0/   28]\n",
      "loss: 0.119195  [    0/   28]\n",
      "loss: 0.119145  [    0/   28]\n",
      "loss: 0.119096  [    0/   28]\n",
      "loss: 0.119048  [    0/   28]\n",
      "loss: 0.119000  [    0/   28]\n",
      "loss: 0.118952  [    0/   28]\n",
      "loss: 0.118903  [    0/   28]\n",
      "loss: 0.118855  [    0/   28]\n",
      "loss: 0.118807  [    0/   28]\n",
      "loss: 0.118757  [    0/   28]\n",
      "loss: 0.118709  [    0/   28]\n",
      "loss: 0.118661  [    0/   28]\n",
      "loss: 0.118616  [    0/   28]\n",
      "loss: 0.118565  [    0/   28]\n",
      "loss: 0.118518  [    0/   28]\n",
      "loss: 0.118470  [    0/   28]\n",
      "loss: 0.118421  [    0/   28]\n",
      "loss: 0.118372  [    0/   28]\n",
      "loss: 0.118324  [    0/   28]\n",
      "loss: 0.118277  [    0/   28]\n",
      "loss: 0.118231  [    0/   28]\n",
      "loss: 0.118181  [    0/   28]\n",
      "loss: 0.118133  [    0/   28]\n",
      "loss: 0.118085  [    0/   28]\n",
      "loss: 0.118038  [    0/   28]\n",
      "loss: 0.117989  [    0/   28]\n",
      "loss: 0.117942  [    0/   28]\n",
      "loss: 0.117893  [    0/   28]\n",
      "loss: 0.117846  [    0/   28]\n",
      "loss: 0.117798  [    0/   28]\n",
      "loss: 0.117750  [    0/   28]\n",
      "loss: 0.117702  [    0/   28]\n",
      "loss: 0.117658  [    0/   28]\n",
      "loss: 0.117609  [    0/   28]\n",
      "loss: 0.117560  [    0/   28]\n",
      "loss: 0.117515  [    0/   28]\n",
      "loss: 0.117466  [    0/   28]\n",
      "loss: 0.117418  [    0/   28]\n",
      "loss: 0.117371  [    0/   28]\n",
      "loss: 0.117323  [    0/   28]\n",
      "loss: 0.117275  [    0/   28]\n",
      "loss: 0.117231  [    0/   28]\n",
      "loss: 0.117183  [    0/   28]\n",
      "loss: 0.117134  [    0/   28]\n",
      "loss: 0.117086  [    0/   28]\n",
      "loss: 0.117040  [    0/   28]\n",
      "loss: 0.116994  [    0/   28]\n",
      "loss: 0.116945  [    0/   28]\n",
      "loss: 0.116898  [    0/   28]\n",
      "loss: 0.116850  [    0/   28]\n",
      "loss: 0.116803  [    0/   28]\n",
      "loss: 0.116755  [    0/   28]\n",
      "loss: 0.116712  [    0/   28]\n",
      "loss: 0.116662  [    0/   28]\n",
      "loss: 0.116617  [    0/   28]\n",
      "loss: 0.116569  [    0/   28]\n",
      "loss: 0.116523  [    0/   28]\n",
      "loss: 0.116474  [    0/   28]\n",
      "loss: 0.116427  [    0/   28]\n",
      "loss: 0.116381  [    0/   28]\n",
      "loss: 0.116335  [    0/   28]\n",
      "loss: 0.116289  [    0/   28]\n",
      "loss: 0.116241  [    0/   28]\n",
      "loss: 0.116194  [    0/   28]\n",
      "loss: 0.116147  [    0/   28]\n",
      "loss: 0.116100  [    0/   28]\n",
      "loss: 0.116053  [    0/   28]\n",
      "loss: 0.116007  [    0/   28]\n",
      "loss: 0.115963  [    0/   28]\n",
      "loss: 0.115913  [    0/   28]\n",
      "loss: 0.115867  [    0/   28]\n",
      "loss: 0.115821  [    0/   28]\n",
      "loss: 0.115775  [    0/   28]\n",
      "loss: 0.115730  [    0/   28]\n",
      "loss: 0.115680  [    0/   28]\n",
      "loss: 0.115635  [    0/   28]\n",
      "loss: 0.115589  [    0/   28]\n",
      "loss: 0.115544  [    0/   28]\n",
      "loss: 0.115496  [    0/   28]\n",
      "loss: 0.115448  [    0/   28]\n",
      "loss: 0.115403  [    0/   28]\n",
      "loss: 0.115358  [    0/   28]\n",
      "loss: 0.115310  [    0/   28]\n",
      "loss: 0.115266  [    0/   28]\n",
      "loss: 0.115219  [    0/   28]\n",
      "loss: 0.115173  [    0/   28]\n",
      "loss: 0.115126  [    0/   28]\n",
      "loss: 0.115079  [    0/   28]\n",
      "loss: 0.115034  [    0/   28]\n",
      "loss: 0.114986  [    0/   28]\n",
      "loss: 0.114941  [    0/   28]\n",
      "loss: 0.114895  [    0/   28]\n",
      "loss: 0.114851  [    0/   28]\n",
      "loss: 0.114803  [    0/   28]\n",
      "loss: 0.114758  [    0/   28]\n",
      "loss: 0.114710  [    0/   28]\n",
      "loss: 0.114666  [    0/   28]\n",
      "loss: 0.114622  [    0/   28]\n",
      "loss: 0.114575  [    0/   28]\n",
      "loss: 0.114528  [    0/   28]\n",
      "loss: 0.114482  [    0/   28]\n",
      "loss: 0.114438  [    0/   28]\n",
      "loss: 0.114391  [    0/   28]\n",
      "loss: 0.114345  [    0/   28]\n",
      "loss: 0.114299  [    0/   28]\n",
      "loss: 0.114254  [    0/   28]\n",
      "loss: 0.114209  [    0/   28]\n",
      "loss: 0.114163  [    0/   28]\n",
      "loss: 0.114117  [    0/   28]\n",
      "loss: 0.114071  [    0/   28]\n",
      "loss: 0.114025  [    0/   28]\n",
      "loss: 0.113980  [    0/   28]\n",
      "loss: 0.113936  [    0/   28]\n",
      "loss: 0.113890  [    0/   28]\n",
      "loss: 0.113844  [    0/   28]\n",
      "loss: 0.113798  [    0/   28]\n",
      "loss: 0.113752  [    0/   28]\n",
      "loss: 0.113708  [    0/   28]\n",
      "loss: 0.113663  [    0/   28]\n",
      "loss: 0.113618  [    0/   28]\n",
      "loss: 0.113571  [    0/   28]\n",
      "loss: 0.113525  [    0/   28]\n",
      "loss: 0.113481  [    0/   28]\n",
      "loss: 0.113437  [    0/   28]\n",
      "loss: 0.113391  [    0/   28]\n",
      "loss: 0.113345  [    0/   28]\n",
      "loss: 0.113300  [    0/   28]\n",
      "loss: 0.113255  [    0/   28]\n",
      "loss: 0.113209  [    0/   28]\n",
      "loss: 0.113164  [    0/   28]\n",
      "loss: 0.113121  [    0/   28]\n",
      "loss: 0.113075  [    0/   28]\n",
      "loss: 0.113030  [    0/   28]\n",
      "loss: 0.112985  [    0/   28]\n",
      "loss: 0.112939  [    0/   28]\n",
      "loss: 0.112895  [    0/   28]\n",
      "loss: 0.112849  [    0/   28]\n",
      "loss: 0.112805  [    0/   28]\n",
      "loss: 0.112760  [    0/   28]\n",
      "loss: 0.112716  [    0/   28]\n",
      "loss: 0.112671  [    0/   28]\n",
      "loss: 0.112626  [    0/   28]\n",
      "loss: 0.112581  [    0/   28]\n",
      "loss: 0.112536  [    0/   28]\n",
      "loss: 0.112493  [    0/   28]\n",
      "loss: 0.112445  [    0/   28]\n",
      "loss: 0.112403  [    0/   28]\n",
      "loss: 0.112357  [    0/   28]\n",
      "loss: 0.112314  [    0/   28]\n",
      "loss: 0.112269  [    0/   28]\n",
      "loss: 0.112223  [    0/   28]\n",
      "loss: 0.112179  [    0/   28]\n",
      "loss: 0.112134  [    0/   28]\n",
      "loss: 0.112091  [    0/   28]\n",
      "loss: 0.112046  [    0/   28]\n",
      "loss: 0.112002  [    0/   28]\n",
      "loss: 0.111958  [    0/   28]\n",
      "loss: 0.111913  [    0/   28]\n",
      "loss: 0.111869  [    0/   28]\n",
      "loss: 0.111825  [    0/   28]\n",
      "loss: 0.111780  [    0/   28]\n",
      "loss: 0.111736  [    0/   28]\n",
      "loss: 0.111693  [    0/   28]\n",
      "loss: 0.111647  [    0/   28]\n",
      "loss: 0.111604  [    0/   28]\n",
      "loss: 0.111559  [    0/   28]\n",
      "loss: 0.111515  [    0/   28]\n",
      "loss: 0.111472  [    0/   28]\n",
      "loss: 0.111429  [    0/   28]\n",
      "loss: 0.111382  [    0/   28]\n",
      "loss: 0.111341  [    0/   28]\n",
      "loss: 0.111295  [    0/   28]\n",
      "loss: 0.111252  [    0/   28]\n",
      "loss: 0.111208  [    0/   28]\n",
      "loss: 0.111165  [    0/   28]\n",
      "loss: 0.111120  [    0/   28]\n",
      "loss: 0.111076  [    0/   28]\n",
      "loss: 0.111033  [    0/   28]\n",
      "loss: 0.110988  [    0/   28]\n",
      "loss: 0.110945  [    0/   28]\n",
      "loss: 0.110901  [    0/   28]\n",
      "loss: 0.110857  [    0/   28]\n",
      "loss: 0.110813  [    0/   28]\n",
      "loss: 0.110772  [    0/   28]\n",
      "loss: 0.110727  [    0/   28]\n",
      "loss: 0.110684  [    0/   28]\n",
      "loss: 0.110639  [    0/   28]\n",
      "loss: 0.110596  [    0/   28]\n",
      "loss: 0.110552  [    0/   28]\n",
      "loss: 0.110508  [    0/   28]\n",
      "loss: 0.110466  [    0/   28]\n",
      "loss: 0.110422  [    0/   28]\n",
      "loss: 0.110379  [    0/   28]\n",
      "loss: 0.110335  [    0/   28]\n",
      "loss: 0.110292  [    0/   28]\n",
      "loss: 0.110248  [    0/   28]\n",
      "loss: 0.110204  [    0/   28]\n",
      "loss: 0.110161  [    0/   28]\n",
      "loss: 0.110120  [    0/   28]\n",
      "loss: 0.110074  [    0/   28]\n",
      "loss: 0.110031  [    0/   28]\n",
      "loss: 0.109988  [    0/   28]\n",
      "loss: 0.109946  [    0/   28]\n",
      "loss: 0.109902  [    0/   28]\n",
      "loss: 0.109859  [    0/   28]\n",
      "loss: 0.109816  [    0/   28]\n",
      "loss: 0.109772  [    0/   28]\n",
      "loss: 0.109729  [    0/   28]\n",
      "loss: 0.109688  [    0/   28]\n",
      "loss: 0.109643  [    0/   28]\n",
      "loss: 0.109601  [    0/   28]\n",
      "loss: 0.109558  [    0/   28]\n",
      "loss: 0.109515  [    0/   28]\n",
      "loss: 0.109471  [    0/   28]\n",
      "loss: 0.109427  [    0/   28]\n",
      "loss: 0.109386  [    0/   28]\n",
      "loss: 0.109344  [    0/   28]\n",
      "loss: 0.109301  [    0/   28]\n",
      "loss: 0.109257  [    0/   28]\n",
      "loss: 0.109215  [    0/   28]\n",
      "loss: 0.109172  [    0/   28]\n",
      "loss: 0.109129  [    0/   28]\n",
      "loss: 0.109088  [    0/   28]\n",
      "loss: 0.109043  [    0/   28]\n",
      "loss: 0.109001  [    0/   28]\n",
      "loss: 0.108960  [    0/   28]\n",
      "loss: 0.108916  [    0/   28]\n",
      "loss: 0.108873  [    0/   28]\n",
      "loss: 0.108833  [    0/   28]\n",
      "loss: 0.108789  [    0/   28]\n",
      "loss: 0.108747  [    0/   28]\n",
      "loss: 0.108703  [    0/   28]\n",
      "loss: 0.108661  [    0/   28]\n",
      "loss: 0.108619  [    0/   28]\n",
      "loss: 0.108576  [    0/   28]\n",
      "loss: 0.108534  [    0/   28]\n",
      "loss: 0.108492  [    0/   28]\n",
      "loss: 0.108451  [    0/   28]\n",
      "loss: 0.108407  [    0/   28]\n",
      "loss: 0.108365  [    0/   28]\n",
      "loss: 0.108323  [    0/   28]\n",
      "loss: 0.108280  [    0/   28]\n",
      "loss: 0.108238  [    0/   28]\n",
      "loss: 0.108197  [    0/   28]\n",
      "loss: 0.108153  [    0/   28]\n",
      "loss: 0.108112  [    0/   28]\n",
      "loss: 0.108070  [    0/   28]\n",
      "loss: 0.108029  [    0/   28]\n",
      "loss: 0.107984  [    0/   28]\n",
      "loss: 0.107944  [    0/   28]\n",
      "loss: 0.107903  [    0/   28]\n",
      "loss: 0.107861  [    0/   28]\n",
      "loss: 0.107817  [    0/   28]\n",
      "loss: 0.107774  [    0/   28]\n",
      "loss: 0.107733  [    0/   28]\n",
      "loss: 0.107693  [    0/   28]\n",
      "loss: 0.107649  [    0/   28]\n",
      "loss: 0.107609  [    0/   28]\n",
      "loss: 0.107566  [    0/   28]\n",
      "loss: 0.107525  [    0/   28]\n",
      "loss: 0.107481  [    0/   28]\n",
      "loss: 0.107440  [    0/   28]\n",
      "loss: 0.107400  [    0/   28]\n",
      "loss: 0.107357  [    0/   28]\n",
      "loss: 0.107315  [    0/   28]\n",
      "loss: 0.107273  [    0/   28]\n",
      "loss: 0.107234  [    0/   28]\n",
      "loss: 0.107190  [    0/   28]\n",
      "loss: 0.107149  [    0/   28]\n",
      "loss: 0.107107  [    0/   28]\n",
      "loss: 0.107067  [    0/   28]\n",
      "loss: 0.107024  [    0/   28]\n",
      "loss: 0.106983  [    0/   28]\n",
      "loss: 0.106941  [    0/   28]\n",
      "loss: 0.106900  [    0/   28]\n",
      "loss: 0.106859  [    0/   28]\n",
      "loss: 0.106817  [    0/   28]\n",
      "loss: 0.106777  [    0/   28]\n",
      "loss: 0.106734  [    0/   28]\n",
      "loss: 0.106692  [    0/   28]\n",
      "loss: 0.106652  [    0/   28]\n",
      "loss: 0.106611  [    0/   28]\n",
      "loss: 0.106569  [    0/   28]\n",
      "loss: 0.106528  [    0/   28]\n",
      "loss: 0.106487  [    0/   28]\n",
      "loss: 0.106445  [    0/   28]\n",
      "loss: 0.106405  [    0/   28]\n",
      "loss: 0.106361  [    0/   28]\n",
      "loss: 0.106322  [    0/   28]\n",
      "loss: 0.106281  [    0/   28]\n",
      "loss: 0.106240  [    0/   28]\n",
      "loss: 0.106199  [    0/   28]\n",
      "loss: 0.106157  [    0/   28]\n",
      "loss: 0.106116  [    0/   28]\n",
      "loss: 0.106076  [    0/   28]\n",
      "loss: 0.106033  [    0/   28]\n",
      "loss: 0.105993  [    0/   28]\n",
      "loss: 0.105954  [    0/   28]\n",
      "loss: 0.105912  [    0/   28]\n",
      "loss: 0.105872  [    0/   28]\n",
      "loss: 0.105830  [    0/   28]\n",
      "loss: 0.105788  [    0/   28]\n",
      "loss: 0.105747  [    0/   28]\n",
      "loss: 0.105708  [    0/   28]\n",
      "loss: 0.105666  [    0/   28]\n",
      "loss: 0.105627  [    0/   28]\n",
      "loss: 0.105586  [    0/   28]\n",
      "loss: 0.105543  [    0/   28]\n",
      "loss: 0.105502  [    0/   28]\n",
      "loss: 0.105463  [    0/   28]\n",
      "loss: 0.105422  [    0/   28]\n",
      "loss: 0.105383  [    0/   28]\n",
      "loss: 0.105340  [    0/   28]\n",
      "loss: 0.105299  [    0/   28]\n",
      "loss: 0.105259  [    0/   28]\n",
      "loss: 0.105219  [    0/   28]\n",
      "loss: 0.105179  [    0/   28]\n",
      "loss: 0.105138  [    0/   28]\n",
      "loss: 0.105097  [    0/   28]\n",
      "loss: 0.105057  [    0/   28]\n",
      "loss: 0.105017  [    0/   28]\n",
      "loss: 0.104976  [    0/   28]\n",
      "loss: 0.104934  [    0/   28]\n",
      "loss: 0.104894  [    0/   28]\n",
      "loss: 0.104855  [    0/   28]\n",
      "loss: 0.104814  [    0/   28]\n",
      "loss: 0.104775  [    0/   28]\n",
      "loss: 0.104734  [    0/   28]\n",
      "loss: 0.104694  [    0/   28]\n",
      "loss: 0.104653  [    0/   28]\n",
      "loss: 0.104613  [    0/   28]\n",
      "loss: 0.104573  [    0/   28]\n",
      "loss: 0.104534  [    0/   28]\n",
      "loss: 0.104492  [    0/   28]\n",
      "loss: 0.104454  [    0/   28]\n",
      "loss: 0.104413  [    0/   28]\n",
      "loss: 0.104371  [    0/   28]\n",
      "loss: 0.104332  [    0/   28]\n",
      "loss: 0.104292  [    0/   28]\n",
      "loss: 0.104253  [    0/   28]\n",
      "loss: 0.104212  [    0/   28]\n",
      "loss: 0.104172  [    0/   28]\n",
      "loss: 0.104133  [    0/   28]\n",
      "loss: 0.104091  [    0/   28]\n",
      "loss: 0.104054  [    0/   28]\n",
      "loss: 0.104012  [    0/   28]\n",
      "loss: 0.103973  [    0/   28]\n",
      "loss: 0.103933  [    0/   28]\n",
      "loss: 0.103893  [    0/   28]\n",
      "loss: 0.103853  [    0/   28]\n",
      "loss: 0.103813  [    0/   28]\n",
      "loss: 0.103774  [    0/   28]\n",
      "loss: 0.103734  [    0/   28]\n",
      "loss: 0.103694  [    0/   28]\n",
      "loss: 0.103654  [    0/   28]\n",
      "loss: 0.103615  [    0/   28]\n",
      "loss: 0.103575  [    0/   28]\n",
      "loss: 0.103534  [    0/   28]\n",
      "loss: 0.103496  [    0/   28]\n",
      "loss: 0.103457  [    0/   28]\n",
      "loss: 0.103417  [    0/   28]\n",
      "loss: 0.103377  [    0/   28]\n",
      "loss: 0.103337  [    0/   28]\n",
      "loss: 0.103298  [    0/   28]\n",
      "loss: 0.103258  [    0/   28]\n",
      "loss: 0.103218  [    0/   28]\n",
      "loss: 0.103181  [    0/   28]\n",
      "loss: 0.103140  [    0/   28]\n",
      "loss: 0.103101  [    0/   28]\n",
      "loss: 0.103060  [    0/   28]\n",
      "loss: 0.103021  [    0/   28]\n",
      "loss: 0.102981  [    0/   28]\n",
      "loss: 0.102942  [    0/   28]\n",
      "loss: 0.102905  [    0/   28]\n",
      "loss: 0.102866  [    0/   28]\n",
      "loss: 0.102826  [    0/   28]\n",
      "loss: 0.102786  [    0/   28]\n",
      "loss: 0.102747  [    0/   28]\n",
      "loss: 0.102708  [    0/   28]\n",
      "loss: 0.102669  [    0/   28]\n",
      "loss: 0.102628  [    0/   28]\n",
      "loss: 0.102590  [    0/   28]\n",
      "loss: 0.102552  [    0/   28]\n",
      "loss: 0.102512  [    0/   28]\n",
      "loss: 0.102472  [    0/   28]\n",
      "loss: 0.102434  [    0/   28]\n",
      "loss: 0.102395  [    0/   28]\n",
      "loss: 0.102355  [    0/   28]\n",
      "loss: 0.102317  [    0/   28]\n",
      "loss: 0.102277  [    0/   28]\n",
      "loss: 0.102240  [    0/   28]\n",
      "loss: 0.102200  [    0/   28]\n",
      "loss: 0.102162  [    0/   28]\n",
      "loss: 0.102123  [    0/   28]\n",
      "loss: 0.102083  [    0/   28]\n",
      "loss: 0.102045  [    0/   28]\n",
      "loss: 0.102006  [    0/   28]\n",
      "loss: 0.101967  [    0/   28]\n",
      "loss: 0.101930  [    0/   28]\n",
      "loss: 0.101890  [    0/   28]\n",
      "loss: 0.101851  [    0/   28]\n",
      "loss: 0.101812  [    0/   28]\n",
      "loss: 0.101773  [    0/   28]\n",
      "loss: 0.101735  [    0/   28]\n",
      "loss: 0.101696  [    0/   28]\n",
      "loss: 0.101658  [    0/   28]\n",
      "loss: 0.101619  [    0/   28]\n",
      "loss: 0.101581  [    0/   28]\n",
      "loss: 0.101541  [    0/   28]\n",
      "loss: 0.101503  [    0/   28]\n",
      "loss: 0.101464  [    0/   28]\n",
      "loss: 0.101426  [    0/   28]\n",
      "loss: 0.101388  [    0/   28]\n",
      "loss: 0.101349  [    0/   28]\n",
      "loss: 0.101311  [    0/   28]\n",
      "loss: 0.101272  [    0/   28]\n",
      "loss: 0.101234  [    0/   28]\n",
      "loss: 0.101196  [    0/   28]\n",
      "loss: 0.101158  [    0/   28]\n",
      "loss: 0.101118  [    0/   28]\n",
      "loss: 0.101080  [    0/   28]\n",
      "loss: 0.101042  [    0/   28]\n",
      "loss: 0.101004  [    0/   28]\n",
      "loss: 0.100965  [    0/   28]\n",
      "loss: 0.100928  [    0/   28]\n",
      "loss: 0.100890  [    0/   28]\n",
      "loss: 0.100852  [    0/   28]\n",
      "loss: 0.100812  [    0/   28]\n",
      "loss: 0.100774  [    0/   28]\n",
      "loss: 0.100736  [    0/   28]\n",
      "loss: 0.100699  [    0/   28]\n",
      "loss: 0.100661  [    0/   28]\n",
      "loss: 0.100622  [    0/   28]\n",
      "loss: 0.100584  [    0/   28]\n",
      "loss: 0.100546  [    0/   28]\n",
      "loss: 0.100508  [    0/   28]\n",
      "loss: 0.100470  [    0/   28]\n",
      "loss: 0.100431  [    0/   28]\n",
      "loss: 0.100394  [    0/   28]\n",
      "loss: 0.100356  [    0/   28]\n",
      "loss: 0.100319  [    0/   28]\n",
      "loss: 0.100281  [    0/   28]\n",
      "loss: 0.100242  [    0/   28]\n",
      "loss: 0.100205  [    0/   28]\n",
      "loss: 0.100166  [    0/   28]\n",
      "loss: 0.100128  [    0/   28]\n",
      "loss: 0.100091  [    0/   28]\n",
      "loss: 0.100054  [    0/   28]\n",
      "loss: 0.100016  [    0/   28]\n",
      "loss: 0.099978  [    0/   28]\n",
      "loss: 0.099940  [    0/   28]\n",
      "loss: 0.099901  [    0/   28]\n",
      "loss: 0.099863  [    0/   28]\n",
      "loss: 0.099827  [    0/   28]\n",
      "loss: 0.099790  [    0/   28]\n",
      "loss: 0.099753  [    0/   28]\n",
      "loss: 0.099713  [    0/   28]\n",
      "loss: 0.099677  [    0/   28]\n",
      "loss: 0.099639  [    0/   28]\n",
      "loss: 0.099602  [    0/   28]\n",
      "loss: 0.099564  [    0/   28]\n",
      "loss: 0.099526  [    0/   28]\n",
      "loss: 0.099490  [    0/   28]\n",
      "loss: 0.099451  [    0/   28]\n",
      "loss: 0.099413  [    0/   28]\n",
      "loss: 0.099375  [    0/   28]\n",
      "loss: 0.099341  [    0/   28]\n",
      "loss: 0.099301  [    0/   28]\n",
      "loss: 0.099265  [    0/   28]\n",
      "loss: 0.099228  [    0/   28]\n",
      "loss: 0.099190  [    0/   28]\n",
      "loss: 0.099152  [    0/   28]\n",
      "loss: 0.099115  [    0/   28]\n",
      "loss: 0.099077  [    0/   28]\n",
      "loss: 0.099040  [    0/   28]\n",
      "loss: 0.099004  [    0/   28]\n",
      "loss: 0.098966  [    0/   28]\n",
      "loss: 0.098929  [    0/   28]\n",
      "loss: 0.098891  [    0/   28]\n",
      "loss: 0.098855  [    0/   28]\n",
      "loss: 0.098819  [    0/   28]\n",
      "loss: 0.098779  [    0/   28]\n",
      "loss: 0.098742  [    0/   28]\n",
      "loss: 0.098706  [    0/   28]\n",
      "loss: 0.098669  [    0/   28]\n",
      "loss: 0.098632  [    0/   28]\n",
      "loss: 0.098594  [    0/   28]\n",
      "loss: 0.098556  [    0/   28]\n",
      "loss: 0.098521  [    0/   28]\n",
      "loss: 0.098483  [    0/   28]\n",
      "loss: 0.098447  [    0/   28]\n",
      "loss: 0.098409  [    0/   28]\n",
      "loss: 0.098372  [    0/   28]\n",
      "loss: 0.098336  [    0/   28]\n",
      "loss: 0.098299  [    0/   28]\n",
      "loss: 0.098261  [    0/   28]\n",
      "loss: 0.098224  [    0/   28]\n",
      "loss: 0.098188  [    0/   28]\n",
      "loss: 0.098151  [    0/   28]\n",
      "loss: 0.098113  [    0/   28]\n",
      "loss: 0.098077  [    0/   28]\n",
      "loss: 0.098042  [    0/   28]\n",
      "loss: 0.098005  [    0/   28]\n",
      "loss: 0.097968  [    0/   28]\n",
      "loss: 0.097930  [    0/   28]\n",
      "loss: 0.097894  [    0/   28]\n",
      "loss: 0.097857  [    0/   28]\n",
      "loss: 0.097820  [    0/   28]\n",
      "loss: 0.097783  [    0/   28]\n",
      "loss: 0.097747  [    0/   28]\n",
      "loss: 0.097712  [    0/   28]\n",
      "loss: 0.097673  [    0/   28]\n",
      "loss: 0.097638  [    0/   28]\n",
      "loss: 0.097601  [    0/   28]\n",
      "loss: 0.097565  [    0/   28]\n",
      "loss: 0.097527  [    0/   28]\n",
      "loss: 0.097491  [    0/   28]\n",
      "loss: 0.097456  [    0/   28]\n",
      "loss: 0.097419  [    0/   28]\n",
      "loss: 0.097381  [    0/   28]\n",
      "loss: 0.097347  [    0/   28]\n",
      "loss: 0.097309  [    0/   28]\n",
      "loss: 0.097272  [    0/   28]\n",
      "loss: 0.097236  [    0/   28]\n",
      "loss: 0.097201  [    0/   28]\n",
      "loss: 0.097164  [    0/   28]\n",
      "loss: 0.097128  [    0/   28]\n",
      "loss: 0.097091  [    0/   28]\n",
      "loss: 0.097055  [    0/   28]\n",
      "loss: 0.097017  [    0/   28]\n",
      "loss: 0.096982  [    0/   28]\n",
      "loss: 0.096947  [    0/   28]\n",
      "loss: 0.096911  [    0/   28]\n",
      "loss: 0.096874  [    0/   28]\n",
      "loss: 0.096838  [    0/   28]\n",
      "loss: 0.096801  [    0/   28]\n",
      "loss: 0.096766  [    0/   28]\n",
      "loss: 0.096729  [    0/   28]\n",
      "loss: 0.096694  [    0/   28]\n",
      "loss: 0.096658  [    0/   28]\n",
      "loss: 0.096624  [    0/   28]\n",
      "loss: 0.096585  [    0/   28]\n",
      "loss: 0.096550  [    0/   28]\n",
      "loss: 0.096514  [    0/   28]\n",
      "loss: 0.096479  [    0/   28]\n",
      "loss: 0.096442  [    0/   28]\n",
      "loss: 0.096406  [    0/   28]\n",
      "loss: 0.096371  [    0/   28]\n",
      "loss: 0.096336  [    0/   28]\n",
      "loss: 0.096299  [    0/   28]\n",
      "loss: 0.096264  [    0/   28]\n",
      "loss: 0.096227  [    0/   28]\n",
      "loss: 0.096193  [    0/   28]\n",
      "loss: 0.096156  [    0/   28]\n",
      "loss: 0.096121  [    0/   28]\n",
      "loss: 0.096085  [    0/   28]\n",
      "loss: 0.096049  [    0/   28]\n",
      "loss: 0.096012  [    0/   28]\n",
      "loss: 0.095978  [    0/   28]\n",
      "loss: 0.095944  [    0/   28]\n",
      "loss: 0.095907  [    0/   28]\n",
      "loss: 0.095872  [    0/   28]\n",
      "loss: 0.095836  [    0/   28]\n",
      "loss: 0.095800  [    0/   28]\n",
      "loss: 0.095764  [    0/   28]\n",
      "loss: 0.095729  [    0/   28]\n",
      "loss: 0.095695  [    0/   28]\n",
      "loss: 0.095658  [    0/   28]\n",
      "loss: 0.095623  [    0/   28]\n",
      "loss: 0.095587  [    0/   28]\n",
      "loss: 0.095552  [    0/   28]\n",
      "loss: 0.095515  [    0/   28]\n",
      "loss: 0.095481  [    0/   28]\n",
      "loss: 0.095447  [    0/   28]\n",
      "loss: 0.095410  [    0/   28]\n",
      "loss: 0.095374  [    0/   28]\n",
      "loss: 0.095340  [    0/   28]\n",
      "loss: 0.095305  [    0/   28]\n",
      "loss: 0.095270  [    0/   28]\n",
      "loss: 0.095233  [    0/   28]\n",
      "loss: 0.095199  [    0/   28]\n",
      "loss: 0.095165  [    0/   28]\n",
      "loss: 0.095128  [    0/   28]\n",
      "loss: 0.095093  [    0/   28]\n",
      "loss: 0.095058  [    0/   28]\n",
      "loss: 0.095023  [    0/   28]\n",
      "loss: 0.094988  [    0/   28]\n",
      "loss: 0.094952  [    0/   28]\n",
      "loss: 0.094918  [    0/   28]\n",
      "loss: 0.094883  [    0/   28]\n",
      "loss: 0.094848  [    0/   28]\n",
      "loss: 0.094814  [    0/   28]\n",
      "loss: 0.094778  [    0/   28]\n",
      "loss: 0.094742  [    0/   28]\n",
      "loss: 0.094707  [    0/   28]\n",
      "loss: 0.094673  [    0/   28]\n",
      "loss: 0.094638  [    0/   28]\n",
      "loss: 0.094604  [    0/   28]\n",
      "loss: 0.094568  [    0/   28]\n",
      "loss: 0.094534  [    0/   28]\n",
      "loss: 0.094499  [    0/   28]\n",
      "loss: 0.094463  [    0/   28]\n",
      "loss: 0.094428  [    0/   28]\n",
      "loss: 0.094394  [    0/   28]\n",
      "loss: 0.094360  [    0/   28]\n",
      "loss: 0.094325  [    0/   28]\n",
      "loss: 0.094291  [    0/   28]\n",
      "loss: 0.094255  [    0/   28]\n",
      "loss: 0.094221  [    0/   28]\n",
      "loss: 0.094185  [    0/   28]\n",
      "loss: 0.094151  [    0/   28]\n",
      "loss: 0.094116  [    0/   28]\n",
      "loss: 0.094081  [    0/   28]\n",
      "loss: 0.094046  [    0/   28]\n",
      "loss: 0.094012  [    0/   28]\n",
      "loss: 0.093979  [    0/   28]\n",
      "loss: 0.093944  [    0/   28]\n",
      "loss: 0.093908  [    0/   28]\n",
      "loss: 0.093875  [    0/   28]\n",
      "loss: 0.093840  [    0/   28]\n",
      "loss: 0.093806  [    0/   28]\n",
      "loss: 0.093771  [    0/   28]\n",
      "loss: 0.093736  [    0/   28]\n",
      "loss: 0.093702  [    0/   28]\n",
      "loss: 0.093667  [    0/   28]\n",
      "loss: 0.093632  [    0/   28]\n",
      "loss: 0.093599  [    0/   28]\n",
      "loss: 0.093565  [    0/   28]\n",
      "loss: 0.093531  [    0/   28]\n",
      "loss: 0.093496  [    0/   28]\n",
      "loss: 0.093461  [    0/   28]\n",
      "loss: 0.093426  [    0/   28]\n",
      "loss: 0.093392  [    0/   28]\n",
      "loss: 0.093359  [    0/   28]\n",
      "loss: 0.093324  [    0/   28]\n",
      "loss: 0.093291  [    0/   28]\n",
      "loss: 0.093256  [    0/   28]\n",
      "loss: 0.093221  [    0/   28]\n",
      "loss: 0.093187  [    0/   28]\n",
      "loss: 0.093155  [    0/   28]\n",
      "loss: 0.093119  [    0/   28]\n",
      "loss: 0.093086  [    0/   28]\n",
      "loss: 0.093051  [    0/   28]\n",
      "loss: 0.093018  [    0/   28]\n",
      "loss: 0.092983  [    0/   28]\n",
      "loss: 0.092949  [    0/   28]\n",
      "loss: 0.092915  [    0/   28]\n",
      "loss: 0.092880  [    0/   28]\n",
      "loss: 0.092847  [    0/   28]\n",
      "loss: 0.092814  [    0/   28]\n",
      "loss: 0.092780  [    0/   28]\n",
      "loss: 0.092745  [    0/   28]\n",
      "loss: 0.092711  [    0/   28]\n",
      "loss: 0.092678  [    0/   28]\n",
      "loss: 0.092643  [    0/   28]\n",
      "loss: 0.092609  [    0/   28]\n",
      "loss: 0.092575  [    0/   28]\n",
      "loss: 0.092541  [    0/   28]\n",
      "loss: 0.092508  [    0/   28]\n",
      "loss: 0.092476  [    0/   28]\n",
      "loss: 0.092441  [    0/   28]\n",
      "loss: 0.092408  [    0/   28]\n",
      "loss: 0.092373  [    0/   28]\n",
      "loss: 0.092339  [    0/   28]\n",
      "loss: 0.092305  [    0/   28]\n",
      "loss: 0.092271  [    0/   28]\n",
      "loss: 0.092238  [    0/   28]\n",
      "loss: 0.092205  [    0/   28]\n",
      "loss: 0.092171  [    0/   28]\n",
      "loss: 0.092138  [    0/   28]\n",
      "loss: 0.092104  [    0/   28]\n",
      "loss: 0.092070  [    0/   28]\n",
      "loss: 0.092037  [    0/   28]\n",
      "loss: 0.092003  [    0/   28]\n",
      "loss: 0.091969  [    0/   28]\n",
      "loss: 0.091938  [    0/   28]\n",
      "loss: 0.091903  [    0/   28]\n",
      "loss: 0.091869  [    0/   28]\n",
      "loss: 0.091836  [    0/   28]\n",
      "loss: 0.091803  [    0/   28]\n",
      "loss: 0.091771  [    0/   28]\n",
      "loss: 0.091735  [    0/   28]\n",
      "loss: 0.091702  [    0/   28]\n",
      "loss: 0.091669  [    0/   28]\n",
      "loss: 0.091637  [    0/   28]\n",
      "loss: 0.091604  [    0/   28]\n",
      "loss: 0.091570  [    0/   28]\n",
      "loss: 0.091537  [    0/   28]\n",
      "loss: 0.091502  [    0/   28]\n",
      "loss: 0.091470  [    0/   28]\n",
      "loss: 0.091437  [    0/   28]\n",
      "loss: 0.091404  [    0/   28]\n",
      "loss: 0.091371  [    0/   28]\n",
      "loss: 0.091338  [    0/   28]\n",
      "loss: 0.091304  [    0/   28]\n",
      "loss: 0.091270  [    0/   28]\n",
      "loss: 0.091239  [    0/   28]\n",
      "loss: 0.091206  [    0/   28]\n",
      "loss: 0.091172  [    0/   28]\n",
      "loss: 0.091139  [    0/   28]\n",
      "loss: 0.091106  [    0/   28]\n",
      "loss: 0.091073  [    0/   28]\n",
      "loss: 0.091040  [    0/   28]\n",
      "loss: 0.091007  [    0/   28]\n",
      "loss: 0.090974  [    0/   28]\n",
      "loss: 0.090943  [    0/   28]\n",
      "loss: 0.090909  [    0/   28]\n",
      "loss: 0.090876  [    0/   28]\n",
      "loss: 0.090842  [    0/   28]\n",
      "loss: 0.090810  [    0/   28]\n",
      "loss: 0.090777  [    0/   28]\n",
      "loss: 0.090746  [    0/   28]\n",
      "loss: 0.090712  [    0/   28]\n",
      "loss: 0.090679  [    0/   28]\n",
      "loss: 0.090646  [    0/   28]\n",
      "loss: 0.090615  [    0/   28]\n",
      "loss: 0.090581  [    0/   28]\n",
      "loss: 0.090547  [    0/   28]\n",
      "loss: 0.090515  [    0/   28]\n",
      "loss: 0.090483  [    0/   28]\n",
      "loss: 0.090450  [    0/   28]\n",
      "loss: 0.090417  [    0/   28]\n",
      "loss: 0.090386  [    0/   28]\n",
      "loss: 0.090353  [    0/   28]\n",
      "loss: 0.090321  [    0/   28]\n",
      "loss: 0.090286  [    0/   28]\n",
      "loss: 0.090254  [    0/   28]\n",
      "loss: 0.090222  [    0/   28]\n",
      "loss: 0.090190  [    0/   28]\n",
      "loss: 0.090158  [    0/   28]\n",
      "loss: 0.090125  [    0/   28]\n",
      "loss: 0.090092  [    0/   28]\n",
      "loss: 0.090060  [    0/   28]\n",
      "loss: 0.090028  [    0/   28]\n",
      "loss: 0.089995  [    0/   28]\n",
      "loss: 0.089962  [    0/   28]\n",
      "loss: 0.089930  [    0/   28]\n",
      "loss: 0.089898  [    0/   28]\n",
      "loss: 0.089865  [    0/   28]\n",
      "loss: 0.089833  [    0/   28]\n",
      "loss: 0.089800  [    0/   28]\n",
      "loss: 0.089768  [    0/   28]\n",
      "loss: 0.089737  [    0/   28]\n",
      "loss: 0.089705  [    0/   28]\n",
      "loss: 0.089672  [    0/   28]\n",
      "loss: 0.089639  [    0/   28]\n",
      "loss: 0.089608  [    0/   28]\n",
      "loss: 0.089575  [    0/   28]\n",
      "loss: 0.089543  [    0/   28]\n",
      "loss: 0.089511  [    0/   28]\n",
      "loss: 0.089479  [    0/   28]\n",
      "loss: 0.089445  [    0/   28]\n",
      "loss: 0.089415  [    0/   28]\n",
      "loss: 0.089383  [    0/   28]\n",
      "loss: 0.089351  [    0/   28]\n",
      "loss: 0.089318  [    0/   28]\n",
      "loss: 0.089286  [    0/   28]\n",
      "loss: 0.089255  [    0/   28]\n",
      "loss: 0.089222  [    0/   28]\n",
      "loss: 0.089190  [    0/   28]\n",
      "loss: 0.089158  [    0/   28]\n",
      "loss: 0.089126  [    0/   28]\n",
      "loss: 0.089094  [    0/   28]\n",
      "loss: 0.089063  [    0/   28]\n",
      "loss: 0.089031  [    0/   28]\n",
      "loss: 0.088998  [    0/   28]\n",
      "loss: 0.088967  [    0/   28]\n",
      "loss: 0.088935  [    0/   28]\n",
      "loss: 0.088903  [    0/   28]\n",
      "loss: 0.088872  [    0/   28]\n",
      "loss: 0.088839  [    0/   28]\n",
      "loss: 0.088808  [    0/   28]\n",
      "loss: 0.088776  [    0/   28]\n",
      "loss: 0.088744  [    0/   28]\n",
      "loss: 0.088713  [    0/   28]\n",
      "loss: 0.088680  [    0/   28]\n",
      "loss: 0.088648  [    0/   28]\n",
      "loss: 0.088617  [    0/   28]\n",
      "loss: 0.088587  [    0/   28]\n",
      "loss: 0.088556  [    0/   28]\n",
      "loss: 0.088522  [    0/   28]\n",
      "loss: 0.088491  [    0/   28]\n",
      "loss: 0.088460  [    0/   28]\n",
      "loss: 0.088428  [    0/   28]\n",
      "loss: 0.088395  [    0/   28]\n",
      "loss: 0.088365  [    0/   28]\n",
      "loss: 0.088333  [    0/   28]\n",
      "loss: 0.088302  [    0/   28]\n",
      "loss: 0.088270  [    0/   28]\n",
      "loss: 0.088239  [    0/   28]\n",
      "loss: 0.088207  [    0/   28]\n",
      "loss: 0.088176  [    0/   28]\n",
      "loss: 0.088144  [    0/   28]\n",
      "loss: 0.088113  [    0/   28]\n",
      "loss: 0.088083  [    0/   28]\n",
      "loss: 0.088051  [    0/   28]\n",
      "loss: 0.088019  [    0/   28]\n",
      "loss: 0.087988  [    0/   28]\n",
      "loss: 0.087956  [    0/   28]\n",
      "loss: 0.087926  [    0/   28]\n",
      "loss: 0.087893  [    0/   28]\n",
      "loss: 0.087863  [    0/   28]\n",
      "loss: 0.087831  [    0/   28]\n",
      "loss: 0.087801  [    0/   28]\n",
      "loss: 0.087768  [    0/   28]\n",
      "loss: 0.087738  [    0/   28]\n",
      "loss: 0.087707  [    0/   28]\n",
      "loss: 0.087676  [    0/   28]\n",
      "loss: 0.087645  [    0/   28]\n",
      "loss: 0.087613  [    0/   28]\n",
      "loss: 0.087583  [    0/   28]\n",
      "loss: 0.087551  [    0/   28]\n",
      "loss: 0.087521  [    0/   28]\n",
      "loss: 0.087490  [    0/   28]\n",
      "loss: 0.087459  [    0/   28]\n",
      "loss: 0.087427  [    0/   28]\n",
      "loss: 0.087395  [    0/   28]\n",
      "loss: 0.087365  [    0/   28]\n",
      "loss: 0.087334  [    0/   28]\n",
      "loss: 0.087305  [    0/   28]\n",
      "loss: 0.087272  [    0/   28]\n",
      "loss: 0.087241  [    0/   28]\n",
      "loss: 0.087211  [    0/   28]\n",
      "loss: 0.087179  [    0/   28]\n",
      "loss: 0.087149  [    0/   28]\n",
      "loss: 0.087117  [    0/   28]\n",
      "loss: 0.087087  [    0/   28]\n",
      "loss: 0.087056  [    0/   28]\n",
      "loss: 0.087026  [    0/   28]\n",
      "loss: 0.086996  [    0/   28]\n",
      "loss: 0.086965  [    0/   28]\n",
      "loss: 0.086933  [    0/   28]\n",
      "loss: 0.086903  [    0/   28]\n",
      "loss: 0.086873  [    0/   28]\n",
      "loss: 0.086841  [    0/   28]\n",
      "loss: 0.086810  [    0/   28]\n",
      "loss: 0.086779  [    0/   28]\n",
      "loss: 0.086749  [    0/   28]\n",
      "loss: 0.086719  [    0/   28]\n",
      "loss: 0.086688  [    0/   28]\n",
      "loss: 0.086659  [    0/   28]\n",
      "loss: 0.086626  [    0/   28]\n",
      "loss: 0.086596  [    0/   28]\n",
      "loss: 0.086565  [    0/   28]\n",
      "loss: 0.086536  [    0/   28]\n",
      "loss: 0.086505  [    0/   28]\n",
      "loss: 0.086474  [    0/   28]\n",
      "loss: 0.086444  [    0/   28]\n",
      "loss: 0.086413  [    0/   28]\n",
      "loss: 0.086382  [    0/   28]\n",
      "loss: 0.086353  [    0/   28]\n",
      "loss: 0.086323  [    0/   28]\n",
      "loss: 0.086292  [    0/   28]\n",
      "loss: 0.086260  [    0/   28]\n",
      "loss: 0.086231  [    0/   28]\n",
      "loss: 0.086201  [    0/   28]\n",
      "loss: 0.086170  [    0/   28]\n",
      "loss: 0.086139  [    0/   28]\n",
      "loss: 0.086109  [    0/   28]\n",
      "loss: 0.086080  [    0/   28]\n",
      "loss: 0.086050  [    0/   28]\n",
      "loss: 0.086019  [    0/   28]\n",
      "loss: 0.085988  [    0/   28]\n",
      "loss: 0.085959  [    0/   28]\n",
      "loss: 0.085928  [    0/   28]\n",
      "loss: 0.085898  [    0/   28]\n",
      "loss: 0.085869  [    0/   28]\n",
      "loss: 0.085837  [    0/   28]\n",
      "loss: 0.085808  [    0/   28]\n",
      "loss: 0.085777  [    0/   28]\n",
      "loss: 0.085749  [    0/   28]\n",
      "loss: 0.085718  [    0/   28]\n",
      "loss: 0.085686  [    0/   28]\n",
      "loss: 0.085656  [    0/   28]\n",
      "loss: 0.085627  [    0/   28]\n",
      "loss: 0.085598  [    0/   28]\n",
      "loss: 0.085567  [    0/   28]\n",
      "loss: 0.085538  [    0/   28]\n",
      "loss: 0.085508  [    0/   28]\n",
      "loss: 0.085478  [    0/   28]\n",
      "loss: 0.085447  [    0/   28]\n",
      "loss: 0.085417  [    0/   28]\n",
      "loss: 0.085387  [    0/   28]\n",
      "loss: 0.085357  [    0/   28]\n",
      "loss: 0.085327  [    0/   28]\n",
      "loss: 0.085298  [    0/   28]\n",
      "loss: 0.085269  [    0/   28]\n",
      "loss: 0.085239  [    0/   28]\n",
      "loss: 0.085208  [    0/   28]\n",
      "loss: 0.085178  [    0/   28]\n",
      "loss: 0.085148  [    0/   28]\n",
      "loss: 0.085117  [    0/   28]\n",
      "loss: 0.085088  [    0/   28]\n",
      "loss: 0.085061  [    0/   28]\n",
      "loss: 0.085029  [    0/   28]\n",
      "loss: 0.085000  [    0/   28]\n",
      "loss: 0.084969  [    0/   28]\n",
      "loss: 0.084941  [    0/   28]\n",
      "loss: 0.084910  [    0/   28]\n",
      "loss: 0.084881  [    0/   28]\n",
      "loss: 0.084852  [    0/   28]\n",
      "loss: 0.084823  [    0/   28]\n",
      "loss: 0.084792  [    0/   28]\n",
      "loss: 0.084763  [    0/   28]\n",
      "loss: 0.084732  [    0/   28]\n",
      "loss: 0.084703  [    0/   28]\n",
      "loss: 0.084674  [    0/   28]\n",
      "loss: 0.084646  [    0/   28]\n",
      "loss: 0.084615  [    0/   28]\n",
      "loss: 0.084586  [    0/   28]\n",
      "loss: 0.084555  [    0/   28]\n",
      "loss: 0.084526  [    0/   28]\n",
      "loss: 0.084499  [    0/   28]\n",
      "loss: 0.084467  [    0/   28]\n",
      "loss: 0.084438  [    0/   28]\n",
      "loss: 0.084409  [    0/   28]\n",
      "loss: 0.084381  [    0/   28]\n",
      "loss: 0.084350  [    0/   28]\n",
      "loss: 0.084320  [    0/   28]\n",
      "loss: 0.084291  [    0/   28]\n",
      "loss: 0.084262  [    0/   28]\n",
      "loss: 0.084234  [    0/   28]\n",
      "loss: 0.084203  [    0/   28]\n",
      "loss: 0.084173  [    0/   28]\n",
      "loss: 0.084144  [    0/   28]\n",
      "loss: 0.084116  [    0/   28]\n",
      "loss: 0.084087  [    0/   28]\n",
      "loss: 0.084058  [    0/   28]\n",
      "loss: 0.084028  [    0/   28]\n",
      "loss: 0.083999  [    0/   28]\n",
      "loss: 0.083968  [    0/   28]\n",
      "loss: 0.083941  [    0/   28]\n",
      "loss: 0.083911  [    0/   28]\n",
      "loss: 0.083882  [    0/   28]\n",
      "loss: 0.083854  [    0/   28]\n",
      "loss: 0.083823  [    0/   28]\n",
      "loss: 0.083794  [    0/   28]\n",
      "loss: 0.083766  [    0/   28]\n",
      "loss: 0.083737  [    0/   28]\n",
      "loss: 0.083707  [    0/   28]\n",
      "loss: 0.083678  [    0/   28]\n",
      "loss: 0.083649  [    0/   28]\n",
      "loss: 0.083621  [    0/   28]\n",
      "loss: 0.083592  [    0/   28]\n",
      "loss: 0.083562  [    0/   28]\n",
      "loss: 0.083533  [    0/   28]\n",
      "loss: 0.083504  [    0/   28]\n",
      "loss: 0.083476  [    0/   28]\n",
      "loss: 0.083446  [    0/   28]\n",
      "loss: 0.083418  [    0/   28]\n",
      "loss: 0.083389  [    0/   28]\n",
      "loss: 0.083361  [    0/   28]\n",
      "loss: 0.083331  [    0/   28]\n",
      "loss: 0.083302  [    0/   28]\n",
      "loss: 0.083274  [    0/   28]\n",
      "loss: 0.083244  [    0/   28]\n",
      "loss: 0.083216  [    0/   28]\n",
      "loss: 0.083187  [    0/   28]\n",
      "loss: 0.083159  [    0/   28]\n",
      "loss: 0.083129  [    0/   28]\n",
      "loss: 0.083101  [    0/   28]\n",
      "loss: 0.083072  [    0/   28]\n",
      "loss: 0.083044  [    0/   28]\n",
      "loss: 0.083015  [    0/   28]\n",
      "loss: 0.082987  [    0/   28]\n",
      "loss: 0.082957  [    0/   28]\n",
      "loss: 0.082928  [    0/   28]\n",
      "loss: 0.082900  [    0/   28]\n",
      "loss: 0.082872  [    0/   28]\n",
      "loss: 0.082844  [    0/   28]\n",
      "loss: 0.082815  [    0/   28]\n",
      "loss: 0.082785  [    0/   28]\n",
      "loss: 0.082757  [    0/   28]\n",
      "loss: 0.082729  [    0/   28]\n",
      "loss: 0.082700  [    0/   28]\n",
      "loss: 0.082672  [    0/   28]\n",
      "loss: 0.082643  [    0/   28]\n",
      "loss: 0.082614  [    0/   28]\n",
      "loss: 0.082587  [    0/   28]\n",
      "loss: 0.082558  [    0/   28]\n",
      "loss: 0.082529  [    0/   28]\n",
      "loss: 0.082500  [    0/   28]\n",
      "loss: 0.082472  [    0/   28]\n",
      "loss: 0.082443  [    0/   28]\n",
      "loss: 0.082417  [    0/   28]\n",
      "loss: 0.082388  [    0/   28]\n",
      "loss: 0.082359  [    0/   28]\n",
      "loss: 0.082331  [    0/   28]\n",
      "loss: 0.082302  [    0/   28]\n",
      "loss: 0.082274  [    0/   28]\n",
      "loss: 0.082246  [    0/   28]\n",
      "loss: 0.082217  [    0/   28]\n",
      "loss: 0.082189  [    0/   28]\n",
      "loss: 0.082160  [    0/   28]\n",
      "loss: 0.082133  [    0/   28]\n",
      "loss: 0.082104  [    0/   28]\n",
      "loss: 0.082077  [    0/   28]\n",
      "loss: 0.082049  [    0/   28]\n",
      "loss: 0.082020  [    0/   28]\n",
      "loss: 0.081991  [    0/   28]\n",
      "loss: 0.081963  [    0/   28]\n",
      "loss: 0.081935  [    0/   28]\n",
      "loss: 0.081907  [    0/   28]\n",
      "loss: 0.081879  [    0/   28]\n",
      "loss: 0.081852  [    0/   28]\n",
      "loss: 0.081823  [    0/   28]\n",
      "loss: 0.081795  [    0/   28]\n",
      "loss: 0.081767  [    0/   28]\n",
      "loss: 0.081739  [    0/   28]\n",
      "loss: 0.081710  [    0/   28]\n",
      "loss: 0.081681  [    0/   28]\n",
      "loss: 0.081655  [    0/   28]\n",
      "loss: 0.081627  [    0/   28]\n",
      "loss: 0.081599  [    0/   28]\n",
      "loss: 0.081572  [    0/   28]\n",
      "loss: 0.081543  [    0/   28]\n",
      "loss: 0.081515  [    0/   28]\n",
      "loss: 0.081487  [    0/   28]\n",
      "loss: 0.081459  [    0/   28]\n",
      "loss: 0.081432  [    0/   28]\n",
      "loss: 0.081404  [    0/   28]\n",
      "loss: 0.081375  [    0/   28]\n",
      "loss: 0.081349  [    0/   28]\n",
      "loss: 0.081320  [    0/   28]\n",
      "loss: 0.081293  [    0/   28]\n",
      "loss: 0.081264  [    0/   28]\n",
      "loss: 0.081237  [    0/   28]\n",
      "loss: 0.081209  [    0/   28]\n",
      "loss: 0.081181  [    0/   28]\n",
      "loss: 0.081154  [    0/   28]\n",
      "loss: 0.081125  [    0/   28]\n",
      "loss: 0.081099  [    0/   28]\n",
      "loss: 0.081070  [    0/   28]\n",
      "loss: 0.081043  [    0/   28]\n",
      "loss: 0.081015  [    0/   28]\n",
      "loss: 0.080988  [    0/   28]\n",
      "loss: 0.080960  [    0/   28]\n",
      "loss: 0.080932  [    0/   28]\n",
      "loss: 0.080904  [    0/   28]\n",
      "loss: 0.080877  [    0/   28]\n",
      "loss: 0.080850  [    0/   28]\n",
      "loss: 0.080821  [    0/   28]\n",
      "loss: 0.080793  [    0/   28]\n",
      "loss: 0.080766  [    0/   28]\n",
      "loss: 0.080738  [    0/   28]\n",
      "loss: 0.080711  [    0/   28]\n",
      "loss: 0.080684  [    0/   28]\n",
      "loss: 0.080658  [    0/   28]\n",
      "loss: 0.080629  [    0/   28]\n",
      "loss: 0.080601  [    0/   28]\n",
      "loss: 0.080575  [    0/   28]\n",
      "loss: 0.080548  [    0/   28]\n",
      "loss: 0.080520  [    0/   28]\n",
      "loss: 0.080491  [    0/   28]\n",
      "loss: 0.080464  [    0/   28]\n",
      "loss: 0.080437  [    0/   28]\n",
      "loss: 0.080410  [    0/   28]\n",
      "loss: 0.080382  [    0/   28]\n",
      "loss: 0.080354  [    0/   28]\n",
      "loss: 0.080328  [    0/   28]\n",
      "loss: 0.080301  [    0/   28]\n",
      "loss: 0.080273  [    0/   28]\n",
      "loss: 0.080246  [    0/   28]\n",
      "loss: 0.080219  [    0/   28]\n",
      "loss: 0.080191  [    0/   28]\n",
      "loss: 0.080165  [    0/   28]\n",
      "loss: 0.080137  [    0/   28]\n",
      "loss: 0.080110  [    0/   28]\n",
      "loss: 0.080083  [    0/   28]\n",
      "loss: 0.080055  [    0/   28]\n",
      "loss: 0.080028  [    0/   28]\n",
      "loss: 0.080000  [    0/   28]\n",
      "loss: 0.079976  [    0/   28]\n",
      "loss: 0.079946  [    0/   28]\n",
      "loss: 0.079919  [    0/   28]\n",
      "loss: 0.079893  [    0/   28]\n",
      "loss: 0.079866  [    0/   28]\n",
      "loss: 0.079838  [    0/   28]\n",
      "loss: 0.079812  [    0/   28]\n",
      "loss: 0.079785  [    0/   28]\n",
      "loss: 0.079757  [    0/   28]\n",
      "loss: 0.079730  [    0/   28]\n",
      "loss: 0.079703  [    0/   28]\n",
      "loss: 0.079676  [    0/   28]\n",
      "loss: 0.079649  [    0/   28]\n",
      "loss: 0.079621  [    0/   28]\n",
      "loss: 0.079594  [    0/   28]\n",
      "loss: 0.079569  [    0/   28]\n",
      "loss: 0.079542  [    0/   28]\n",
      "loss: 0.079513  [    0/   28]\n",
      "loss: 0.079487  [    0/   28]\n",
      "loss: 0.079460  [    0/   28]\n",
      "loss: 0.079433  [    0/   28]\n",
      "loss: 0.079406  [    0/   28]\n",
      "loss: 0.079379  [    0/   28]\n",
      "loss: 0.079352  [    0/   28]\n",
      "loss: 0.079326  [    0/   28]\n",
      "loss: 0.079299  [    0/   28]\n",
      "loss: 0.079273  [    0/   28]\n",
      "loss: 0.079245  [    0/   28]\n",
      "loss: 0.079218  [    0/   28]\n",
      "loss: 0.079192  [    0/   28]\n",
      "loss: 0.079164  [    0/   28]\n",
      "loss: 0.079138  [    0/   28]\n",
      "loss: 0.079112  [    0/   28]\n",
      "loss: 0.079084  [    0/   28]\n",
      "loss: 0.079058  [    0/   28]\n",
      "loss: 0.079033  [    0/   28]\n",
      "loss: 0.079004  [    0/   28]\n",
      "loss: 0.078978  [    0/   28]\n",
      "loss: 0.078951  [    0/   28]\n",
      "loss: 0.078924  [    0/   28]\n",
      "loss: 0.078898  [    0/   28]\n",
      "loss: 0.078872  [    0/   28]\n",
      "loss: 0.078845  [    0/   28]\n",
      "loss: 0.078818  [    0/   28]\n",
      "loss: 0.078791  [    0/   28]\n",
      "loss: 0.078764  [    0/   28]\n",
      "loss: 0.078739  [    0/   28]\n",
      "loss: 0.078713  [    0/   28]\n",
      "loss: 0.078686  [    0/   28]\n",
      "loss: 0.078659  [    0/   28]\n",
      "loss: 0.078633  [    0/   28]\n",
      "loss: 0.078607  [    0/   28]\n",
      "loss: 0.078579  [    0/   28]\n",
      "loss: 0.078553  [    0/   28]\n",
      "loss: 0.078527  [    0/   28]\n",
      "loss: 0.078500  [    0/   28]\n",
      "loss: 0.078476  [    0/   28]\n",
      "loss: 0.078448  [    0/   28]\n",
      "loss: 0.078422  [    0/   28]\n",
      "loss: 0.078395  [    0/   28]\n",
      "loss: 0.078369  [    0/   28]\n",
      "loss: 0.078343  [    0/   28]\n",
      "loss: 0.078317  [    0/   28]\n",
      "loss: 0.078291  [    0/   28]\n",
      "loss: 0.078263  [    0/   28]\n",
      "loss: 0.078239  [    0/   28]\n",
      "loss: 0.078212  [    0/   28]\n",
      "loss: 0.078185  [    0/   28]\n",
      "loss: 0.078158  [    0/   28]\n",
      "loss: 0.078133  [    0/   28]\n",
      "loss: 0.078107  [    0/   28]\n",
      "loss: 0.078082  [    0/   28]\n",
      "loss: 0.078055  [    0/   28]\n",
      "loss: 0.078029  [    0/   28]\n",
      "loss: 0.078002  [    0/   28]\n",
      "loss: 0.077976  [    0/   28]\n",
      "loss: 0.077950  [    0/   28]\n",
      "loss: 0.077924  [    0/   28]\n",
      "loss: 0.077897  [    0/   28]\n",
      "loss: 0.077872  [    0/   28]\n",
      "loss: 0.077847  [    0/   28]\n",
      "loss: 0.077820  [    0/   28]\n",
      "loss: 0.077794  [    0/   28]\n",
      "loss: 0.077767  [    0/   28]\n",
      "loss: 0.077742  [    0/   28]\n",
      "loss: 0.077716  [    0/   28]\n",
      "loss: 0.077690  [    0/   28]\n",
      "loss: 0.077664  [    0/   28]\n",
      "loss: 0.077638  [    0/   28]\n",
      "loss: 0.077612  [    0/   28]\n",
      "loss: 0.077586  [    0/   28]\n",
      "loss: 0.077561  [    0/   28]\n",
      "loss: 0.077534  [    0/   28]\n",
      "loss: 0.077509  [    0/   28]\n",
      "loss: 0.077483  [    0/   28]\n",
      "loss: 0.077456  [    0/   28]\n",
      "loss: 0.077430  [    0/   28]\n",
      "loss: 0.077406  [    0/   28]\n",
      "loss: 0.077380  [    0/   28]\n",
      "loss: 0.077354  [    0/   28]\n",
      "loss: 0.077328  [    0/   28]\n",
      "loss: 0.077302  [    0/   28]\n",
      "loss: 0.077277  [    0/   28]\n",
      "loss: 0.077251  [    0/   28]\n",
      "loss: 0.077225  [    0/   28]\n",
      "loss: 0.077199  [    0/   28]\n",
      "loss: 0.077174  [    0/   28]\n",
      "loss: 0.077149  [    0/   28]\n",
      "loss: 0.077123  [    0/   28]\n",
      "loss: 0.077096  [    0/   28]\n",
      "loss: 0.077070  [    0/   28]\n",
      "loss: 0.077045  [    0/   28]\n",
      "loss: 0.077020  [    0/   28]\n",
      "loss: 0.076994  [    0/   28]\n",
      "loss: 0.076969  [    0/   28]\n",
      "loss: 0.076943  [    0/   28]\n",
      "loss: 0.076917  [    0/   28]\n",
      "loss: 0.076891  [    0/   28]\n",
      "loss: 0.076868  [    0/   28]\n",
      "loss: 0.076841  [    0/   28]\n",
      "loss: 0.076815  [    0/   28]\n",
      "loss: 0.076789  [    0/   28]\n",
      "loss: 0.076764  [    0/   28]\n",
      "loss: 0.076738  [    0/   28]\n",
      "loss: 0.076714  [    0/   28]\n",
      "loss: 0.076688  [    0/   28]\n",
      "loss: 0.076662  [    0/   28]\n",
      "loss: 0.076636  [    0/   28]\n",
      "loss: 0.076612  [    0/   28]\n",
      "loss: 0.076586  [    0/   28]\n",
      "loss: 0.076561  [    0/   28]\n",
      "loss: 0.076535  [    0/   28]\n",
      "loss: 0.076510  [    0/   28]\n",
      "loss: 0.076484  [    0/   28]\n",
      "loss: 0.076460  [    0/   28]\n",
      "loss: 0.076434  [    0/   28]\n",
      "loss: 0.076408  [    0/   28]\n",
      "loss: 0.076383  [    0/   28]\n",
      "loss: 0.076359  [    0/   28]\n",
      "loss: 0.076334  [    0/   28]\n",
      "loss: 0.076308  [    0/   28]\n",
      "loss: 0.076282  [    0/   28]\n",
      "loss: 0.076257  [    0/   28]\n",
      "loss: 0.076233  [    0/   28]\n",
      "loss: 0.076207  [    0/   28]\n",
      "loss: 0.076181  [    0/   28]\n",
      "loss: 0.076156  [    0/   28]\n",
      "loss: 0.076131  [    0/   28]\n",
      "loss: 0.076106  [    0/   28]\n",
      "loss: 0.076082  [    0/   28]\n",
      "loss: 0.076055  [    0/   28]\n",
      "loss: 0.076030  [    0/   28]\n",
      "loss: 0.076005  [    0/   28]\n",
      "loss: 0.075980  [    0/   28]\n",
      "loss: 0.075956  [    0/   28]\n",
      "loss: 0.075931  [    0/   28]\n",
      "loss: 0.075905  [    0/   28]\n",
      "loss: 0.075881  [    0/   28]\n",
      "loss: 0.075855  [    0/   28]\n",
      "loss: 0.075830  [    0/   28]\n",
      "loss: 0.075806  [    0/   28]\n",
      "loss: 0.075780  [    0/   28]\n",
      "loss: 0.075755  [    0/   28]\n",
      "loss: 0.075730  [    0/   28]\n",
      "loss: 0.075705  [    0/   28]\n",
      "loss: 0.075681  [    0/   28]\n",
      "loss: 0.075655  [    0/   28]\n",
      "loss: 0.075630  [    0/   28]\n",
      "loss: 0.075606  [    0/   28]\n",
      "loss: 0.075581  [    0/   28]\n",
      "loss: 0.075556  [    0/   28]\n",
      "loss: 0.075531  [    0/   28]\n",
      "loss: 0.075506  [    0/   28]\n",
      "loss: 0.075481  [    0/   28]\n",
      "loss: 0.075458  [    0/   28]\n",
      "loss: 0.075432  [    0/   28]\n",
      "loss: 0.075407  [    0/   28]\n",
      "loss: 0.075381  [    0/   28]\n",
      "loss: 0.075358  [    0/   28]\n",
      "loss: 0.075334  [    0/   28]\n",
      "loss: 0.075307  [    0/   28]\n",
      "loss: 0.075283  [    0/   28]\n",
      "loss: 0.075258  [    0/   28]\n",
      "loss: 0.075234  [    0/   28]\n",
      "loss: 0.075209  [    0/   28]\n",
      "loss: 0.075184  [    0/   28]\n",
      "loss: 0.075160  [    0/   28]\n",
      "loss: 0.075135  [    0/   28]\n",
      "loss: 0.075110  [    0/   28]\n",
      "loss: 0.075086  [    0/   28]\n",
      "loss: 0.075061  [    0/   28]\n",
      "loss: 0.075036  [    0/   28]\n",
      "loss: 0.075012  [    0/   28]\n",
      "loss: 0.074987  [    0/   28]\n",
      "loss: 0.074962  [    0/   28]\n",
      "loss: 0.074939  [    0/   28]\n",
      "loss: 0.074914  [    0/   28]\n",
      "loss: 0.074889  [    0/   28]\n",
      "loss: 0.074864  [    0/   28]\n",
      "loss: 0.074840  [    0/   28]\n",
      "loss: 0.074815  [    0/   28]\n",
      "loss: 0.074791  [    0/   28]\n",
      "loss: 0.074766  [    0/   28]\n",
      "loss: 0.074741  [    0/   28]\n",
      "loss: 0.074717  [    0/   28]\n",
      "loss: 0.074693  [    0/   28]\n",
      "loss: 0.074669  [    0/   28]\n",
      "loss: 0.074645  [    0/   28]\n",
      "loss: 0.074621  [    0/   28]\n",
      "loss: 0.074595  [    0/   28]\n",
      "loss: 0.074571  [    0/   28]\n",
      "loss: 0.074546  [    0/   28]\n",
      "loss: 0.074522  [    0/   28]\n",
      "loss: 0.074498  [    0/   28]\n",
      "loss: 0.074475  [    0/   28]\n",
      "loss: 0.074450  [    0/   28]\n",
      "loss: 0.074425  [    0/   28]\n",
      "loss: 0.074400  [    0/   28]\n",
      "loss: 0.074377  [    0/   28]\n",
      "loss: 0.074353  [    0/   28]\n",
      "loss: 0.074328  [    0/   28]\n",
      "loss: 0.074304  [    0/   28]\n",
      "loss: 0.074279  [    0/   28]\n",
      "loss: 0.074255  [    0/   28]\n",
      "loss: 0.074231  [    0/   28]\n",
      "loss: 0.074206  [    0/   28]\n",
      "loss: 0.074183  [    0/   28]\n",
      "loss: 0.074159  [    0/   28]\n",
      "loss: 0.074134  [    0/   28]\n",
      "loss: 0.074110  [    0/   28]\n",
      "loss: 0.074086  [    0/   28]\n",
      "loss: 0.074062  [    0/   28]\n",
      "loss: 0.074037  [    0/   28]\n",
      "loss: 0.074014  [    0/   28]\n",
      "loss: 0.073990  [    0/   28]\n",
      "loss: 0.073966  [    0/   28]\n",
      "loss: 0.073941  [    0/   28]\n",
      "loss: 0.073918  [    0/   28]\n",
      "loss: 0.073893  [    0/   28]\n",
      "loss: 0.073869  [    0/   28]\n",
      "loss: 0.073844  [    0/   28]\n",
      "loss: 0.073821  [    0/   28]\n",
      "loss: 0.073798  [    0/   28]\n",
      "loss: 0.073773  [    0/   28]\n",
      "loss: 0.073749  [    0/   28]\n",
      "loss: 0.073726  [    0/   28]\n",
      "loss: 0.073702  [    0/   28]\n",
      "loss: 0.073677  [    0/   28]\n",
      "loss: 0.073654  [    0/   28]\n",
      "loss: 0.073629  [    0/   28]\n",
      "loss: 0.073606  [    0/   28]\n",
      "loss: 0.073582  [    0/   28]\n",
      "loss: 0.073558  [    0/   28]\n",
      "loss: 0.073534  [    0/   28]\n",
      "loss: 0.073511  [    0/   28]\n",
      "loss: 0.073487  [    0/   28]\n",
      "loss: 0.073462  [    0/   28]\n",
      "loss: 0.073439  [    0/   28]\n",
      "loss: 0.073416  [    0/   28]\n",
      "loss: 0.073391  [    0/   28]\n",
      "loss: 0.073368  [    0/   28]\n",
      "loss: 0.073343  [    0/   28]\n",
      "loss: 0.073320  [    0/   28]\n",
      "loss: 0.073296  [    0/   28]\n",
      "loss: 0.073273  [    0/   28]\n",
      "loss: 0.073248  [    0/   28]\n",
      "loss: 0.073225  [    0/   28]\n",
      "loss: 0.073201  [    0/   28]\n",
      "loss: 0.073178  [    0/   28]\n",
      "loss: 0.073153  [    0/   28]\n",
      "loss: 0.073131  [    0/   28]\n",
      "loss: 0.073106  [    0/   28]\n",
      "loss: 0.073083  [    0/   28]\n",
      "loss: 0.073059  [    0/   28]\n",
      "loss: 0.073035  [    0/   28]\n",
      "loss: 0.073013  [    0/   28]\n",
      "loss: 0.072989  [    0/   28]\n",
      "loss: 0.072966  [    0/   28]\n",
      "loss: 0.072941  [    0/   28]\n",
      "loss: 0.072917  [    0/   28]\n",
      "loss: 0.072894  [    0/   28]\n",
      "loss: 0.072872  [    0/   28]\n",
      "loss: 0.072847  [    0/   28]\n",
      "loss: 0.072824  [    0/   28]\n",
      "loss: 0.072800  [    0/   28]\n",
      "loss: 0.072776  [    0/   28]\n",
      "loss: 0.072754  [    0/   28]\n",
      "loss: 0.072730  [    0/   28]\n",
      "loss: 0.072707  [    0/   28]\n",
      "loss: 0.072683  [    0/   28]\n",
      "loss: 0.072659  [    0/   28]\n",
      "loss: 0.072637  [    0/   28]\n",
      "loss: 0.072612  [    0/   28]\n",
      "loss: 0.072590  [    0/   28]\n",
      "loss: 0.072566  [    0/   28]\n",
      "loss: 0.072542  [    0/   28]\n",
      "loss: 0.072519  [    0/   28]\n",
      "loss: 0.072496  [    0/   28]\n",
      "loss: 0.072474  [    0/   28]\n",
      "loss: 0.072450  [    0/   28]\n",
      "loss: 0.072426  [    0/   28]\n",
      "loss: 0.072403  [    0/   28]\n",
      "loss: 0.072380  [    0/   28]\n",
      "loss: 0.072356  [    0/   28]\n",
      "loss: 0.072333  [    0/   28]\n",
      "loss: 0.072310  [    0/   28]\n",
      "loss: 0.072287  [    0/   28]\n",
      "loss: 0.072263  [    0/   28]\n",
      "loss: 0.072240  [    0/   28]\n",
      "loss: 0.072218  [    0/   28]\n",
      "loss: 0.072194  [    0/   28]\n",
      "loss: 0.072171  [    0/   28]\n",
      "loss: 0.072148  [    0/   28]\n",
      "loss: 0.072125  [    0/   28]\n",
      "loss: 0.072102  [    0/   28]\n",
      "loss: 0.072078  [    0/   28]\n",
      "loss: 0.072055  [    0/   28]\n",
      "loss: 0.072032  [    0/   28]\n",
      "loss: 0.072009  [    0/   28]\n",
      "loss: 0.071987  [    0/   28]\n",
      "loss: 0.071962  [    0/   28]\n",
      "loss: 0.071940  [    0/   28]\n",
      "loss: 0.071917  [    0/   28]\n",
      "loss: 0.071894  [    0/   28]\n",
      "loss: 0.071872  [    0/   28]\n",
      "loss: 0.071848  [    0/   28]\n",
      "loss: 0.071825  [    0/   28]\n",
      "loss: 0.071801  [    0/   28]\n",
      "loss: 0.071779  [    0/   28]\n",
      "loss: 0.071757  [    0/   28]\n",
      "loss: 0.071734  [    0/   28]\n",
      "loss: 0.071710  [    0/   28]\n",
      "loss: 0.071688  [    0/   28]\n",
      "loss: 0.071664  [    0/   28]\n",
      "loss: 0.071642  [    0/   28]\n",
      "loss: 0.071618  [    0/   28]\n",
      "loss: 0.071596  [    0/   28]\n",
      "loss: 0.071573  [    0/   28]\n",
      "loss: 0.071551  [    0/   28]\n",
      "loss: 0.071528  [    0/   28]\n",
      "loss: 0.071505  [    0/   28]\n",
      "loss: 0.071482  [    0/   28]\n",
      "loss: 0.071458  [    0/   28]\n",
      "loss: 0.071437  [    0/   28]\n",
      "loss: 0.071414  [    0/   28]\n",
      "loss: 0.071391  [    0/   28]\n",
      "loss: 0.071368  [    0/   28]\n",
      "loss: 0.071345  [    0/   28]\n",
      "loss: 0.071322  [    0/   28]\n",
      "loss: 0.071300  [    0/   28]\n",
      "loss: 0.071276  [    0/   28]\n",
      "loss: 0.071254  [    0/   28]\n",
      "loss: 0.071233  [    0/   28]\n",
      "loss: 0.071209  [    0/   28]\n",
      "loss: 0.071187  [    0/   28]\n",
      "loss: 0.071164  [    0/   28]\n",
      "loss: 0.071141  [    0/   28]\n",
      "loss: 0.071119  [    0/   28]\n",
      "loss: 0.071096  [    0/   28]\n",
      "loss: 0.071073  [    0/   28]\n",
      "loss: 0.071051  [    0/   28]\n",
      "loss: 0.071029  [    0/   28]\n",
      "loss: 0.071006  [    0/   28]\n",
      "loss: 0.070983  [    0/   28]\n",
      "loss: 0.070961  [    0/   28]\n",
      "loss: 0.070938  [    0/   28]\n",
      "loss: 0.070916  [    0/   28]\n",
      "loss: 0.070893  [    0/   28]\n",
      "loss: 0.070871  [    0/   28]\n",
      "loss: 0.070848  [    0/   28]\n",
      "loss: 0.070826  [    0/   28]\n",
      "loss: 0.070804  [    0/   28]\n",
      "loss: 0.070781  [    0/   28]\n",
      "loss: 0.070758  [    0/   28]\n",
      "loss: 0.070736  [    0/   28]\n",
      "loss: 0.070714  [    0/   28]\n",
      "loss: 0.070692  [    0/   28]\n",
      "loss: 0.070669  [    0/   28]\n",
      "loss: 0.070647  [    0/   28]\n",
      "loss: 0.070624  [    0/   28]\n",
      "loss: 0.070602  [    0/   28]\n",
      "loss: 0.070579  [    0/   28]\n",
      "loss: 0.070557  [    0/   28]\n",
      "loss: 0.070534  [    0/   28]\n",
      "loss: 0.070512  [    0/   28]\n",
      "loss: 0.070490  [    0/   28]\n",
      "loss: 0.070468  [    0/   28]\n",
      "loss: 0.070446  [    0/   28]\n",
      "loss: 0.070423  [    0/   28]\n",
      "loss: 0.070401  [    0/   28]\n",
      "loss: 0.070379  [    0/   28]\n",
      "loss: 0.070358  [    0/   28]\n",
      "loss: 0.070334  [    0/   28]\n",
      "loss: 0.070311  [    0/   28]\n",
      "loss: 0.070289  [    0/   28]\n",
      "loss: 0.070267  [    0/   28]\n",
      "loss: 0.070247  [    0/   28]\n",
      "loss: 0.070223  [    0/   28]\n",
      "loss: 0.070201  [    0/   28]\n",
      "loss: 0.070179  [    0/   28]\n",
      "loss: 0.070157  [    0/   28]\n",
      "loss: 0.070135  [    0/   28]\n",
      "loss: 0.070112  [    0/   28]\n",
      "loss: 0.070091  [    0/   28]\n",
      "loss: 0.070068  [    0/   28]\n",
      "loss: 0.070046  [    0/   28]\n",
      "loss: 0.070024  [    0/   28]\n",
      "loss: 0.070002  [    0/   28]\n",
      "loss: 0.069980  [    0/   28]\n",
      "loss: 0.069957  [    0/   28]\n",
      "loss: 0.069935  [    0/   28]\n",
      "loss: 0.069915  [    0/   28]\n",
      "loss: 0.069892  [    0/   28]\n",
      "loss: 0.069870  [    0/   28]\n",
      "loss: 0.069847  [    0/   28]\n",
      "loss: 0.069825  [    0/   28]\n",
      "loss: 0.069804  [    0/   28]\n",
      "loss: 0.069782  [    0/   28]\n",
      "loss: 0.069760  [    0/   28]\n",
      "loss: 0.069737  [    0/   28]\n",
      "loss: 0.069716  [    0/   28]\n",
      "loss: 0.069694  [    0/   28]\n",
      "loss: 0.069672  [    0/   28]\n",
      "loss: 0.069650  [    0/   28]\n",
      "loss: 0.069628  [    0/   28]\n",
      "loss: 0.069606  [    0/   28]\n",
      "loss: 0.069585  [    0/   28]\n",
      "loss: 0.069562  [    0/   28]\n",
      "loss: 0.069541  [    0/   28]\n",
      "loss: 0.069518  [    0/   28]\n",
      "loss: 0.069497  [    0/   28]\n",
      "loss: 0.069476  [    0/   28]\n",
      "loss: 0.069453  [    0/   28]\n",
      "loss: 0.069432  [    0/   28]\n",
      "loss: 0.069409  [    0/   28]\n",
      "loss: 0.069388  [    0/   28]\n",
      "loss: 0.069365  [    0/   28]\n",
      "loss: 0.069344  [    0/   28]\n",
      "loss: 0.069322  [    0/   28]\n",
      "loss: 0.069300  [    0/   28]\n",
      "loss: 0.069279  [    0/   28]\n",
      "loss: 0.069256  [    0/   28]\n",
      "loss: 0.069236  [    0/   28]\n",
      "loss: 0.069213  [    0/   28]\n",
      "loss: 0.069192  [    0/   28]\n",
      "loss: 0.069169  [    0/   28]\n",
      "loss: 0.069148  [    0/   28]\n",
      "loss: 0.069127  [    0/   28]\n",
      "loss: 0.069105  [    0/   28]\n",
      "loss: 0.069083  [    0/   28]\n",
      "loss: 0.069061  [    0/   28]\n",
      "loss: 0.069040  [    0/   28]\n",
      "loss: 0.069017  [    0/   28]\n",
      "loss: 0.068997  [    0/   28]\n",
      "loss: 0.068975  [    0/   28]\n",
      "loss: 0.068953  [    0/   28]\n",
      "loss: 0.068932  [    0/   28]\n",
      "loss: 0.068910  [    0/   28]\n",
      "loss: 0.068889  [    0/   28]\n",
      "loss: 0.068867  [    0/   28]\n",
      "loss: 0.068845  [    0/   28]\n",
      "loss: 0.068823  [    0/   28]\n",
      "loss: 0.068802  [    0/   28]\n",
      "loss: 0.068780  [    0/   28]\n",
      "loss: 0.068759  [    0/   28]\n",
      "loss: 0.068738  [    0/   28]\n",
      "loss: 0.068716  [    0/   28]\n",
      "loss: 0.068695  [    0/   28]\n",
      "loss: 0.068674  [    0/   28]\n",
      "loss: 0.068651  [    0/   28]\n",
      "loss: 0.068630  [    0/   28]\n",
      "loss: 0.068608  [    0/   28]\n",
      "loss: 0.068588  [    0/   28]\n",
      "loss: 0.068566  [    0/   28]\n",
      "loss: 0.068544  [    0/   28]\n",
      "loss: 0.068522  [    0/   28]\n",
      "loss: 0.068502  [    0/   28]\n",
      "loss: 0.068480  [    0/   28]\n",
      "loss: 0.068459  [    0/   28]\n",
      "loss: 0.068438  [    0/   28]\n",
      "loss: 0.068416  [    0/   28]\n",
      "loss: 0.068394  [    0/   28]\n",
      "loss: 0.068374  [    0/   28]\n",
      "loss: 0.068352  [    0/   28]\n",
      "loss: 0.068332  [    0/   28]\n",
      "loss: 0.068310  [    0/   28]\n",
      "loss: 0.068288  [    0/   28]\n",
      "loss: 0.068267  [    0/   28]\n",
      "loss: 0.068245  [    0/   28]\n",
      "loss: 0.068224  [    0/   28]\n",
      "loss: 0.068203  [    0/   28]\n",
      "loss: 0.068182  [    0/   28]\n",
      "loss: 0.068160  [    0/   28]\n",
      "loss: 0.068139  [    0/   28]\n",
      "loss: 0.068119  [    0/   28]\n",
      "loss: 0.068097  [    0/   28]\n",
      "loss: 0.068076  [    0/   28]\n",
      "loss: 0.068054  [    0/   28]\n",
      "loss: 0.068033  [    0/   28]\n",
      "loss: 0.068012  [    0/   28]\n",
      "loss: 0.067991  [    0/   28]\n",
      "loss: 0.067970  [    0/   28]\n",
      "loss: 0.067950  [    0/   28]\n",
      "loss: 0.067927  [    0/   28]\n",
      "loss: 0.067906  [    0/   28]\n",
      "loss: 0.067885  [    0/   28]\n",
      "loss: 0.067864  [    0/   28]\n",
      "loss: 0.067844  [    0/   28]\n",
      "loss: 0.067821  [    0/   28]\n",
      "loss: 0.067801  [    0/   28]\n",
      "loss: 0.067779  [    0/   28]\n",
      "loss: 0.067759  [    0/   28]\n",
      "loss: 0.067737  [    0/   28]\n",
      "loss: 0.067717  [    0/   28]\n",
      "loss: 0.067696  [    0/   28]\n",
      "loss: 0.067675  [    0/   28]\n",
      "loss: 0.067654  [    0/   28]\n",
      "loss: 0.067632  [    0/   28]\n",
      "loss: 0.067611  [    0/   28]\n",
      "loss: 0.067590  [    0/   28]\n",
      "loss: 0.067569  [    0/   28]\n",
      "loss: 0.067549  [    0/   28]\n",
      "loss: 0.067528  [    0/   28]\n",
      "loss: 0.067507  [    0/   28]\n",
      "loss: 0.067485  [    0/   28]\n",
      "loss: 0.067465  [    0/   28]\n",
      "loss: 0.067444  [    0/   28]\n",
      "loss: 0.067424  [    0/   28]\n",
      "loss: 0.067403  [    0/   28]\n",
      "loss: 0.067382  [    0/   28]\n",
      "loss: 0.067360  [    0/   28]\n",
      "loss: 0.067340  [    0/   28]\n",
      "loss: 0.067319  [    0/   28]\n",
      "loss: 0.067298  [    0/   28]\n",
      "loss: 0.067277  [    0/   28]\n",
      "loss: 0.067256  [    0/   28]\n",
      "loss: 0.067235  [    0/   28]\n",
      "loss: 0.067215  [    0/   28]\n",
      "loss: 0.067193  [    0/   28]\n",
      "loss: 0.067173  [    0/   28]\n",
      "loss: 0.067153  [    0/   28]\n",
      "loss: 0.067132  [    0/   28]\n",
      "loss: 0.067111  [    0/   28]\n",
      "loss: 0.067090  [    0/   28]\n",
      "loss: 0.067069  [    0/   28]\n",
      "loss: 0.067049  [    0/   28]\n",
      "loss: 0.067027  [    0/   28]\n",
      "loss: 0.067007  [    0/   28]\n",
      "loss: 0.066987  [    0/   28]\n",
      "loss: 0.066966  [    0/   28]\n",
      "loss: 0.066945  [    0/   28]\n",
      "loss: 0.066925  [    0/   28]\n",
      "loss: 0.066904  [    0/   28]\n",
      "loss: 0.066883  [    0/   28]\n",
      "loss: 0.066862  [    0/   28]\n",
      "loss: 0.066842  [    0/   28]\n",
      "loss: 0.066821  [    0/   28]\n",
      "loss: 0.066800  [    0/   28]\n",
      "loss: 0.066780  [    0/   28]\n",
      "loss: 0.066760  [    0/   28]\n",
      "loss: 0.066739  [    0/   28]\n",
      "loss: 0.066718  [    0/   28]\n",
      "loss: 0.066697  [    0/   28]\n",
      "loss: 0.066676  [    0/   28]\n",
      "loss: 0.066657  [    0/   28]\n",
      "loss: 0.066636  [    0/   28]\n",
      "loss: 0.066616  [    0/   28]\n",
      "loss: 0.066595  [    0/   28]\n",
      "loss: 0.066574  [    0/   28]\n",
      "loss: 0.066554  [    0/   28]\n",
      "loss: 0.066534  [    0/   28]\n",
      "loss: 0.066513  [    0/   28]\n",
      "loss: 0.066493  [    0/   28]\n",
      "loss: 0.066472  [    0/   28]\n",
      "loss: 0.066452  [    0/   28]\n",
      "loss: 0.066430  [    0/   28]\n",
      "loss: 0.066411  [    0/   28]\n",
      "loss: 0.066391  [    0/   28]\n",
      "loss: 0.066370  [    0/   28]\n",
      "loss: 0.066349  [    0/   28]\n",
      "loss: 0.066329  [    0/   28]\n",
      "loss: 0.066309  [    0/   28]\n",
      "loss: 0.066288  [    0/   28]\n",
      "loss: 0.066268  [    0/   28]\n",
      "loss: 0.066248  [    0/   28]\n",
      "loss: 0.066228  [    0/   28]\n",
      "loss: 0.066206  [    0/   28]\n",
      "loss: 0.066187  [    0/   28]\n",
      "loss: 0.066165  [    0/   28]\n",
      "loss: 0.066146  [    0/   28]\n",
      "loss: 0.066126  [    0/   28]\n",
      "loss: 0.066106  [    0/   28]\n",
      "loss: 0.066085  [    0/   28]\n",
      "loss: 0.066064  [    0/   28]\n",
      "loss: 0.066045  [    0/   28]\n",
      "loss: 0.066024  [    0/   28]\n",
      "loss: 0.066005  [    0/   28]\n",
      "loss: 0.065983  [    0/   28]\n",
      "loss: 0.065963  [    0/   28]\n",
      "loss: 0.065943  [    0/   28]\n",
      "loss: 0.065923  [    0/   28]\n",
      "loss: 0.065903  [    0/   28]\n",
      "loss: 0.065883  [    0/   28]\n",
      "loss: 0.065863  [    0/   28]\n",
      "loss: 0.065842  [    0/   28]\n",
      "loss: 0.065822  [    0/   28]\n",
      "loss: 0.065801  [    0/   28]\n",
      "loss: 0.065782  [    0/   28]\n",
      "loss: 0.065762  [    0/   28]\n",
      "loss: 0.065742  [    0/   28]\n",
      "loss: 0.065721  [    0/   28]\n",
      "loss: 0.065702  [    0/   28]\n",
      "loss: 0.065681  [    0/   28]\n",
      "loss: 0.065661  [    0/   28]\n",
      "loss: 0.065641  [    0/   28]\n",
      "loss: 0.065621  [    0/   28]\n",
      "loss: 0.065601  [    0/   28]\n",
      "loss: 0.065581  [    0/   28]\n",
      "loss: 0.065561  [    0/   28]\n",
      "loss: 0.065541  [    0/   28]\n",
      "loss: 0.065521  [    0/   28]\n",
      "loss: 0.065501  [    0/   28]\n",
      "loss: 0.065481  [    0/   28]\n",
      "loss: 0.065461  [    0/   28]\n",
      "loss: 0.065441  [    0/   28]\n",
      "loss: 0.065421  [    0/   28]\n",
      "loss: 0.065401  [    0/   28]\n",
      "loss: 0.065381  [    0/   28]\n",
      "loss: 0.065361  [    0/   28]\n",
      "loss: 0.065341  [    0/   28]\n",
      "loss: 0.065321  [    0/   28]\n",
      "loss: 0.065301  [    0/   28]\n",
      "loss: 0.065281  [    0/   28]\n",
      "loss: 0.065261  [    0/   28]\n",
      "loss: 0.065242  [    0/   28]\n",
      "loss: 0.065222  [    0/   28]\n",
      "loss: 0.065202  [    0/   28]\n",
      "loss: 0.065182  [    0/   28]\n",
      "loss: 0.065162  [    0/   28]\n",
      "loss: 0.065142  [    0/   28]\n",
      "loss: 0.065122  [    0/   28]\n",
      "loss: 0.065103  [    0/   28]\n",
      "loss: 0.065083  [    0/   28]\n",
      "loss: 0.065064  [    0/   28]\n",
      "loss: 0.065043  [    0/   28]\n",
      "loss: 0.065023  [    0/   28]\n",
      "loss: 0.065004  [    0/   28]\n",
      "loss: 0.064984  [    0/   28]\n",
      "loss: 0.064964  [    0/   28]\n",
      "loss: 0.064945  [    0/   28]\n",
      "loss: 0.064924  [    0/   28]\n",
      "loss: 0.064905  [    0/   28]\n",
      "loss: 0.064885  [    0/   28]\n",
      "loss: 0.064866  [    0/   28]\n",
      "loss: 0.064846  [    0/   28]\n",
      "loss: 0.064826  [    0/   28]\n",
      "loss: 0.064806  [    0/   28]\n",
      "loss: 0.064787  [    0/   28]\n",
      "loss: 0.064767  [    0/   28]\n",
      "loss: 0.064747  [    0/   28]\n",
      "loss: 0.064727  [    0/   28]\n",
      "loss: 0.064708  [    0/   28]\n",
      "loss: 0.064688  [    0/   28]\n",
      "loss: 0.064669  [    0/   28]\n",
      "loss: 0.064649  [    0/   28]\n",
      "loss: 0.064630  [    0/   28]\n",
      "loss: 0.064610  [    0/   28]\n",
      "loss: 0.064590  [    0/   28]\n",
      "loss: 0.064570  [    0/   28]\n",
      "loss: 0.064552  [    0/   28]\n",
      "loss: 0.064531  [    0/   28]\n",
      "loss: 0.064511  [    0/   28]\n",
      "loss: 0.064492  [    0/   28]\n",
      "loss: 0.064472  [    0/   28]\n",
      "loss: 0.064454  [    0/   28]\n",
      "loss: 0.064434  [    0/   28]\n",
      "loss: 0.064414  [    0/   28]\n",
      "loss: 0.064394  [    0/   28]\n",
      "loss: 0.064375  [    0/   28]\n",
      "loss: 0.064356  [    0/   28]\n",
      "loss: 0.064337  [    0/   28]\n",
      "loss: 0.064317  [    0/   28]\n",
      "loss: 0.064297  [    0/   28]\n",
      "loss: 0.064278  [    0/   28]\n",
      "loss: 0.064258  [    0/   28]\n",
      "loss: 0.064238  [    0/   28]\n",
      "loss: 0.064220  [    0/   28]\n",
      "loss: 0.064200  [    0/   28]\n",
      "loss: 0.064181  [    0/   28]\n",
      "loss: 0.064162  [    0/   28]\n",
      "loss: 0.064142  [    0/   28]\n",
      "loss: 0.064123  [    0/   28]\n",
      "loss: 0.064103  [    0/   28]\n",
      "loss: 0.064083  [    0/   28]\n",
      "loss: 0.064064  [    0/   28]\n",
      "loss: 0.064045  [    0/   28]\n",
      "loss: 0.064026  [    0/   28]\n",
      "loss: 0.064008  [    0/   28]\n",
      "loss: 0.063987  [    0/   28]\n",
      "loss: 0.063968  [    0/   28]\n",
      "loss: 0.063949  [    0/   28]\n",
      "loss: 0.063930  [    0/   28]\n",
      "loss: 0.063910  [    0/   28]\n",
      "loss: 0.063891  [    0/   28]\n",
      "loss: 0.063871  [    0/   28]\n",
      "loss: 0.063852  [    0/   28]\n",
      "loss: 0.063834  [    0/   28]\n",
      "loss: 0.063814  [    0/   28]\n",
      "loss: 0.063795  [    0/   28]\n",
      "loss: 0.063776  [    0/   28]\n",
      "loss: 0.063757  [    0/   28]\n",
      "loss: 0.063736  [    0/   28]\n",
      "loss: 0.063717  [    0/   28]\n",
      "loss: 0.063699  [    0/   28]\n",
      "loss: 0.063679  [    0/   28]\n",
      "loss: 0.063660  [    0/   28]\n",
      "loss: 0.063641  [    0/   28]\n",
      "loss: 0.063623  [    0/   28]\n",
      "loss: 0.063602  [    0/   28]\n",
      "loss: 0.063583  [    0/   28]\n",
      "loss: 0.063565  [    0/   28]\n",
      "loss: 0.063545  [    0/   28]\n",
      "loss: 0.063526  [    0/   28]\n",
      "loss: 0.063507  [    0/   28]\n",
      "loss: 0.063487  [    0/   28]\n",
      "loss: 0.063469  [    0/   28]\n",
      "loss: 0.063450  [    0/   28]\n",
      "loss: 0.063431  [    0/   28]\n",
      "loss: 0.063412  [    0/   28]\n",
      "loss: 0.063392  [    0/   28]\n",
      "loss: 0.063374  [    0/   28]\n",
      "loss: 0.063355  [    0/   28]\n",
      "loss: 0.063336  [    0/   28]\n",
      "loss: 0.063317  [    0/   28]\n",
      "loss: 0.063298  [    0/   28]\n",
      "loss: 0.063279  [    0/   28]\n",
      "loss: 0.063259  [    0/   28]\n",
      "loss: 0.063241  [    0/   28]\n",
      "loss: 0.063222  [    0/   28]\n",
      "loss: 0.063202  [    0/   28]\n",
      "loss: 0.063184  [    0/   28]\n",
      "loss: 0.063165  [    0/   28]\n",
      "loss: 0.063145  [    0/   28]\n",
      "loss: 0.063127  [    0/   28]\n",
      "loss: 0.063109  [    0/   28]\n",
      "loss: 0.063090  [    0/   28]\n",
      "loss: 0.063070  [    0/   28]\n",
      "loss: 0.063052  [    0/   28]\n",
      "loss: 0.063033  [    0/   28]\n",
      "loss: 0.063013  [    0/   28]\n",
      "loss: 0.062995  [    0/   28]\n",
      "loss: 0.062976  [    0/   28]\n",
      "loss: 0.062957  [    0/   28]\n",
      "loss: 0.062939  [    0/   28]\n",
      "loss: 0.062920  [    0/   28]\n",
      "loss: 0.062901  [    0/   28]\n",
      "loss: 0.062882  [    0/   28]\n",
      "loss: 0.062864  [    0/   28]\n",
      "loss: 0.062844  [    0/   28]\n",
      "loss: 0.062826  [    0/   28]\n",
      "loss: 0.062807  [    0/   28]\n",
      "loss: 0.062788  [    0/   28]\n",
      "loss: 0.062770  [    0/   28]\n",
      "loss: 0.062751  [    0/   28]\n",
      "loss: 0.062732  [    0/   28]\n",
      "loss: 0.062713  [    0/   28]\n",
      "loss: 0.062695  [    0/   28]\n",
      "loss: 0.062676  [    0/   28]\n",
      "loss: 0.062658  [    0/   28]\n",
      "loss: 0.062639  [    0/   28]\n",
      "loss: 0.062619  [    0/   28]\n",
      "loss: 0.062601  [    0/   28]\n",
      "loss: 0.062583  [    0/   28]\n",
      "loss: 0.062564  [    0/   28]\n",
      "loss: 0.062545  [    0/   28]\n",
      "loss: 0.062527  [    0/   28]\n",
      "loss: 0.062508  [    0/   28]\n",
      "loss: 0.062489  [    0/   28]\n",
      "loss: 0.062471  [    0/   28]\n",
      "loss: 0.062452  [    0/   28]\n",
      "loss: 0.062434  [    0/   28]\n",
      "loss: 0.062415  [    0/   28]\n",
      "loss: 0.062396  [    0/   28]\n",
      "loss: 0.062377  [    0/   28]\n",
      "loss: 0.062359  [    0/   28]\n",
      "loss: 0.062341  [    0/   28]\n",
      "loss: 0.062322  [    0/   28]\n",
      "loss: 0.062304  [    0/   28]\n",
      "loss: 0.062285  [    0/   28]\n",
      "loss: 0.062267  [    0/   28]\n",
      "loss: 0.062248  [    0/   28]\n",
      "loss: 0.062229  [    0/   28]\n",
      "loss: 0.062211  [    0/   28]\n",
      "loss: 0.062193  [    0/   28]\n",
      "loss: 0.062174  [    0/   28]\n",
      "loss: 0.062155  [    0/   28]\n",
      "loss: 0.062137  [    0/   28]\n",
      "loss: 0.062118  [    0/   28]\n",
      "loss: 0.062100  [    0/   28]\n",
      "loss: 0.062082  [    0/   28]\n",
      "loss: 0.062063  [    0/   28]\n",
      "loss: 0.062044  [    0/   28]\n",
      "loss: 0.062026  [    0/   28]\n",
      "loss: 0.062008  [    0/   28]\n",
      "loss: 0.061989  [    0/   28]\n",
      "loss: 0.061971  [    0/   28]\n",
      "loss: 0.061953  [    0/   28]\n",
      "loss: 0.061934  [    0/   28]\n",
      "loss: 0.061916  [    0/   28]\n",
      "loss: 0.061897  [    0/   28]\n",
      "loss: 0.061879  [    0/   28]\n",
      "loss: 0.061861  [    0/   28]\n",
      "loss: 0.061843  [    0/   28]\n",
      "loss: 0.061824  [    0/   28]\n",
      "loss: 0.061806  [    0/   28]\n",
      "loss: 0.061789  [    0/   28]\n",
      "loss: 0.061769  [    0/   28]\n",
      "loss: 0.061751  [    0/   28]\n",
      "loss: 0.061733  [    0/   28]\n",
      "loss: 0.061715  [    0/   28]\n",
      "loss: 0.061697  [    0/   28]\n",
      "loss: 0.061678  [    0/   28]\n",
      "loss: 0.061660  [    0/   28]\n",
      "loss: 0.061642  [    0/   28]\n",
      "loss: 0.061624  [    0/   28]\n",
      "loss: 0.061605  [    0/   28]\n",
      "loss: 0.061587  [    0/   28]\n",
      "loss: 0.061569  [    0/   28]\n",
      "loss: 0.061550  [    0/   28]\n",
      "loss: 0.061533  [    0/   28]\n",
      "loss: 0.061514  [    0/   28]\n",
      "loss: 0.061496  [    0/   28]\n",
      "loss: 0.061478  [    0/   28]\n",
      "loss: 0.061459  [    0/   28]\n",
      "loss: 0.061442  [    0/   28]\n",
      "loss: 0.061424  [    0/   28]\n",
      "loss: 0.061405  [    0/   28]\n",
      "loss: 0.061388  [    0/   28]\n",
      "loss: 0.061370  [    0/   28]\n",
      "loss: 0.061351  [    0/   28]\n",
      "loss: 0.061333  [    0/   28]\n",
      "loss: 0.061314  [    0/   28]\n",
      "loss: 0.061296  [    0/   28]\n",
      "loss: 0.061279  [    0/   28]\n",
      "loss: 0.061261  [    0/   28]\n",
      "loss: 0.061243  [    0/   28]\n",
      "loss: 0.061225  [    0/   28]\n",
      "loss: 0.061207  [    0/   28]\n",
      "loss: 0.061189  [    0/   28]\n",
      "loss: 0.061171  [    0/   28]\n",
      "loss: 0.061153  [    0/   28]\n",
      "loss: 0.061134  [    0/   28]\n",
      "loss: 0.061117  [    0/   28]\n",
      "loss: 0.061098  [    0/   28]\n",
      "loss: 0.061081  [    0/   28]\n",
      "loss: 0.061063  [    0/   28]\n",
      "loss: 0.061045  [    0/   28]\n",
      "loss: 0.061027  [    0/   28]\n",
      "loss: 0.061009  [    0/   28]\n",
      "loss: 0.060991  [    0/   28]\n",
      "loss: 0.060973  [    0/   28]\n",
      "loss: 0.060956  [    0/   28]\n",
      "loss: 0.060938  [    0/   28]\n",
      "loss: 0.060920  [    0/   28]\n",
      "loss: 0.060901  [    0/   28]\n",
      "loss: 0.060883  [    0/   28]\n",
      "loss: 0.060865  [    0/   28]\n",
      "loss: 0.060848  [    0/   28]\n",
      "loss: 0.060831  [    0/   28]\n",
      "loss: 0.060813  [    0/   28]\n",
      "loss: 0.060794  [    0/   28]\n",
      "loss: 0.060777  [    0/   28]\n",
      "loss: 0.060759  [    0/   28]\n",
      "loss: 0.060741  [    0/   28]\n",
      "loss: 0.060723  [    0/   28]\n",
      "loss: 0.060705  [    0/   28]\n",
      "loss: 0.060688  [    0/   28]\n",
      "loss: 0.060670  [    0/   28]\n",
      "loss: 0.060652  [    0/   28]\n",
      "loss: 0.060634  [    0/   28]\n",
      "loss: 0.060617  [    0/   28]\n",
      "loss: 0.060599  [    0/   28]\n",
      "loss: 0.060581  [    0/   28]\n",
      "loss: 0.060563  [    0/   28]\n",
      "loss: 0.060546  [    0/   28]\n",
      "loss: 0.060528  [    0/   28]\n",
      "loss: 0.060510  [    0/   28]\n",
      "loss: 0.060493  [    0/   28]\n",
      "loss: 0.060474  [    0/   28]\n",
      "loss: 0.060457  [    0/   28]\n",
      "loss: 0.060440  [    0/   28]\n",
      "loss: 0.060422  [    0/   28]\n",
      "loss: 0.060404  [    0/   28]\n",
      "loss: 0.060386  [    0/   28]\n",
      "loss: 0.060369  [    0/   28]\n",
      "loss: 0.060351  [    0/   28]\n",
      "loss: 0.060334  [    0/   28]\n",
      "loss: 0.060316  [    0/   28]\n",
      "loss: 0.060299  [    0/   28]\n",
      "loss: 0.060280  [    0/   28]\n",
      "loss: 0.060263  [    0/   28]\n",
      "loss: 0.060245  [    0/   28]\n",
      "loss: 0.060228  [    0/   28]\n",
      "loss: 0.060211  [    0/   28]\n",
      "loss: 0.060193  [    0/   28]\n",
      "loss: 0.060175  [    0/   28]\n",
      "loss: 0.060157  [    0/   28]\n",
      "loss: 0.060140  [    0/   28]\n",
      "loss: 0.060123  [    0/   28]\n",
      "loss: 0.060106  [    0/   28]\n",
      "loss: 0.060087  [    0/   28]\n",
      "loss: 0.060070  [    0/   28]\n",
      "loss: 0.060052  [    0/   28]\n",
      "loss: 0.060036  [    0/   28]\n",
      "loss: 0.060017  [    0/   28]\n",
      "loss: 0.060001  [    0/   28]\n",
      "loss: 0.059982  [    0/   28]\n",
      "loss: 0.059965  [    0/   28]\n",
      "loss: 0.059948  [    0/   28]\n",
      "loss: 0.059931  [    0/   28]\n",
      "loss: 0.059913  [    0/   28]\n",
      "loss: 0.059896  [    0/   28]\n",
      "loss: 0.059879  [    0/   28]\n",
      "loss: 0.059861  [    0/   28]\n",
      "loss: 0.059844  [    0/   28]\n",
      "loss: 0.059826  [    0/   28]\n",
      "loss: 0.059808  [    0/   28]\n",
      "loss: 0.059791  [    0/   28]\n",
      "loss: 0.059775  [    0/   28]\n",
      "loss: 0.059757  [    0/   28]\n",
      "loss: 0.059739  [    0/   28]\n",
      "loss: 0.059721  [    0/   28]\n",
      "loss: 0.059705  [    0/   28]\n",
      "loss: 0.059688  [    0/   28]\n",
      "loss: 0.059670  [    0/   28]\n",
      "loss: 0.059652  [    0/   28]\n",
      "loss: 0.059635  [    0/   28]\n",
      "loss: 0.059618  [    0/   28]\n",
      "loss: 0.059601  [    0/   28]\n",
      "loss: 0.059584  [    0/   28]\n",
      "loss: 0.059566  [    0/   28]\n",
      "loss: 0.059549  [    0/   28]\n",
      "loss: 0.059531  [    0/   28]\n",
      "loss: 0.059515  [    0/   28]\n",
      "loss: 0.059498  [    0/   28]\n",
      "loss: 0.059480  [    0/   28]\n",
      "loss: 0.059463  [    0/   28]\n",
      "loss: 0.059445  [    0/   28]\n",
      "loss: 0.059428  [    0/   28]\n",
      "loss: 0.059411  [    0/   28]\n",
      "loss: 0.059394  [    0/   28]\n",
      "loss: 0.059376  [    0/   28]\n",
      "loss: 0.059359  [    0/   28]\n",
      "loss: 0.059342  [    0/   28]\n",
      "loss: 0.059325  [    0/   28]\n",
      "loss: 0.059308  [    0/   28]\n",
      "loss: 0.059291  [    0/   28]\n",
      "loss: 0.059274  [    0/   28]\n",
      "loss: 0.059257  [    0/   28]\n",
      "loss: 0.059240  [    0/   28]\n",
      "loss: 0.059223  [    0/   28]\n",
      "loss: 0.059205  [    0/   28]\n",
      "loss: 0.059188  [    0/   28]\n",
      "loss: 0.059170  [    0/   28]\n",
      "loss: 0.059154  [    0/   28]\n",
      "loss: 0.059137  [    0/   28]\n",
      "loss: 0.059121  [    0/   28]\n",
      "loss: 0.059103  [    0/   28]\n",
      "loss: 0.059085  [    0/   28]\n",
      "loss: 0.059069  [    0/   28]\n",
      "loss: 0.059052  [    0/   28]\n",
      "loss: 0.059035  [    0/   28]\n",
      "loss: 0.059017  [    0/   28]\n",
      "loss: 0.059000  [    0/   28]\n",
      "loss: 0.058984  [    0/   28]\n",
      "loss: 0.058966  [    0/   28]\n",
      "loss: 0.058950  [    0/   28]\n",
      "loss: 0.058933  [    0/   28]\n",
      "loss: 0.058916  [    0/   28]\n",
      "loss: 0.058899  [    0/   28]\n",
      "loss: 0.058882  [    0/   28]\n",
      "loss: 0.058865  [    0/   28]\n",
      "loss: 0.058848  [    0/   28]\n",
      "loss: 0.058831  [    0/   28]\n",
      "loss: 0.058814  [    0/   28]\n",
      "loss: 0.058798  [    0/   28]\n",
      "loss: 0.058780  [    0/   28]\n",
      "loss: 0.058763  [    0/   28]\n",
      "loss: 0.058746  [    0/   28]\n",
      "loss: 0.058730  [    0/   28]\n",
      "loss: 0.058712  [    0/   28]\n",
      "loss: 0.058696  [    0/   28]\n",
      "loss: 0.058679  [    0/   28]\n",
      "loss: 0.058662  [    0/   28]\n",
      "loss: 0.058646  [    0/   28]\n",
      "loss: 0.058629  [    0/   28]\n",
      "loss: 0.058612  [    0/   28]\n",
      "loss: 0.058595  [    0/   28]\n",
      "loss: 0.058578  [    0/   28]\n",
      "loss: 0.058561  [    0/   28]\n",
      "loss: 0.058545  [    0/   28]\n",
      "loss: 0.058528  [    0/   28]\n",
      "loss: 0.058512  [    0/   28]\n",
      "loss: 0.058494  [    0/   28]\n",
      "loss: 0.058477  [    0/   28]\n",
      "loss: 0.058461  [    0/   28]\n",
      "loss: 0.058445  [    0/   28]\n",
      "loss: 0.058427  [    0/   28]\n",
      "loss: 0.058411  [    0/   28]\n",
      "loss: 0.058394  [    0/   28]\n",
      "loss: 0.058377  [    0/   28]\n",
      "loss: 0.058360  [    0/   28]\n",
      "loss: 0.058344  [    0/   28]\n",
      "loss: 0.058327  [    0/   28]\n",
      "loss: 0.058311  [    0/   28]\n",
      "loss: 0.058293  [    0/   28]\n",
      "loss: 0.058277  [    0/   28]\n",
      "loss: 0.058260  [    0/   28]\n",
      "loss: 0.058244  [    0/   28]\n",
      "loss: 0.058227  [    0/   28]\n",
      "loss: 0.058211  [    0/   28]\n",
      "loss: 0.058193  [    0/   28]\n",
      "loss: 0.058177  [    0/   28]\n",
      "loss: 0.058160  [    0/   28]\n",
      "loss: 0.058143  [    0/   28]\n",
      "loss: 0.058127  [    0/   28]\n",
      "loss: 0.058111  [    0/   28]\n",
      "loss: 0.058094  [    0/   28]\n",
      "loss: 0.058077  [    0/   28]\n",
      "loss: 0.058061  [    0/   28]\n",
      "loss: 0.058045  [    0/   28]\n",
      "loss: 0.058028  [    0/   28]\n",
      "loss: 0.058011  [    0/   28]\n",
      "loss: 0.057995  [    0/   28]\n",
      "loss: 0.057978  [    0/   28]\n",
      "loss: 0.057961  [    0/   28]\n",
      "loss: 0.057945  [    0/   28]\n",
      "loss: 0.057928  [    0/   28]\n",
      "loss: 0.057912  [    0/   28]\n",
      "loss: 0.057895  [    0/   28]\n",
      "loss: 0.057879  [    0/   28]\n",
      "loss: 0.057862  [    0/   28]\n",
      "loss: 0.057845  [    0/   28]\n",
      "loss: 0.057829  [    0/   28]\n",
      "loss: 0.057814  [    0/   28]\n",
      "loss: 0.057796  [    0/   28]\n",
      "loss: 0.057779  [    0/   28]\n",
      "loss: 0.057763  [    0/   28]\n",
      "loss: 0.057747  [    0/   28]\n",
      "loss: 0.057730  [    0/   28]\n",
      "loss: 0.057714  [    0/   28]\n",
      "loss: 0.057698  [    0/   28]\n",
      "loss: 0.057682  [    0/   28]\n",
      "loss: 0.057664  [    0/   28]\n",
      "loss: 0.057648  [    0/   28]\n",
      "loss: 0.057632  [    0/   28]\n",
      "loss: 0.057616  [    0/   28]\n",
      "loss: 0.057599  [    0/   28]\n",
      "loss: 0.057582  [    0/   28]\n",
      "loss: 0.057567  [    0/   28]\n",
      "loss: 0.057550  [    0/   28]\n",
      "loss: 0.057534  [    0/   28]\n",
      "loss: 0.057517  [    0/   28]\n",
      "loss: 0.057501  [    0/   28]\n",
      "loss: 0.057485  [    0/   28]\n",
      "loss: 0.057469  [    0/   28]\n",
      "loss: 0.057452  [    0/   28]\n",
      "loss: 0.057436  [    0/   28]\n",
      "loss: 0.057420  [    0/   28]\n",
      "loss: 0.057403  [    0/   28]\n",
      "loss: 0.057387  [    0/   28]\n",
      "loss: 0.057371  [    0/   28]\n",
      "loss: 0.057354  [    0/   28]\n",
      "loss: 0.057338  [    0/   28]\n",
      "loss: 0.057322  [    0/   28]\n",
      "loss: 0.057306  [    0/   28]\n",
      "loss: 0.057289  [    0/   28]\n",
      "loss: 0.057273  [    0/   28]\n",
      "loss: 0.057257  [    0/   28]\n",
      "loss: 0.057241  [    0/   28]\n",
      "loss: 0.057224  [    0/   28]\n",
      "loss: 0.057208  [    0/   28]\n",
      "loss: 0.057192  [    0/   28]\n",
      "loss: 0.057176  [    0/   28]\n",
      "loss: 0.057159  [    0/   28]\n",
      "loss: 0.057143  [    0/   28]\n",
      "loss: 0.057127  [    0/   28]\n",
      "loss: 0.057111  [    0/   28]\n",
      "loss: 0.057095  [    0/   28]\n",
      "loss: 0.057079  [    0/   28]\n",
      "loss: 0.057063  [    0/   28]\n",
      "loss: 0.057047  [    0/   28]\n",
      "loss: 0.057031  [    0/   28]\n",
      "loss: 0.057014  [    0/   28]\n",
      "loss: 0.056998  [    0/   28]\n",
      "loss: 0.056982  [    0/   28]\n",
      "loss: 0.056966  [    0/   28]\n",
      "loss: 0.056950  [    0/   28]\n",
      "loss: 0.056934  [    0/   28]\n",
      "loss: 0.056918  [    0/   28]\n",
      "loss: 0.056902  [    0/   28]\n",
      "loss: 0.056885  [    0/   28]\n",
      "loss: 0.056870  [    0/   28]\n",
      "loss: 0.056853  [    0/   28]\n",
      "loss: 0.056837  [    0/   28]\n",
      "loss: 0.056822  [    0/   28]\n",
      "loss: 0.056805  [    0/   28]\n",
      "loss: 0.056790  [    0/   28]\n",
      "loss: 0.056773  [    0/   28]\n",
      "loss: 0.056758  [    0/   28]\n",
      "loss: 0.056741  [    0/   28]\n",
      "loss: 0.056725  [    0/   28]\n",
      "loss: 0.056709  [    0/   28]\n",
      "loss: 0.056693  [    0/   28]\n",
      "loss: 0.056677  [    0/   28]\n",
      "loss: 0.056662  [    0/   28]\n",
      "loss: 0.056645  [    0/   28]\n",
      "loss: 0.056629  [    0/   28]\n",
      "loss: 0.056614  [    0/   28]\n",
      "loss: 0.056597  [    0/   28]\n",
      "loss: 0.056582  [    0/   28]\n",
      "loss: 0.056566  [    0/   28]\n",
      "loss: 0.056550  [    0/   28]\n",
      "loss: 0.056534  [    0/   28]\n",
      "loss: 0.056518  [    0/   28]\n",
      "loss: 0.056502  [    0/   28]\n",
      "loss: 0.056486  [    0/   28]\n",
      "loss: 0.056470  [    0/   28]\n",
      "loss: 0.056454  [    0/   28]\n",
      "loss: 0.056438  [    0/   28]\n",
      "loss: 0.056423  [    0/   28]\n",
      "loss: 0.056407  [    0/   28]\n",
      "loss: 0.056391  [    0/   28]\n",
      "loss: 0.056376  [    0/   28]\n",
      "loss: 0.056359  [    0/   28]\n",
      "loss: 0.056344  [    0/   28]\n",
      "loss: 0.056328  [    0/   28]\n",
      "loss: 0.056312  [    0/   28]\n",
      "loss: 0.056296  [    0/   28]\n",
      "loss: 0.056280  [    0/   28]\n",
      "loss: 0.056264  [    0/   28]\n",
      "loss: 0.056249  [    0/   28]\n",
      "loss: 0.056233  [    0/   28]\n",
      "loss: 0.056217  [    0/   28]\n",
      "loss: 0.056201  [    0/   28]\n",
      "loss: 0.056185  [    0/   28]\n",
      "loss: 0.056170  [    0/   28]\n",
      "loss: 0.056154  [    0/   28]\n",
      "loss: 0.056139  [    0/   28]\n",
      "loss: 0.056122  [    0/   28]\n",
      "loss: 0.056107  [    0/   28]\n",
      "loss: 0.056091  [    0/   28]\n",
      "loss: 0.056076  [    0/   28]\n",
      "loss: 0.056060  [    0/   28]\n",
      "loss: 0.056044  [    0/   28]\n",
      "loss: 0.056029  [    0/   28]\n",
      "loss: 0.056013  [    0/   28]\n",
      "loss: 0.055997  [    0/   28]\n",
      "loss: 0.055981  [    0/   28]\n",
      "loss: 0.055966  [    0/   28]\n",
      "loss: 0.055950  [    0/   28]\n",
      "loss: 0.055935  [    0/   28]\n",
      "loss: 0.055918  [    0/   28]\n",
      "loss: 0.055903  [    0/   28]\n",
      "loss: 0.055888  [    0/   28]\n",
      "loss: 0.055873  [    0/   28]\n",
      "loss: 0.055856  [    0/   28]\n",
      "loss: 0.055840  [    0/   28]\n",
      "loss: 0.055825  [    0/   28]\n",
      "loss: 0.055809  [    0/   28]\n",
      "loss: 0.055794  [    0/   28]\n",
      "loss: 0.055779  [    0/   28]\n",
      "loss: 0.055763  [    0/   28]\n",
      "loss: 0.055747  [    0/   28]\n",
      "loss: 0.055732  [    0/   28]\n",
      "loss: 0.055716  [    0/   28]\n",
      "loss: 0.055701  [    0/   28]\n",
      "loss: 0.055685  [    0/   28]\n",
      "loss: 0.055670  [    0/   28]\n",
      "loss: 0.055654  [    0/   28]\n",
      "loss: 0.055638  [    0/   28]\n",
      "loss: 0.055623  [    0/   28]\n",
      "loss: 0.055607  [    0/   28]\n",
      "loss: 0.055592  [    0/   28]\n",
      "loss: 0.055576  [    0/   28]\n",
      "loss: 0.055562  [    0/   28]\n",
      "loss: 0.055545  [    0/   28]\n",
      "loss: 0.055530  [    0/   28]\n",
      "loss: 0.055514  [    0/   28]\n",
      "loss: 0.055499  [    0/   28]\n",
      "loss: 0.055484  [    0/   28]\n",
      "loss: 0.055468  [    0/   28]\n",
      "loss: 0.055453  [    0/   28]\n",
      "loss: 0.055438  [    0/   28]\n",
      "loss: 0.055422  [    0/   28]\n",
      "loss: 0.055407  [    0/   28]\n",
      "loss: 0.055391  [    0/   28]\n",
      "loss: 0.055376  [    0/   28]\n",
      "loss: 0.055360  [    0/   28]\n",
      "loss: 0.055345  [    0/   28]\n",
      "loss: 0.055330  [    0/   28]\n",
      "loss: 0.055314  [    0/   28]\n",
      "loss: 0.055299  [    0/   28]\n",
      "loss: 0.055284  [    0/   28]\n",
      "loss: 0.055269  [    0/   28]\n",
      "loss: 0.055253  [    0/   28]\n",
      "loss: 0.055237  [    0/   28]\n",
      "loss: 0.055222  [    0/   28]\n",
      "loss: 0.055207  [    0/   28]\n",
      "loss: 0.055191  [    0/   28]\n",
      "loss: 0.055177  [    0/   28]\n",
      "loss: 0.055161  [    0/   28]\n",
      "loss: 0.055146  [    0/   28]\n",
      "loss: 0.055130  [    0/   28]\n",
      "loss: 0.055115  [    0/   28]\n",
      "loss: 0.055100  [    0/   28]\n",
      "loss: 0.055084  [    0/   28]\n",
      "loss: 0.055069  [    0/   28]\n",
      "loss: 0.055054  [    0/   28]\n",
      "loss: 0.055039  [    0/   28]\n",
      "loss: 0.055024  [    0/   28]\n",
      "loss: 0.055008  [    0/   28]\n",
      "loss: 0.054993  [    0/   28]\n",
      "loss: 0.054978  [    0/   28]\n",
      "loss: 0.054962  [    0/   28]\n",
      "loss: 0.054948  [    0/   28]\n",
      "loss: 0.054932  [    0/   28]\n",
      "loss: 0.054917  [    0/   28]\n",
      "loss: 0.054902  [    0/   28]\n",
      "loss: 0.054887  [    0/   28]\n",
      "loss: 0.054871  [    0/   28]\n",
      "loss: 0.054856  [    0/   28]\n",
      "loss: 0.054841  [    0/   28]\n",
      "loss: 0.054825  [    0/   28]\n",
      "loss: 0.054811  [    0/   28]\n",
      "loss: 0.054796  [    0/   28]\n",
      "loss: 0.054781  [    0/   28]\n",
      "loss: 0.054766  [    0/   28]\n",
      "loss: 0.054750  [    0/   28]\n",
      "loss: 0.054735  [    0/   28]\n",
      "loss: 0.054720  [    0/   28]\n",
      "loss: 0.054705  [    0/   28]\n",
      "loss: 0.054690  [    0/   28]\n",
      "loss: 0.054674  [    0/   28]\n",
      "loss: 0.054660  [    0/   28]\n",
      "loss: 0.054645  [    0/   28]\n",
      "loss: 0.054629  [    0/   28]\n",
      "loss: 0.054615  [    0/   28]\n",
      "loss: 0.054599  [    0/   28]\n",
      "loss: 0.054584  [    0/   28]\n",
      "loss: 0.054569  [    0/   28]\n",
      "loss: 0.054554  [    0/   28]\n",
      "loss: 0.054540  [    0/   28]\n",
      "loss: 0.054524  [    0/   28]\n",
      "loss: 0.054509  [    0/   28]\n",
      "loss: 0.054494  [    0/   28]\n",
      "loss: 0.054479  [    0/   28]\n",
      "loss: 0.054464  [    0/   28]\n",
      "loss: 0.054449  [    0/   28]\n",
      "loss: 0.054434  [    0/   28]\n",
      "loss: 0.054419  [    0/   28]\n",
      "loss: 0.054403  [    0/   28]\n",
      "loss: 0.054389  [    0/   28]\n",
      "loss: 0.054374  [    0/   28]\n",
      "loss: 0.054359  [    0/   28]\n",
      "loss: 0.054344  [    0/   28]\n",
      "loss: 0.054329  [    0/   28]\n",
      "loss: 0.054314  [    0/   28]\n",
      "loss: 0.054299  [    0/   28]\n",
      "loss: 0.054284  [    0/   28]\n",
      "loss: 0.054269  [    0/   28]\n",
      "loss: 0.054254  [    0/   28]\n",
      "loss: 0.054240  [    0/   28]\n",
      "loss: 0.054225  [    0/   28]\n",
      "loss: 0.054210  [    0/   28]\n",
      "loss: 0.054195  [    0/   28]\n",
      "loss: 0.054180  [    0/   28]\n",
      "loss: 0.054165  [    0/   28]\n",
      "loss: 0.054150  [    0/   28]\n",
      "loss: 0.054136  [    0/   28]\n",
      "loss: 0.054121  [    0/   28]\n",
      "loss: 0.054106  [    0/   28]\n",
      "loss: 0.054091  [    0/   28]\n",
      "loss: 0.054076  [    0/   28]\n",
      "loss: 0.054061  [    0/   28]\n",
      "loss: 0.054046  [    0/   28]\n",
      "loss: 0.054032  [    0/   28]\n",
      "loss: 0.054017  [    0/   28]\n",
      "loss: 0.054002  [    0/   28]\n",
      "loss: 0.053987  [    0/   28]\n",
      "loss: 0.053972  [    0/   28]\n",
      "loss: 0.053958  [    0/   28]\n",
      "loss: 0.053943  [    0/   28]\n",
      "loss: 0.053928  [    0/   28]\n",
      "loss: 0.053913  [    0/   28]\n",
      "loss: 0.053899  [    0/   28]\n",
      "loss: 0.053884  [    0/   28]\n",
      "loss: 0.053869  [    0/   28]\n",
      "loss: 0.053854  [    0/   28]\n",
      "loss: 0.053839  [    0/   28]\n",
      "loss: 0.053825  [    0/   28]\n",
      "loss: 0.053810  [    0/   28]\n",
      "loss: 0.053795  [    0/   28]\n",
      "loss: 0.053781  [    0/   28]\n",
      "loss: 0.053766  [    0/   28]\n",
      "loss: 0.053751  [    0/   28]\n",
      "loss: 0.053736  [    0/   28]\n",
      "loss: 0.053723  [    0/   28]\n",
      "loss: 0.053707  [    0/   28]\n",
      "loss: 0.053693  [    0/   28]\n",
      "loss: 0.053678  [    0/   28]\n",
      "loss: 0.053664  [    0/   28]\n",
      "loss: 0.053649  [    0/   28]\n",
      "loss: 0.053634  [    0/   28]\n",
      "loss: 0.053620  [    0/   28]\n",
      "loss: 0.053605  [    0/   28]\n",
      "loss: 0.053590  [    0/   28]\n",
      "loss: 0.053576  [    0/   28]\n",
      "loss: 0.053561  [    0/   28]\n",
      "loss: 0.053546  [    0/   28]\n",
      "loss: 0.053531  [    0/   28]\n",
      "loss: 0.053517  [    0/   28]\n",
      "loss: 0.053502  [    0/   28]\n",
      "loss: 0.053488  [    0/   28]\n",
      "loss: 0.053474  [    0/   28]\n",
      "loss: 0.053459  [    0/   28]\n",
      "loss: 0.053445  [    0/   28]\n",
      "loss: 0.053430  [    0/   28]\n",
      "loss: 0.053415  [    0/   28]\n",
      "loss: 0.053401  [    0/   28]\n",
      "loss: 0.053387  [    0/   28]\n",
      "loss: 0.053372  [    0/   28]\n",
      "loss: 0.053357  [    0/   28]\n",
      "loss: 0.053343  [    0/   28]\n",
      "loss: 0.053328  [    0/   28]\n",
      "loss: 0.053314  [    0/   28]\n",
      "loss: 0.053299  [    0/   28]\n",
      "loss: 0.053285  [    0/   28]\n",
      "loss: 0.053270  [    0/   28]\n",
      "loss: 0.053256  [    0/   28]\n",
      "loss: 0.053241  [    0/   28]\n",
      "loss: 0.053227  [    0/   28]\n",
      "loss: 0.053212  [    0/   28]\n",
      "loss: 0.053198  [    0/   28]\n",
      "loss: 0.053184  [    0/   28]\n",
      "loss: 0.053169  [    0/   28]\n",
      "loss: 0.053154  [    0/   28]\n",
      "loss: 0.053141  [    0/   28]\n",
      "loss: 0.053126  [    0/   28]\n",
      "loss: 0.053112  [    0/   28]\n",
      "loss: 0.053097  [    0/   28]\n",
      "loss: 0.053082  [    0/   28]\n",
      "loss: 0.053068  [    0/   28]\n",
      "loss: 0.053053  [    0/   28]\n",
      "loss: 0.053039  [    0/   28]\n",
      "loss: 0.053025  [    0/   28]\n",
      "loss: 0.053011  [    0/   28]\n",
      "loss: 0.052996  [    0/   28]\n",
      "loss: 0.052982  [    0/   28]\n",
      "loss: 0.052967  [    0/   28]\n",
      "loss: 0.052954  [    0/   28]\n",
      "loss: 0.052939  [    0/   28]\n",
      "loss: 0.052924  [    0/   28]\n",
      "loss: 0.052910  [    0/   28]\n",
      "loss: 0.052896  [    0/   28]\n",
      "loss: 0.052882  [    0/   28]\n",
      "loss: 0.052867  [    0/   28]\n",
      "loss: 0.052853  [    0/   28]\n",
      "loss: 0.052838  [    0/   28]\n",
      "loss: 0.052824  [    0/   28]\n",
      "loss: 0.052810  [    0/   28]\n",
      "loss: 0.052796  [    0/   28]\n",
      "loss: 0.052782  [    0/   28]\n",
      "loss: 0.052767  [    0/   28]\n",
      "loss: 0.052754  [    0/   28]\n",
      "loss: 0.052739  [    0/   28]\n",
      "loss: 0.052725  [    0/   28]\n",
      "loss: 0.052710  [    0/   28]\n",
      "loss: 0.052696  [    0/   28]\n",
      "loss: 0.052682  [    0/   28]\n",
      "loss: 0.052668  [    0/   28]\n",
      "loss: 0.052653  [    0/   28]\n",
      "loss: 0.052639  [    0/   28]\n",
      "loss: 0.052625  [    0/   28]\n",
      "loss: 0.052610  [    0/   28]\n",
      "loss: 0.052596  [    0/   28]\n",
      "loss: 0.052583  [    0/   28]\n",
      "loss: 0.052568  [    0/   28]\n",
      "loss: 0.052554  [    0/   28]\n",
      "loss: 0.052539  [    0/   28]\n",
      "loss: 0.052526  [    0/   28]\n",
      "loss: 0.052511  [    0/   28]\n",
      "loss: 0.052497  [    0/   28]\n",
      "loss: 0.052483  [    0/   28]\n",
      "loss: 0.052469  [    0/   28]\n",
      "loss: 0.052455  [    0/   28]\n",
      "loss: 0.052441  [    0/   28]\n",
      "loss: 0.052427  [    0/   28]\n",
      "loss: 0.052413  [    0/   28]\n",
      "loss: 0.052399  [    0/   28]\n",
      "loss: 0.052384  [    0/   28]\n",
      "loss: 0.052371  [    0/   28]\n",
      "loss: 0.052356  [    0/   28]\n",
      "loss: 0.052343  [    0/   28]\n",
      "loss: 0.052328  [    0/   28]\n",
      "loss: 0.052314  [    0/   28]\n",
      "loss: 0.052300  [    0/   28]\n",
      "loss: 0.052286  [    0/   28]\n",
      "loss: 0.052271  [    0/   28]\n",
      "loss: 0.052258  [    0/   28]\n",
      "loss: 0.052244  [    0/   28]\n",
      "loss: 0.052229  [    0/   28]\n",
      "loss: 0.052216  [    0/   28]\n",
      "loss: 0.052202  [    0/   28]\n",
      "loss: 0.052188  [    0/   28]\n",
      "loss: 0.052174  [    0/   28]\n",
      "loss: 0.052160  [    0/   28]\n",
      "loss: 0.052146  [    0/   28]\n",
      "loss: 0.052132  [    0/   28]\n",
      "loss: 0.052117  [    0/   28]\n",
      "loss: 0.052104  [    0/   28]\n",
      "loss: 0.052090  [    0/   28]\n",
      "loss: 0.052076  [    0/   28]\n",
      "loss: 0.052062  [    0/   28]\n",
      "loss: 0.052048  [    0/   28]\n",
      "loss: 0.052034  [    0/   28]\n",
      "loss: 0.052020  [    0/   28]\n",
      "loss: 0.052006  [    0/   28]\n",
      "loss: 0.051992  [    0/   28]\n",
      "loss: 0.051978  [    0/   28]\n",
      "loss: 0.051964  [    0/   28]\n",
      "loss: 0.051951  [    0/   28]\n",
      "loss: 0.051936  [    0/   28]\n",
      "loss: 0.051922  [    0/   28]\n",
      "loss: 0.051909  [    0/   28]\n",
      "loss: 0.051894  [    0/   28]\n",
      "loss: 0.051882  [    0/   28]\n",
      "loss: 0.051867  [    0/   28]\n",
      "loss: 0.051854  [    0/   28]\n",
      "loss: 0.051839  [    0/   28]\n",
      "loss: 0.051825  [    0/   28]\n",
      "loss: 0.051812  [    0/   28]\n",
      "loss: 0.051798  [    0/   28]\n",
      "loss: 0.051784  [    0/   28]\n",
      "loss: 0.051771  [    0/   28]\n",
      "loss: 0.051756  [    0/   28]\n",
      "loss: 0.051743  [    0/   28]\n",
      "loss: 0.051729  [    0/   28]\n",
      "loss: 0.051715  [    0/   28]\n",
      "loss: 0.051701  [    0/   28]\n",
      "loss: 0.051687  [    0/   28]\n",
      "loss: 0.051674  [    0/   28]\n",
      "loss: 0.051660  [    0/   28]\n",
      "loss: 0.051646  [    0/   28]\n",
      "loss: 0.051632  [    0/   28]\n",
      "loss: 0.051619  [    0/   28]\n",
      "loss: 0.051605  [    0/   28]\n",
      "loss: 0.051592  [    0/   28]\n",
      "loss: 0.051578  [    0/   28]\n",
      "loss: 0.051564  [    0/   28]\n",
      "loss: 0.051550  [    0/   28]\n",
      "loss: 0.051537  [    0/   28]\n",
      "loss: 0.051523  [    0/   28]\n",
      "loss: 0.051509  [    0/   28]\n",
      "loss: 0.051495  [    0/   28]\n",
      "loss: 0.051481  [    0/   28]\n",
      "loss: 0.051467  [    0/   28]\n",
      "loss: 0.051454  [    0/   28]\n",
      "loss: 0.051441  [    0/   28]\n",
      "loss: 0.051426  [    0/   28]\n",
      "loss: 0.051413  [    0/   28]\n",
      "loss: 0.051400  [    0/   28]\n",
      "loss: 0.051386  [    0/   28]\n",
      "loss: 0.051372  [    0/   28]\n",
      "loss: 0.051358  [    0/   28]\n",
      "loss: 0.051345  [    0/   28]\n",
      "loss: 0.051331  [    0/   28]\n",
      "loss: 0.051317  [    0/   28]\n",
      "loss: 0.051304  [    0/   28]\n",
      "loss: 0.051290  [    0/   28]\n",
      "loss: 0.051276  [    0/   28]\n",
      "loss: 0.051263  [    0/   28]\n",
      "loss: 0.051249  [    0/   28]\n",
      "loss: 0.051236  [    0/   28]\n",
      "loss: 0.051222  [    0/   28]\n",
      "loss: 0.051209  [    0/   28]\n",
      "loss: 0.051195  [    0/   28]\n",
      "loss: 0.051181  [    0/   28]\n",
      "loss: 0.051168  [    0/   28]\n",
      "loss: 0.051155  [    0/   28]\n",
      "loss: 0.051141  [    0/   28]\n",
      "loss: 0.051127  [    0/   28]\n",
      "loss: 0.051113  [    0/   28]\n",
      "loss: 0.051100  [    0/   28]\n",
      "loss: 0.051087  [    0/   28]\n",
      "loss: 0.051073  [    0/   28]\n",
      "loss: 0.051060  [    0/   28]\n",
      "loss: 0.051046  [    0/   28]\n",
      "loss: 0.051033  [    0/   28]\n",
      "loss: 0.051019  [    0/   28]\n",
      "loss: 0.051005  [    0/   28]\n",
      "loss: 0.050992  [    0/   28]\n",
      "loss: 0.050979  [    0/   28]\n",
      "loss: 0.050965  [    0/   28]\n",
      "loss: 0.050952  [    0/   28]\n",
      "loss: 0.050938  [    0/   28]\n",
      "loss: 0.050925  [    0/   28]\n",
      "loss: 0.050911  [    0/   28]\n",
      "loss: 0.050898  [    0/   28]\n",
      "loss: 0.050884  [    0/   28]\n",
      "loss: 0.050871  [    0/   28]\n",
      "loss: 0.050858  [    0/   28]\n",
      "loss: 0.050844  [    0/   28]\n",
      "loss: 0.050831  [    0/   28]\n",
      "loss: 0.050817  [    0/   28]\n",
      "loss: 0.050804  [    0/   28]\n",
      "loss: 0.050791  [    0/   28]\n",
      "loss: 0.050777  [    0/   28]\n",
      "loss: 0.050764  [    0/   28]\n",
      "loss: 0.050750  [    0/   28]\n",
      "loss: 0.050737  [    0/   28]\n",
      "loss: 0.050724  [    0/   28]\n",
      "loss: 0.050710  [    0/   28]\n",
      "loss: 0.050697  [    0/   28]\n",
      "loss: 0.050683  [    0/   28]\n",
      "loss: 0.050671  [    0/   28]\n",
      "loss: 0.050657  [    0/   28]\n",
      "loss: 0.050644  [    0/   28]\n",
      "loss: 0.050630  [    0/   28]\n",
      "loss: 0.050617  [    0/   28]\n",
      "loss: 0.050604  [    0/   28]\n",
      "loss: 0.050591  [    0/   28]\n",
      "loss: 0.050577  [    0/   28]\n",
      "loss: 0.050564  [    0/   28]\n",
      "loss: 0.050550  [    0/   28]\n",
      "loss: 0.050537  [    0/   28]\n",
      "loss: 0.050524  [    0/   28]\n",
      "loss: 0.050511  [    0/   28]\n",
      "loss: 0.050497  [    0/   28]\n",
      "loss: 0.050484  [    0/   28]\n",
      "loss: 0.050471  [    0/   28]\n",
      "loss: 0.050457  [    0/   28]\n",
      "loss: 0.050444  [    0/   28]\n",
      "loss: 0.050431  [    0/   28]\n",
      "loss: 0.050417  [    0/   28]\n",
      "loss: 0.050404  [    0/   28]\n",
      "loss: 0.050391  [    0/   28]\n",
      "loss: 0.050378  [    0/   28]\n",
      "loss: 0.050365  [    0/   28]\n",
      "loss: 0.050351  [    0/   28]\n",
      "loss: 0.050339  [    0/   28]\n",
      "loss: 0.050325  [    0/   28]\n",
      "loss: 0.050312  [    0/   28]\n",
      "loss: 0.050299  [    0/   28]\n",
      "loss: 0.050286  [    0/   28]\n",
      "loss: 0.050273  [    0/   28]\n",
      "loss: 0.050260  [    0/   28]\n",
      "loss: 0.050246  [    0/   28]\n",
      "loss: 0.050233  [    0/   28]\n",
      "loss: 0.050220  [    0/   28]\n",
      "loss: 0.050206  [    0/   28]\n",
      "loss: 0.050193  [    0/   28]\n",
      "loss: 0.050180  [    0/   28]\n",
      "loss: 0.050167  [    0/   28]\n",
      "loss: 0.050155  [    0/   28]\n",
      "loss: 0.050141  [    0/   28]\n",
      "loss: 0.050128  [    0/   28]\n",
      "loss: 0.050115  [    0/   28]\n",
      "loss: 0.050102  [    0/   28]\n",
      "loss: 0.050089  [    0/   28]\n",
      "loss: 0.050076  [    0/   28]\n",
      "loss: 0.050063  [    0/   28]\n",
      "loss: 0.050049  [    0/   28]\n",
      "loss: 0.050037  [    0/   28]\n",
      "loss: 0.050023  [    0/   28]\n",
      "loss: 0.050010  [    0/   28]\n",
      "loss: 0.049996  [    0/   28]\n",
      "loss: 0.049984  [    0/   28]\n",
      "loss: 0.049971  [    0/   28]\n",
      "loss: 0.049959  [    0/   28]\n",
      "loss: 0.049945  [    0/   28]\n",
      "loss: 0.049932  [    0/   28]\n",
      "loss: 0.049919  [    0/   28]\n",
      "loss: 0.049906  [    0/   28]\n",
      "loss: 0.049893  [    0/   28]\n",
      "loss: 0.049880  [    0/   28]\n",
      "loss: 0.049867  [    0/   28]\n",
      "loss: 0.049854  [    0/   28]\n",
      "loss: 0.049841  [    0/   28]\n",
      "loss: 0.049828  [    0/   28]\n",
      "loss: 0.049815  [    0/   28]\n",
      "loss: 0.049801  [    0/   28]\n",
      "loss: 0.049789  [    0/   28]\n",
      "loss: 0.049776  [    0/   28]\n",
      "loss: 0.049763  [    0/   28]\n",
      "loss: 0.049749  [    0/   28]\n",
      "loss: 0.049737  [    0/   28]\n",
      "loss: 0.049724  [    0/   28]\n",
      "loss: 0.049711  [    0/   28]\n",
      "loss: 0.049698  [    0/   28]\n",
      "loss: 0.049685  [    0/   28]\n",
      "loss: 0.049672  [    0/   28]\n",
      "loss: 0.049659  [    0/   28]\n",
      "loss: 0.049646  [    0/   28]\n",
      "loss: 0.049633  [    0/   28]\n",
      "loss: 0.049621  [    0/   28]\n",
      "loss: 0.049608  [    0/   28]\n",
      "loss: 0.049595  [    0/   28]\n",
      "loss: 0.049582  [    0/   28]\n",
      "loss: 0.049569  [    0/   28]\n",
      "loss: 0.049556  [    0/   28]\n",
      "loss: 0.049543  [    0/   28]\n",
      "loss: 0.049531  [    0/   28]\n",
      "loss: 0.049517  [    0/   28]\n",
      "loss: 0.049505  [    0/   28]\n",
      "loss: 0.049492  [    0/   28]\n",
      "loss: 0.049479  [    0/   28]\n",
      "loss: 0.049466  [    0/   28]\n",
      "loss: 0.049453  [    0/   28]\n",
      "loss: 0.049440  [    0/   28]\n",
      "loss: 0.049428  [    0/   28]\n",
      "loss: 0.049415  [    0/   28]\n",
      "loss: 0.049402  [    0/   28]\n",
      "loss: 0.049389  [    0/   28]\n",
      "loss: 0.049377  [    0/   28]\n",
      "loss: 0.049364  [    0/   28]\n",
      "loss: 0.049351  [    0/   28]\n",
      "loss: 0.049338  [    0/   28]\n",
      "loss: 0.049326  [    0/   28]\n",
      "loss: 0.049313  [    0/   28]\n",
      "loss: 0.049299  [    0/   28]\n",
      "loss: 0.049287  [    0/   28]\n",
      "loss: 0.049274  [    0/   28]\n",
      "loss: 0.049262  [    0/   28]\n",
      "loss: 0.049249  [    0/   28]\n",
      "loss: 0.049236  [    0/   28]\n",
      "loss: 0.049224  [    0/   28]\n",
      "loss: 0.049210  [    0/   28]\n",
      "loss: 0.049198  [    0/   28]\n",
      "loss: 0.049185  [    0/   28]\n",
      "loss: 0.049172  [    0/   28]\n",
      "loss: 0.049160  [    0/   28]\n",
      "loss: 0.049148  [    0/   28]\n",
      "loss: 0.049134  [    0/   28]\n",
      "loss: 0.049122  [    0/   28]\n",
      "loss: 0.049109  [    0/   28]\n",
      "loss: 0.049096  [    0/   28]\n",
      "loss: 0.049083  [    0/   28]\n",
      "loss: 0.049071  [    0/   28]\n",
      "loss: 0.049059  [    0/   28]\n",
      "loss: 0.049046  [    0/   28]\n",
      "loss: 0.049034  [    0/   28]\n",
      "loss: 0.049020  [    0/   28]\n",
      "loss: 0.049008  [    0/   28]\n",
      "loss: 0.048995  [    0/   28]\n",
      "loss: 0.048983  [    0/   28]\n",
      "loss: 0.048971  [    0/   28]\n",
      "loss: 0.048957  [    0/   28]\n",
      "loss: 0.048945  [    0/   28]\n",
      "loss: 0.048933  [    0/   28]\n",
      "loss: 0.048919  [    0/   28]\n",
      "loss: 0.048907  [    0/   28]\n",
      "loss: 0.048895  [    0/   28]\n",
      "loss: 0.048882  [    0/   28]\n",
      "loss: 0.048869  [    0/   28]\n",
      "loss: 0.048857  [    0/   28]\n",
      "loss: 0.048844  [    0/   28]\n",
      "loss: 0.048832  [    0/   28]\n",
      "loss: 0.048819  [    0/   28]\n",
      "loss: 0.048806  [    0/   28]\n",
      "loss: 0.048794  [    0/   28]\n",
      "loss: 0.048782  [    0/   28]\n",
      "loss: 0.048769  [    0/   28]\n",
      "loss: 0.048756  [    0/   28]\n",
      "loss: 0.048744  [    0/   28]\n",
      "loss: 0.048731  [    0/   28]\n",
      "loss: 0.048719  [    0/   28]\n",
      "loss: 0.048707  [    0/   28]\n",
      "loss: 0.048694  [    0/   28]\n",
      "loss: 0.048681  [    0/   28]\n",
      "loss: 0.048670  [    0/   28]\n",
      "loss: 0.048657  [    0/   28]\n",
      "loss: 0.048644  [    0/   28]\n",
      "loss: 0.048631  [    0/   28]\n",
      "loss: 0.048619  [    0/   28]\n",
      "loss: 0.048607  [    0/   28]\n",
      "loss: 0.048594  [    0/   28]\n",
      "loss: 0.048582  [    0/   28]\n",
      "loss: 0.048569  [    0/   28]\n",
      "loss: 0.048557  [    0/   28]\n",
      "loss: 0.048544  [    0/   28]\n",
      "loss: 0.048532  [    0/   28]\n",
      "loss: 0.048519  [    0/   28]\n",
      "loss: 0.048507  [    0/   28]\n",
      "loss: 0.048495  [    0/   28]\n",
      "loss: 0.048482  [    0/   28]\n",
      "loss: 0.048470  [    0/   28]\n",
      "loss: 0.048458  [    0/   28]\n",
      "loss: 0.048445  [    0/   28]\n",
      "loss: 0.048433  [    0/   28]\n",
      "loss: 0.048420  [    0/   28]\n",
      "loss: 0.048408  [    0/   28]\n",
      "loss: 0.048396  [    0/   28]\n",
      "loss: 0.048383  [    0/   28]\n",
      "loss: 0.048371  [    0/   28]\n",
      "loss: 0.048358  [    0/   28]\n",
      "loss: 0.048346  [    0/   28]\n",
      "loss: 0.048335  [    0/   28]\n",
      "loss: 0.048322  [    0/   28]\n",
      "loss: 0.048309  [    0/   28]\n",
      "loss: 0.048297  [    0/   28]\n",
      "loss: 0.048285  [    0/   28]\n",
      "loss: 0.048272  [    0/   28]\n",
      "loss: 0.048259  [    0/   28]\n",
      "loss: 0.048248  [    0/   28]\n",
      "loss: 0.048235  [    0/   28]\n",
      "loss: 0.048223  [    0/   28]\n",
      "loss: 0.048210  [    0/   28]\n",
      "loss: 0.048199  [    0/   28]\n",
      "loss: 0.048186  [    0/   28]\n",
      "loss: 0.048174  [    0/   28]\n",
      "loss: 0.048161  [    0/   28]\n",
      "loss: 0.048149  [    0/   28]\n",
      "loss: 0.048137  [    0/   28]\n",
      "loss: 0.048125  [    0/   28]\n",
      "loss: 0.048113  [    0/   28]\n",
      "loss: 0.048100  [    0/   28]\n",
      "loss: 0.048088  [    0/   28]\n",
      "loss: 0.048076  [    0/   28]\n",
      "loss: 0.048063  [    0/   28]\n",
      "loss: 0.048051  [    0/   28]\n",
      "loss: 0.048039  [    0/   28]\n",
      "loss: 0.048027  [    0/   28]\n",
      "loss: 0.048015  [    0/   28]\n",
      "loss: 0.048003  [    0/   28]\n",
      "loss: 0.047990  [    0/   28]\n",
      "loss: 0.047978  [    0/   28]\n",
      "loss: 0.047965  [    0/   28]\n",
      "loss: 0.047954  [    0/   28]\n",
      "loss: 0.047942  [    0/   28]\n",
      "loss: 0.047930  [    0/   28]\n",
      "loss: 0.047917  [    0/   28]\n",
      "loss: 0.047905  [    0/   28]\n",
      "loss: 0.047892  [    0/   28]\n",
      "loss: 0.047880  [    0/   28]\n",
      "loss: 0.047868  [    0/   28]\n",
      "loss: 0.047857  [    0/   28]\n",
      "loss: 0.047844  [    0/   28]\n",
      "loss: 0.047832  [    0/   28]\n",
      "loss: 0.047820  [    0/   28]\n",
      "loss: 0.047808  [    0/   28]\n",
      "loss: 0.047796  [    0/   28]\n",
      "loss: 0.047783  [    0/   28]\n",
      "loss: 0.047771  [    0/   28]\n",
      "loss: 0.047759  [    0/   28]\n",
      "loss: 0.047747  [    0/   28]\n",
      "loss: 0.047735  [    0/   28]\n",
      "loss: 0.047723  [    0/   28]\n",
      "loss: 0.047710  [    0/   28]\n",
      "loss: 0.047699  [    0/   28]\n",
      "loss: 0.047687  [    0/   28]\n",
      "loss: 0.047675  [    0/   28]\n",
      "loss: 0.047662  [    0/   28]\n",
      "loss: 0.047650  [    0/   28]\n",
      "loss: 0.047639  [    0/   28]\n",
      "loss: 0.047627  [    0/   28]\n",
      "loss: 0.047615  [    0/   28]\n",
      "loss: 0.047602  [    0/   28]\n",
      "loss: 0.047590  [    0/   28]\n",
      "loss: 0.047578  [    0/   28]\n",
      "loss: 0.047566  [    0/   28]\n",
      "loss: 0.047554  [    0/   28]\n",
      "loss: 0.047542  [    0/   28]\n",
      "loss: 0.047529  [    0/   28]\n",
      "loss: 0.047518  [    0/   28]\n",
      "loss: 0.047506  [    0/   28]\n",
      "loss: 0.047494  [    0/   28]\n",
      "loss: 0.047483  [    0/   28]\n",
      "loss: 0.047470  [    0/   28]\n",
      "loss: 0.047458  [    0/   28]\n",
      "loss: 0.047446  [    0/   28]\n",
      "loss: 0.047434  [    0/   28]\n",
      "loss: 0.047422  [    0/   28]\n",
      "loss: 0.047410  [    0/   28]\n",
      "loss: 0.047398  [    0/   28]\n",
      "loss: 0.047386  [    0/   28]\n",
      "loss: 0.047374  [    0/   28]\n",
      "loss: 0.047363  [    0/   28]\n",
      "loss: 0.047350  [    0/   28]\n",
      "loss: 0.047338  [    0/   28]\n",
      "loss: 0.047326  [    0/   28]\n",
      "loss: 0.047314  [    0/   28]\n",
      "loss: 0.047302  [    0/   28]\n",
      "loss: 0.047290  [    0/   28]\n",
      "loss: 0.047279  [    0/   28]\n",
      "loss: 0.047267  [    0/   28]\n",
      "loss: 0.047255  [    0/   28]\n",
      "loss: 0.047243  [    0/   28]\n",
      "loss: 0.047231  [    0/   28]\n",
      "loss: 0.047219  [    0/   28]\n",
      "loss: 0.047208  [    0/   28]\n",
      "loss: 0.047195  [    0/   28]\n",
      "loss: 0.047184  [    0/   28]\n",
      "loss: 0.047171  [    0/   28]\n",
      "loss: 0.047160  [    0/   28]\n",
      "loss: 0.047147  [    0/   28]\n",
      "loss: 0.047136  [    0/   28]\n",
      "loss: 0.047124  [    0/   28]\n",
      "loss: 0.047113  [    0/   28]\n",
      "loss: 0.047101  [    0/   28]\n",
      "loss: 0.047089  [    0/   28]\n",
      "loss: 0.047077  [    0/   28]\n",
      "loss: 0.047065  [    0/   28]\n",
      "loss: 0.047053  [    0/   28]\n",
      "loss: 0.047041  [    0/   28]\n",
      "loss: 0.047030  [    0/   28]\n",
      "loss: 0.047018  [    0/   28]\n",
      "loss: 0.047006  [    0/   28]\n",
      "loss: 0.046994  [    0/   28]\n",
      "loss: 0.046982  [    0/   28]\n",
      "loss: 0.046971  [    0/   28]\n",
      "loss: 0.046959  [    0/   28]\n",
      "loss: 0.046947  [    0/   28]\n",
      "loss: 0.046935  [    0/   28]\n",
      "loss: 0.046924  [    0/   28]\n",
      "loss: 0.046912  [    0/   28]\n",
      "loss: 0.046900  [    0/   28]\n",
      "loss: 0.046888  [    0/   28]\n",
      "loss: 0.046877  [    0/   28]\n",
      "loss: 0.046864  [    0/   28]\n",
      "loss: 0.046853  [    0/   28]\n",
      "loss: 0.046841  [    0/   28]\n",
      "loss: 0.046830  [    0/   28]\n",
      "loss: 0.046818  [    0/   28]\n",
      "loss: 0.046806  [    0/   28]\n",
      "loss: 0.046794  [    0/   28]\n",
      "loss: 0.046782  [    0/   28]\n",
      "loss: 0.046771  [    0/   28]\n",
      "loss: 0.046759  [    0/   28]\n",
      "loss: 0.046748  [    0/   28]\n",
      "loss: 0.046735  [    0/   28]\n",
      "loss: 0.046724  [    0/   28]\n",
      "loss: 0.046713  [    0/   28]\n",
      "loss: 0.046701  [    0/   28]\n",
      "loss: 0.046689  [    0/   28]\n",
      "loss: 0.046677  [    0/   28]\n",
      "loss: 0.046666  [    0/   28]\n",
      "loss: 0.046654  [    0/   28]\n",
      "loss: 0.046642  [    0/   28]\n",
      "loss: 0.046630  [    0/   28]\n",
      "loss: 0.046619  [    0/   28]\n",
      "loss: 0.046608  [    0/   28]\n",
      "loss: 0.046596  [    0/   28]\n",
      "loss: 0.046584  [    0/   28]\n",
      "loss: 0.046573  [    0/   28]\n",
      "loss: 0.046561  [    0/   28]\n",
      "loss: 0.046550  [    0/   28]\n",
      "loss: 0.046538  [    0/   28]\n",
      "loss: 0.046526  [    0/   28]\n",
      "loss: 0.046514  [    0/   28]\n",
      "loss: 0.046503  [    0/   28]\n",
      "loss: 0.046491  [    0/   28]\n",
      "loss: 0.046480  [    0/   28]\n",
      "loss: 0.046468  [    0/   28]\n",
      "loss: 0.046457  [    0/   28]\n",
      "loss: 0.046445  [    0/   28]\n",
      "loss: 0.046433  [    0/   28]\n",
      "loss: 0.046422  [    0/   28]\n",
      "loss: 0.046410  [    0/   28]\n",
      "loss: 0.046399  [    0/   28]\n",
      "loss: 0.046387  [    0/   28]\n",
      "loss: 0.046375  [    0/   28]\n",
      "loss: 0.046364  [    0/   28]\n",
      "loss: 0.046352  [    0/   28]\n",
      "loss: 0.046341  [    0/   28]\n",
      "loss: 0.046329  [    0/   28]\n",
      "loss: 0.046318  [    0/   28]\n",
      "loss: 0.046307  [    0/   28]\n",
      "loss: 0.046295  [    0/   28]\n",
      "loss: 0.046283  [    0/   28]\n",
      "loss: 0.046272  [    0/   28]\n",
      "loss: 0.046261  [    0/   28]\n",
      "loss: 0.046248  [    0/   28]\n",
      "loss: 0.046237  [    0/   28]\n",
      "loss: 0.046226  [    0/   28]\n",
      "loss: 0.046214  [    0/   28]\n",
      "loss: 0.046203  [    0/   28]\n",
      "loss: 0.046191  [    0/   28]\n",
      "loss: 0.046180  [    0/   28]\n",
      "loss: 0.046169  [    0/   28]\n",
      "loss: 0.046157  [    0/   28]\n",
      "loss: 0.046146  [    0/   28]\n",
      "loss: 0.046134  [    0/   28]\n",
      "loss: 0.046123  [    0/   28]\n",
      "loss: 0.046111  [    0/   28]\n",
      "loss: 0.046100  [    0/   28]\n",
      "loss: 0.046089  [    0/   28]\n",
      "loss: 0.046077  [    0/   28]\n",
      "loss: 0.046065  [    0/   28]\n",
      "loss: 0.046054  [    0/   28]\n",
      "loss: 0.046043  [    0/   28]\n",
      "loss: 0.046032  [    0/   28]\n",
      "loss: 0.046019  [    0/   28]\n",
      "loss: 0.046008  [    0/   28]\n",
      "loss: 0.045997  [    0/   28]\n",
      "loss: 0.045986  [    0/   28]\n",
      "loss: 0.045975  [    0/   28]\n",
      "loss: 0.045963  [    0/   28]\n",
      "loss: 0.045951  [    0/   28]\n",
      "loss: 0.045940  [    0/   28]\n",
      "loss: 0.045929  [    0/   28]\n",
      "loss: 0.045918  [    0/   28]\n",
      "loss: 0.045906  [    0/   28]\n",
      "loss: 0.045894  [    0/   28]\n",
      "loss: 0.045884  [    0/   28]\n",
      "loss: 0.045872  [    0/   28]\n",
      "loss: 0.045861  [    0/   28]\n",
      "loss: 0.045850  [    0/   28]\n",
      "loss: 0.045838  [    0/   28]\n",
      "loss: 0.045826  [    0/   28]\n",
      "loss: 0.045815  [    0/   28]\n",
      "loss: 0.045804  [    0/   28]\n",
      "loss: 0.045793  [    0/   28]\n",
      "loss: 0.045781  [    0/   28]\n",
      "loss: 0.045770  [    0/   28]\n",
      "loss: 0.045759  [    0/   28]\n",
      "loss: 0.045747  [    0/   28]\n",
      "loss: 0.045737  [    0/   28]\n",
      "loss: 0.045725  [    0/   28]\n",
      "loss: 0.045714  [    0/   28]\n",
      "loss: 0.045702  [    0/   28]\n",
      "loss: 0.045691  [    0/   28]\n",
      "loss: 0.045679  [    0/   28]\n",
      "loss: 0.045669  [    0/   28]\n",
      "loss: 0.045658  [    0/   28]\n",
      "loss: 0.045646  [    0/   28]\n",
      "loss: 0.045635  [    0/   28]\n",
      "loss: 0.045624  [    0/   28]\n",
      "loss: 0.045613  [    0/   28]\n",
      "loss: 0.045601  [    0/   28]\n",
      "loss: 0.045590  [    0/   28]\n",
      "loss: 0.045579  [    0/   28]\n",
      "loss: 0.045568  [    0/   28]\n",
      "loss: 0.045557  [    0/   28]\n",
      "loss: 0.045545  [    0/   28]\n",
      "loss: 0.045534  [    0/   28]\n",
      "loss: 0.045523  [    0/   28]\n",
      "loss: 0.045512  [    0/   28]\n",
      "loss: 0.045501  [    0/   28]\n",
      "loss: 0.045489  [    0/   28]\n",
      "loss: 0.045478  [    0/   28]\n",
      "loss: 0.045467  [    0/   28]\n",
      "loss: 0.045456  [    0/   28]\n",
      "loss: 0.045445  [    0/   28]\n",
      "loss: 0.045434  [    0/   28]\n",
      "loss: 0.045422  [    0/   28]\n",
      "loss: 0.045411  [    0/   28]\n",
      "loss: 0.045400  [    0/   28]\n",
      "loss: 0.045389  [    0/   28]\n",
      "loss: 0.045378  [    0/   28]\n",
      "loss: 0.045367  [    0/   28]\n",
      "loss: 0.045355  [    0/   28]\n",
      "loss: 0.045345  [    0/   28]\n",
      "loss: 0.045334  [    0/   28]\n",
      "loss: 0.045323  [    0/   28]\n",
      "loss: 0.045311  [    0/   28]\n",
      "loss: 0.045300  [    0/   28]\n",
      "loss: 0.045288  [    0/   28]\n",
      "loss: 0.045278  [    0/   28]\n",
      "loss: 0.045267  [    0/   28]\n",
      "loss: 0.045256  [    0/   28]\n",
      "loss: 0.045245  [    0/   28]\n",
      "loss: 0.045233  [    0/   28]\n",
      "loss: 0.045223  [    0/   28]\n",
      "loss: 0.045211  [    0/   28]\n",
      "loss: 0.045200  [    0/   28]\n",
      "loss: 0.045190  [    0/   28]\n",
      "loss: 0.045178  [    0/   28]\n",
      "loss: 0.045167  [    0/   28]\n",
      "loss: 0.045157  [    0/   28]\n",
      "loss: 0.045145  [    0/   28]\n",
      "loss: 0.045134  [    0/   28]\n",
      "loss: 0.045123  [    0/   28]\n",
      "loss: 0.045112  [    0/   28]\n",
      "loss: 0.045101  [    0/   28]\n",
      "loss: 0.045090  [    0/   28]\n",
      "loss: 0.045079  [    0/   28]\n",
      "loss: 0.045068  [    0/   28]\n",
      "loss: 0.045057  [    0/   28]\n",
      "loss: 0.045046  [    0/   28]\n",
      "loss: 0.045035  [    0/   28]\n",
      "loss: 0.045024  [    0/   28]\n",
      "loss: 0.045013  [    0/   28]\n",
      "loss: 0.045002  [    0/   28]\n",
      "loss: 0.044992  [    0/   28]\n",
      "loss: 0.044981  [    0/   28]\n",
      "loss: 0.044969  [    0/   28]\n",
      "loss: 0.044959  [    0/   28]\n",
      "loss: 0.044948  [    0/   28]\n",
      "loss: 0.044937  [    0/   28]\n",
      "loss: 0.044925  [    0/   28]\n",
      "loss: 0.044914  [    0/   28]\n",
      "loss: 0.044903  [    0/   28]\n",
      "loss: 0.044893  [    0/   28]\n",
      "loss: 0.044882  [    0/   28]\n",
      "loss: 0.044871  [    0/   28]\n",
      "loss: 0.044860  [    0/   28]\n",
      "loss: 0.044849  [    0/   28]\n",
      "loss: 0.044838  [    0/   28]\n",
      "loss: 0.044828  [    0/   28]\n",
      "loss: 0.044816  [    0/   28]\n",
      "loss: 0.044806  [    0/   28]\n",
      "loss: 0.044794  [    0/   28]\n",
      "loss: 0.044784  [    0/   28]\n",
      "loss: 0.044773  [    0/   28]\n",
      "loss: 0.044762  [    0/   28]\n",
      "loss: 0.044751  [    0/   28]\n",
      "loss: 0.044740  [    0/   28]\n",
      "loss: 0.044730  [    0/   28]\n",
      "loss: 0.044719  [    0/   28]\n",
      "loss: 0.044708  [    0/   28]\n",
      "loss: 0.044697  [    0/   28]\n",
      "loss: 0.044686  [    0/   28]\n",
      "loss: 0.044675  [    0/   28]\n",
      "loss: 0.044664  [    0/   28]\n",
      "loss: 0.044653  [    0/   28]\n",
      "loss: 0.044643  [    0/   28]\n",
      "loss: 0.044632  [    0/   28]\n",
      "loss: 0.044621  [    0/   28]\n",
      "loss: 0.044610  [    0/   28]\n",
      "loss: 0.044599  [    0/   28]\n",
      "loss: 0.044589  [    0/   28]\n",
      "loss: 0.044578  [    0/   28]\n",
      "loss: 0.044567  [    0/   28]\n",
      "loss: 0.044557  [    0/   28]\n",
      "loss: 0.044546  [    0/   28]\n",
      "loss: 0.044534  [    0/   28]\n",
      "loss: 0.044524  [    0/   28]\n",
      "loss: 0.044514  [    0/   28]\n",
      "loss: 0.044502  [    0/   28]\n",
      "loss: 0.044492  [    0/   28]\n",
      "loss: 0.044481  [    0/   28]\n",
      "loss: 0.044470  [    0/   28]\n",
      "loss: 0.044460  [    0/   28]\n",
      "loss: 0.044449  [    0/   28]\n",
      "loss: 0.044438  [    0/   28]\n",
      "loss: 0.044428  [    0/   28]\n",
      "loss: 0.044416  [    0/   28]\n",
      "loss: 0.044405  [    0/   28]\n",
      "loss: 0.044395  [    0/   28]\n",
      "loss: 0.044384  [    0/   28]\n",
      "loss: 0.044374  [    0/   28]\n",
      "loss: 0.044363  [    0/   28]\n",
      "loss: 0.044352  [    0/   28]\n",
      "loss: 0.044342  [    0/   28]\n",
      "loss: 0.044331  [    0/   28]\n",
      "loss: 0.044320  [    0/   28]\n",
      "loss: 0.044309  [    0/   28]\n",
      "loss: 0.044298  [    0/   28]\n",
      "loss: 0.044288  [    0/   28]\n",
      "loss: 0.044277  [    0/   28]\n",
      "loss: 0.044267  [    0/   28]\n",
      "loss: 0.044256  [    0/   28]\n",
      "loss: 0.044245  [    0/   28]\n",
      "loss: 0.044235  [    0/   28]\n",
      "loss: 0.044224  [    0/   28]\n",
      "loss: 0.044213  [    0/   28]\n",
      "loss: 0.044203  [    0/   28]\n",
      "loss: 0.044192  [    0/   28]\n",
      "loss: 0.044182  [    0/   28]\n",
      "loss: 0.044170  [    0/   28]\n",
      "loss: 0.044160  [    0/   28]\n",
      "loss: 0.044150  [    0/   28]\n",
      "loss: 0.044139  [    0/   28]\n",
      "loss: 0.044128  [    0/   28]\n",
      "loss: 0.044117  [    0/   28]\n",
      "loss: 0.044107  [    0/   28]\n",
      "loss: 0.044097  [    0/   28]\n",
      "loss: 0.044086  [    0/   28]\n",
      "loss: 0.044075  [    0/   28]\n",
      "loss: 0.044064  [    0/   28]\n",
      "loss: 0.044054  [    0/   28]\n",
      "loss: 0.044044  [    0/   28]\n",
      "loss: 0.044033  [    0/   28]\n",
      "loss: 0.044023  [    0/   28]\n",
      "loss: 0.044012  [    0/   28]\n",
      "loss: 0.044001  [    0/   28]\n",
      "loss: 0.043991  [    0/   28]\n",
      "loss: 0.043980  [    0/   28]\n",
      "loss: 0.043970  [    0/   28]\n",
      "loss: 0.043959  [    0/   28]\n",
      "loss: 0.043948  [    0/   28]\n",
      "loss: 0.043938  [    0/   28]\n",
      "loss: 0.043927  [    0/   28]\n",
      "loss: 0.043917  [    0/   28]\n",
      "loss: 0.043906  [    0/   28]\n",
      "loss: 0.043896  [    0/   28]\n",
      "loss: 0.043885  [    0/   28]\n",
      "loss: 0.043875  [    0/   28]\n",
      "loss: 0.043864  [    0/   28]\n",
      "loss: 0.043854  [    0/   28]\n",
      "loss: 0.043843  [    0/   28]\n",
      "loss: 0.043833  [    0/   28]\n",
      "loss: 0.043822  [    0/   28]\n",
      "loss: 0.043812  [    0/   28]\n",
      "loss: 0.043802  [    0/   28]\n",
      "loss: 0.043791  [    0/   28]\n",
      "loss: 0.043780  [    0/   28]\n",
      "loss: 0.043770  [    0/   28]\n",
      "loss: 0.043759  [    0/   28]\n",
      "loss: 0.043749  [    0/   28]\n",
      "loss: 0.043739  [    0/   28]\n",
      "loss: 0.043728  [    0/   28]\n",
      "loss: 0.043717  [    0/   28]\n",
      "loss: 0.043707  [    0/   28]\n",
      "loss: 0.043696  [    0/   28]\n",
      "loss: 0.043686  [    0/   28]\n",
      "loss: 0.043676  [    0/   28]\n",
      "loss: 0.043665  [    0/   28]\n",
      "loss: 0.043655  [    0/   28]\n",
      "loss: 0.043645  [    0/   28]\n",
      "loss: 0.043634  [    0/   28]\n",
      "loss: 0.043624  [    0/   28]\n",
      "loss: 0.043613  [    0/   28]\n",
      "loss: 0.043603  [    0/   28]\n",
      "loss: 0.043592  [    0/   28]\n",
      "loss: 0.043582  [    0/   28]\n",
      "loss: 0.043571  [    0/   28]\n",
      "loss: 0.043561  [    0/   28]\n",
      "loss: 0.043550  [    0/   28]\n",
      "loss: 0.043540  [    0/   28]\n",
      "loss: 0.043530  [    0/   28]\n",
      "loss: 0.043520  [    0/   28]\n",
      "loss: 0.043509  [    0/   28]\n",
      "loss: 0.043499  [    0/   28]\n",
      "loss: 0.043489  [    0/   28]\n",
      "loss: 0.043478  [    0/   28]\n",
      "loss: 0.043468  [    0/   28]\n",
      "loss: 0.043457  [    0/   28]\n",
      "loss: 0.043447  [    0/   28]\n",
      "loss: 0.043436  [    0/   28]\n",
      "loss: 0.043426  [    0/   28]\n",
      "loss: 0.043417  [    0/   28]\n",
      "loss: 0.043406  [    0/   28]\n",
      "loss: 0.043395  [    0/   28]\n",
      "loss: 0.043385  [    0/   28]\n",
      "loss: 0.043375  [    0/   28]\n",
      "loss: 0.043364  [    0/   28]\n",
      "loss: 0.043354  [    0/   28]\n",
      "loss: 0.043344  [    0/   28]\n",
      "loss: 0.043334  [    0/   28]\n",
      "loss: 0.043323  [    0/   28]\n",
      "loss: 0.043313  [    0/   28]\n",
      "loss: 0.043302  [    0/   28]\n",
      "loss: 0.043293  [    0/   28]\n",
      "loss: 0.043282  [    0/   28]\n",
      "loss: 0.043271  [    0/   28]\n",
      "loss: 0.043261  [    0/   28]\n",
      "loss: 0.043251  [    0/   28]\n",
      "loss: 0.043241  [    0/   28]\n",
      "loss: 0.043231  [    0/   28]\n",
      "loss: 0.043220  [    0/   28]\n",
      "loss: 0.043210  [    0/   28]\n",
      "loss: 0.043200  [    0/   28]\n",
      "loss: 0.043189  [    0/   28]\n",
      "loss: 0.043179  [    0/   28]\n",
      "loss: 0.043169  [    0/   28]\n",
      "loss: 0.043159  [    0/   28]\n",
      "loss: 0.043149  [    0/   28]\n",
      "loss: 0.043139  [    0/   28]\n",
      "loss: 0.043128  [    0/   28]\n",
      "loss: 0.043118  [    0/   28]\n",
      "loss: 0.043108  [    0/   28]\n",
      "loss: 0.043097  [    0/   28]\n",
      "loss: 0.043087  [    0/   28]\n",
      "loss: 0.043077  [    0/   28]\n",
      "loss: 0.043067  [    0/   28]\n",
      "loss: 0.043057  [    0/   28]\n",
      "loss: 0.043047  [    0/   28]\n",
      "loss: 0.043036  [    0/   28]\n",
      "loss: 0.043026  [    0/   28]\n",
      "loss: 0.043016  [    0/   28]\n",
      "loss: 0.043006  [    0/   28]\n",
      "loss: 0.042996  [    0/   28]\n",
      "loss: 0.042985  [    0/   28]\n",
      "loss: 0.042976  [    0/   28]\n",
      "loss: 0.042965  [    0/   28]\n",
      "loss: 0.042955  [    0/   28]\n",
      "loss: 0.042945  [    0/   28]\n",
      "loss: 0.042935  [    0/   28]\n",
      "loss: 0.042925  [    0/   28]\n",
      "loss: 0.042915  [    0/   28]\n",
      "loss: 0.042905  [    0/   28]\n",
      "loss: 0.042894  [    0/   28]\n",
      "loss: 0.042884  [    0/   28]\n",
      "loss: 0.042874  [    0/   28]\n",
      "loss: 0.042864  [    0/   28]\n",
      "loss: 0.042854  [    0/   28]\n",
      "loss: 0.042844  [    0/   28]\n",
      "loss: 0.042834  [    0/   28]\n",
      "loss: 0.042824  [    0/   28]\n",
      "loss: 0.042813  [    0/   28]\n",
      "loss: 0.042803  [    0/   28]\n",
      "loss: 0.042794  [    0/   28]\n",
      "loss: 0.042783  [    0/   28]\n",
      "loss: 0.042773  [    0/   28]\n",
      "loss: 0.042763  [    0/   28]\n",
      "loss: 0.042753  [    0/   28]\n",
      "loss: 0.042743  [    0/   28]\n",
      "loss: 0.042733  [    0/   28]\n",
      "loss: 0.042723  [    0/   28]\n",
      "loss: 0.042713  [    0/   28]\n",
      "loss: 0.042703  [    0/   28]\n",
      "loss: 0.042693  [    0/   28]\n",
      "loss: 0.042683  [    0/   28]\n",
      "loss: 0.042673  [    0/   28]\n",
      "loss: 0.042663  [    0/   28]\n",
      "loss: 0.042653  [    0/   28]\n",
      "loss: 0.042643  [    0/   28]\n",
      "loss: 0.042633  [    0/   28]\n",
      "loss: 0.042623  [    0/   28]\n",
      "loss: 0.042613  [    0/   28]\n",
      "loss: 0.042603  [    0/   28]\n",
      "loss: 0.042593  [    0/   28]\n",
      "loss: 0.042582  [    0/   28]\n",
      "loss: 0.042573  [    0/   28]\n",
      "loss: 0.042563  [    0/   28]\n",
      "loss: 0.042553  [    0/   28]\n",
      "loss: 0.042543  [    0/   28]\n",
      "loss: 0.042532  [    0/   28]\n",
      "loss: 0.042523  [    0/   28]\n",
      "loss: 0.042513  [    0/   28]\n",
      "loss: 0.042503  [    0/   28]\n",
      "loss: 0.042493  [    0/   28]\n",
      "loss: 0.042483  [    0/   28]\n",
      "loss: 0.042473  [    0/   28]\n",
      "loss: 0.042463  [    0/   28]\n",
      "loss: 0.042453  [    0/   28]\n",
      "loss: 0.042443  [    0/   28]\n",
      "loss: 0.042433  [    0/   28]\n",
      "loss: 0.042423  [    0/   28]\n",
      "loss: 0.042413  [    0/   28]\n",
      "loss: 0.042403  [    0/   28]\n",
      "loss: 0.042394  [    0/   28]\n",
      "loss: 0.042383  [    0/   28]\n",
      "loss: 0.042373  [    0/   28]\n",
      "loss: 0.042363  [    0/   28]\n",
      "loss: 0.042354  [    0/   28]\n",
      "loss: 0.042344  [    0/   28]\n",
      "loss: 0.042334  [    0/   28]\n",
      "loss: 0.042324  [    0/   28]\n",
      "loss: 0.042314  [    0/   28]\n",
      "loss: 0.042304  [    0/   28]\n",
      "loss: 0.042295  [    0/   28]\n",
      "loss: 0.042285  [    0/   28]\n",
      "loss: 0.042275  [    0/   28]\n",
      "loss: 0.042265  [    0/   28]\n",
      "loss: 0.042255  [    0/   28]\n",
      "loss: 0.042245  [    0/   28]\n",
      "loss: 0.042235  [    0/   28]\n",
      "loss: 0.042225  [    0/   28]\n",
      "loss: 0.042216  [    0/   28]\n",
      "loss: 0.042206  [    0/   28]\n",
      "loss: 0.042196  [    0/   28]\n",
      "loss: 0.042186  [    0/   28]\n",
      "loss: 0.042176  [    0/   28]\n",
      "loss: 0.042166  [    0/   28]\n",
      "loss: 0.042157  [    0/   28]\n",
      "loss: 0.042147  [    0/   28]\n",
      "loss: 0.042136  [    0/   28]\n",
      "loss: 0.042127  [    0/   28]\n",
      "loss: 0.042117  [    0/   28]\n",
      "loss: 0.042107  [    0/   28]\n",
      "loss: 0.042097  [    0/   28]\n",
      "loss: 0.042088  [    0/   28]\n",
      "loss: 0.042078  [    0/   28]\n",
      "loss: 0.042068  [    0/   28]\n",
      "loss: 0.042058  [    0/   28]\n",
      "loss: 0.042049  [    0/   28]\n",
      "loss: 0.042039  [    0/   28]\n",
      "loss: 0.042028  [    0/   28]\n",
      "loss: 0.042019  [    0/   28]\n",
      "loss: 0.042009  [    0/   28]\n",
      "loss: 0.042000  [    0/   28]\n",
      "loss: 0.041990  [    0/   28]\n",
      "loss: 0.041980  [    0/   28]\n",
      "loss: 0.041970  [    0/   28]\n",
      "loss: 0.041961  [    0/   28]\n",
      "loss: 0.041951  [    0/   28]\n",
      "loss: 0.041941  [    0/   28]\n",
      "loss: 0.041931  [    0/   28]\n",
      "loss: 0.041921  [    0/   28]\n",
      "loss: 0.041912  [    0/   28]\n",
      "loss: 0.041902  [    0/   28]\n",
      "loss: 0.041893  [    0/   28]\n",
      "loss: 0.041882  [    0/   28]\n",
      "loss: 0.041872  [    0/   28]\n",
      "loss: 0.041863  [    0/   28]\n",
      "loss: 0.041854  [    0/   28]\n",
      "loss: 0.041844  [    0/   28]\n",
      "loss: 0.041834  [    0/   28]\n",
      "loss: 0.041824  [    0/   28]\n",
      "loss: 0.041815  [    0/   28]\n",
      "loss: 0.041805  [    0/   28]\n",
      "loss: 0.041796  [    0/   28]\n",
      "loss: 0.041786  [    0/   28]\n",
      "loss: 0.041775  [    0/   28]\n",
      "loss: 0.041766  [    0/   28]\n",
      "loss: 0.041756  [    0/   28]\n",
      "loss: 0.041747  [    0/   28]\n",
      "loss: 0.041737  [    0/   28]\n",
      "loss: 0.041727  [    0/   28]\n",
      "loss: 0.041718  [    0/   28]\n",
      "loss: 0.041708  [    0/   28]\n",
      "loss: 0.041698  [    0/   28]\n",
      "loss: 0.041689  [    0/   28]\n",
      "loss: 0.041679  [    0/   28]\n",
      "loss: 0.041670  [    0/   28]\n",
      "loss: 0.041660  [    0/   28]\n",
      "loss: 0.041650  [    0/   28]\n",
      "loss: 0.041641  [    0/   28]\n",
      "loss: 0.041631  [    0/   28]\n",
      "loss: 0.041621  [    0/   28]\n",
      "loss: 0.041612  [    0/   28]\n",
      "loss: 0.041602  [    0/   28]\n",
      "loss: 0.041593  [    0/   28]\n",
      "loss: 0.041583  [    0/   28]\n",
      "loss: 0.041573  [    0/   28]\n",
      "loss: 0.041563  [    0/   28]\n",
      "loss: 0.041554  [    0/   28]\n",
      "loss: 0.041544  [    0/   28]\n",
      "loss: 0.041535  [    0/   28]\n",
      "loss: 0.041525  [    0/   28]\n",
      "loss: 0.041515  [    0/   28]\n",
      "loss: 0.041505  [    0/   28]\n",
      "loss: 0.041496  [    0/   28]\n",
      "loss: 0.041487  [    0/   28]\n",
      "loss: 0.041477  [    0/   28]\n",
      "loss: 0.041468  [    0/   28]\n",
      "loss: 0.041458  [    0/   28]\n",
      "loss: 0.041449  [    0/   28]\n",
      "loss: 0.041439  [    0/   28]\n",
      "loss: 0.041429  [    0/   28]\n",
      "loss: 0.041420  [    0/   28]\n",
      "loss: 0.041411  [    0/   28]\n",
      "loss: 0.041400  [    0/   28]\n",
      "loss: 0.041391  [    0/   28]\n",
      "loss: 0.041381  [    0/   28]\n",
      "loss: 0.041372  [    0/   28]\n",
      "loss: 0.041362  [    0/   28]\n",
      "loss: 0.041353  [    0/   28]\n",
      "loss: 0.041343  [    0/   28]\n",
      "loss: 0.041334  [    0/   28]\n",
      "loss: 0.041324  [    0/   28]\n",
      "loss: 0.041315  [    0/   28]\n",
      "loss: 0.041305  [    0/   28]\n",
      "loss: 0.041296  [    0/   28]\n",
      "loss: 0.041286  [    0/   28]\n",
      "loss: 0.041277  [    0/   28]\n",
      "loss: 0.041267  [    0/   28]\n",
      "loss: 0.041258  [    0/   28]\n",
      "loss: 0.041248  [    0/   28]\n",
      "loss: 0.041239  [    0/   28]\n",
      "loss: 0.041229  [    0/   28]\n",
      "loss: 0.041220  [    0/   28]\n",
      "loss: 0.041210  [    0/   28]\n",
      "loss: 0.041201  [    0/   28]\n",
      "loss: 0.041191  [    0/   28]\n",
      "loss: 0.041182  [    0/   28]\n",
      "loss: 0.041172  [    0/   28]\n",
      "loss: 0.041163  [    0/   28]\n",
      "loss: 0.041154  [    0/   28]\n",
      "loss: 0.041144  [    0/   28]\n",
      "loss: 0.041135  [    0/   28]\n",
      "loss: 0.041125  [    0/   28]\n",
      "loss: 0.041116  [    0/   28]\n",
      "loss: 0.041106  [    0/   28]\n",
      "loss: 0.041097  [    0/   28]\n",
      "loss: 0.041087  [    0/   28]\n",
      "loss: 0.041078  [    0/   28]\n",
      "loss: 0.041068  [    0/   28]\n",
      "loss: 0.041059  [    0/   28]\n",
      "loss: 0.041050  [    0/   28]\n",
      "loss: 0.041040  [    0/   28]\n",
      "loss: 0.041031  [    0/   28]\n",
      "loss: 0.041022  [    0/   28]\n",
      "loss: 0.041013  [    0/   28]\n",
      "loss: 0.041003  [    0/   28]\n",
      "loss: 0.040994  [    0/   28]\n",
      "loss: 0.040984  [    0/   28]\n",
      "loss: 0.040975  [    0/   28]\n",
      "loss: 0.040965  [    0/   28]\n",
      "loss: 0.040956  [    0/   28]\n",
      "loss: 0.040947  [    0/   28]\n",
      "loss: 0.040937  [    0/   28]\n",
      "loss: 0.040928  [    0/   28]\n",
      "loss: 0.040919  [    0/   28]\n",
      "loss: 0.040910  [    0/   28]\n",
      "loss: 0.040900  [    0/   28]\n",
      "loss: 0.040890  [    0/   28]\n",
      "loss: 0.040881  [    0/   28]\n",
      "loss: 0.040872  [    0/   28]\n",
      "loss: 0.040863  [    0/   28]\n",
      "loss: 0.040854  [    0/   28]\n",
      "loss: 0.040844  [    0/   28]\n",
      "loss: 0.040835  [    0/   28]\n",
      "loss: 0.040826  [    0/   28]\n",
      "loss: 0.040816  [    0/   28]\n",
      "loss: 0.040807  [    0/   28]\n",
      "loss: 0.040797  [    0/   28]\n",
      "loss: 0.040788  [    0/   28]\n",
      "loss: 0.040779  [    0/   28]\n",
      "loss: 0.040770  [    0/   28]\n",
      "loss: 0.040760  [    0/   28]\n",
      "loss: 0.040751  [    0/   28]\n",
      "loss: 0.040741  [    0/   28]\n",
      "loss: 0.040732  [    0/   28]\n",
      "loss: 0.040723  [    0/   28]\n",
      "loss: 0.040714  [    0/   28]\n",
      "loss: 0.040704  [    0/   28]\n",
      "loss: 0.040695  [    0/   28]\n",
      "loss: 0.040686  [    0/   28]\n",
      "loss: 0.040676  [    0/   28]\n",
      "loss: 0.040668  [    0/   28]\n",
      "loss: 0.040658  [    0/   28]\n",
      "loss: 0.040649  [    0/   28]\n",
      "loss: 0.040639  [    0/   28]\n",
      "loss: 0.040630  [    0/   28]\n",
      "loss: 0.040621  [    0/   28]\n",
      "loss: 0.040611  [    0/   28]\n",
      "loss: 0.040602  [    0/   28]\n",
      "loss: 0.040594  [    0/   28]\n",
      "loss: 0.040584  [    0/   28]\n",
      "loss: 0.040575  [    0/   28]\n",
      "loss: 0.040566  [    0/   28]\n",
      "loss: 0.040556  [    0/   28]\n",
      "loss: 0.040548  [    0/   28]\n",
      "loss: 0.040538  [    0/   28]\n",
      "loss: 0.040529  [    0/   28]\n",
      "loss: 0.040520  [    0/   28]\n",
      "loss: 0.040511  [    0/   28]\n",
      "loss: 0.040501  [    0/   28]\n",
      "loss: 0.040492  [    0/   28]\n",
      "loss: 0.040483  [    0/   28]\n",
      "loss: 0.040474  [    0/   28]\n",
      "loss: 0.040464  [    0/   28]\n",
      "loss: 0.040456  [    0/   28]\n",
      "loss: 0.040447  [    0/   28]\n",
      "loss: 0.040437  [    0/   28]\n",
      "loss: 0.040428  [    0/   28]\n",
      "loss: 0.040419  [    0/   28]\n",
      "loss: 0.040409  [    0/   28]\n",
      "loss: 0.040401  [    0/   28]\n",
      "loss: 0.040391  [    0/   28]\n",
      "loss: 0.040382  [    0/   28]\n",
      "loss: 0.040373  [    0/   28]\n",
      "loss: 0.040364  [    0/   28]\n",
      "loss: 0.040355  [    0/   28]\n",
      "loss: 0.040345  [    0/   28]\n",
      "loss: 0.040336  [    0/   28]\n",
      "loss: 0.040327  [    0/   28]\n",
      "loss: 0.040318  [    0/   28]\n",
      "loss: 0.040309  [    0/   28]\n",
      "loss: 0.040300  [    0/   28]\n",
      "loss: 0.040291  [    0/   28]\n",
      "loss: 0.040282  [    0/   28]\n",
      "loss: 0.040272  [    0/   28]\n",
      "loss: 0.040263  [    0/   28]\n",
      "loss: 0.040255  [    0/   28]\n",
      "loss: 0.040245  [    0/   28]\n",
      "loss: 0.040236  [    0/   28]\n",
      "loss: 0.040227  [    0/   28]\n",
      "loss: 0.040218  [    0/   28]\n",
      "loss: 0.040209  [    0/   28]\n",
      "loss: 0.040200  [    0/   28]\n",
      "loss: 0.040191  [    0/   28]\n",
      "loss: 0.040182  [    0/   28]\n",
      "loss: 0.040172  [    0/   28]\n",
      "loss: 0.040163  [    0/   28]\n",
      "loss: 0.040154  [    0/   28]\n",
      "loss: 0.040145  [    0/   28]\n",
      "loss: 0.040136  [    0/   28]\n",
      "loss: 0.040127  [    0/   28]\n",
      "loss: 0.040118  [    0/   28]\n",
      "loss: 0.040109  [    0/   28]\n",
      "loss: 0.040100  [    0/   28]\n",
      "loss: 0.040091  [    0/   28]\n",
      "loss: 0.040082  [    0/   28]\n",
      "loss: 0.040073  [    0/   28]\n",
      "loss: 0.040064  [    0/   28]\n",
      "loss: 0.040055  [    0/   28]\n",
      "loss: 0.040046  [    0/   28]\n",
      "loss: 0.040037  [    0/   28]\n",
      "loss: 0.040028  [    0/   28]\n",
      "loss: 0.040019  [    0/   28]\n",
      "loss: 0.040010  [    0/   28]\n",
      "loss: 0.040001  [    0/   28]\n",
      "loss: 0.039992  [    0/   28]\n",
      "loss: 0.039983  [    0/   28]\n",
      "loss: 0.039974  [    0/   28]\n",
      "loss: 0.039965  [    0/   28]\n",
      "loss: 0.039956  [    0/   28]\n",
      "loss: 0.039947  [    0/   28]\n",
      "loss: 0.039937  [    0/   28]\n",
      "loss: 0.039929  [    0/   28]\n",
      "loss: 0.039920  [    0/   28]\n",
      "loss: 0.039911  [    0/   28]\n",
      "loss: 0.039902  [    0/   28]\n",
      "loss: 0.039893  [    0/   28]\n",
      "loss: 0.039884  [    0/   28]\n",
      "loss: 0.039875  [    0/   28]\n",
      "loss: 0.039866  [    0/   28]\n",
      "loss: 0.039857  [    0/   28]\n",
      "loss: 0.039848  [    0/   28]\n",
      "loss: 0.039839  [    0/   28]\n",
      "loss: 0.039830  [    0/   28]\n",
      "loss: 0.039821  [    0/   28]\n",
      "loss: 0.039812  [    0/   28]\n",
      "loss: 0.039803  [    0/   28]\n",
      "loss: 0.039794  [    0/   28]\n",
      "loss: 0.039785  [    0/   28]\n",
      "loss: 0.039777  [    0/   28]\n",
      "loss: 0.039767  [    0/   28]\n",
      "loss: 0.039759  [    0/   28]\n",
      "loss: 0.039750  [    0/   28]\n",
      "loss: 0.039741  [    0/   28]\n",
      "loss: 0.039732  [    0/   28]\n",
      "loss: 0.039723  [    0/   28]\n",
      "loss: 0.039714  [    0/   28]\n",
      "loss: 0.039705  [    0/   28]\n",
      "loss: 0.039696  [    0/   28]\n",
      "loss: 0.039687  [    0/   28]\n",
      "loss: 0.039678  [    0/   28]\n",
      "loss: 0.039669  [    0/   28]\n",
      "loss: 0.039661  [    0/   28]\n",
      "loss: 0.039652  [    0/   28]\n",
      "loss: 0.039643  [    0/   28]\n",
      "loss: 0.039634  [    0/   28]\n",
      "loss: 0.039625  [    0/   28]\n",
      "loss: 0.039616  [    0/   28]\n",
      "loss: 0.039607  [    0/   28]\n",
      "loss: 0.039599  [    0/   28]\n",
      "loss: 0.039589  [    0/   28]\n",
      "loss: 0.039581  [    0/   28]\n",
      "loss: 0.039572  [    0/   28]\n",
      "loss: 0.039563  [    0/   28]\n",
      "loss: 0.039554  [    0/   28]\n",
      "loss: 0.039545  [    0/   28]\n",
      "loss: 0.039537  [    0/   28]\n",
      "loss: 0.039528  [    0/   28]\n",
      "loss: 0.039519  [    0/   28]\n",
      "loss: 0.039510  [    0/   28]\n",
      "loss: 0.039501  [    0/   28]\n",
      "loss: 0.039492  [    0/   28]\n",
      "loss: 0.039483  [    0/   28]\n",
      "loss: 0.039474  [    0/   28]\n",
      "loss: 0.039466  [    0/   28]\n",
      "loss: 0.039457  [    0/   28]\n",
      "loss: 0.039448  [    0/   28]\n",
      "loss: 0.039439  [    0/   28]\n",
      "loss: 0.039430  [    0/   28]\n",
      "loss: 0.039422  [    0/   28]\n",
      "loss: 0.039413  [    0/   28]\n",
      "loss: 0.039404  [    0/   28]\n",
      "loss: 0.039395  [    0/   28]\n",
      "loss: 0.039386  [    0/   28]\n",
      "loss: 0.039378  [    0/   28]\n",
      "loss: 0.039369  [    0/   28]\n",
      "loss: 0.039361  [    0/   28]\n",
      "loss: 0.039351  [    0/   28]\n",
      "loss: 0.039343  [    0/   28]\n",
      "loss: 0.039334  [    0/   28]\n",
      "loss: 0.039325  [    0/   28]\n",
      "loss: 0.039316  [    0/   28]\n",
      "loss: 0.039307  [    0/   28]\n",
      "loss: 0.039299  [    0/   28]\n",
      "loss: 0.039290  [    0/   28]\n",
      "loss: 0.039282  [    0/   28]\n",
      "loss: 0.039272  [    0/   28]\n",
      "loss: 0.039264  [    0/   28]\n",
      "loss: 0.039255  [    0/   28]\n",
      "loss: 0.039247  [    0/   28]\n",
      "loss: 0.039237  [    0/   28]\n",
      "loss: 0.039229  [    0/   28]\n",
      "loss: 0.039220  [    0/   28]\n",
      "loss: 0.039212  [    0/   28]\n",
      "loss: 0.039203  [    0/   28]\n",
      "loss: 0.039194  [    0/   28]\n",
      "loss: 0.039185  [    0/   28]\n",
      "loss: 0.039176  [    0/   28]\n",
      "loss: 0.039168  [    0/   28]\n",
      "loss: 0.039159  [    0/   28]\n",
      "loss: 0.039151  [    0/   28]\n",
      "loss: 0.039142  [    0/   28]\n",
      "loss: 0.039133  [    0/   28]\n",
      "loss: 0.039124  [    0/   28]\n",
      "loss: 0.039115  [    0/   28]\n",
      "loss: 0.039107  [    0/   28]\n",
      "loss: 0.039098  [    0/   28]\n",
      "loss: 0.039090  [    0/   28]\n",
      "loss: 0.039081  [    0/   28]\n",
      "loss: 0.039072  [    0/   28]\n",
      "loss: 0.039063  [    0/   28]\n",
      "loss: 0.039055  [    0/   28]\n",
      "loss: 0.039047  [    0/   28]\n",
      "loss: 0.039037  [    0/   28]\n",
      "loss: 0.039029  [    0/   28]\n",
      "loss: 0.039020  [    0/   28]\n",
      "loss: 0.039012  [    0/   28]\n",
      "loss: 0.039003  [    0/   28]\n",
      "loss: 0.038994  [    0/   28]\n",
      "loss: 0.038985  [    0/   28]\n",
      "loss: 0.038977  [    0/   28]\n",
      "loss: 0.038968  [    0/   28]\n",
      "loss: 0.038960  [    0/   28]\n",
      "loss: 0.038951  [    0/   28]\n",
      "loss: 0.038943  [    0/   28]\n",
      "loss: 0.038934  [    0/   28]\n",
      "loss: 0.038925  [    0/   28]\n",
      "loss: 0.038916  [    0/   28]\n",
      "loss: 0.038908  [    0/   28]\n",
      "loss: 0.038899  [    0/   28]\n",
      "loss: 0.038891  [    0/   28]\n",
      "loss: 0.038882  [    0/   28]\n",
      "loss: 0.038873  [    0/   28]\n",
      "loss: 0.038865  [    0/   28]\n",
      "loss: 0.038856  [    0/   28]\n",
      "loss: 0.038848  [    0/   28]\n",
      "loss: 0.038840  [    0/   28]\n",
      "loss: 0.038830  [    0/   28]\n",
      "loss: 0.038822  [    0/   28]\n",
      "loss: 0.038813  [    0/   28]\n",
      "loss: 0.038805  [    0/   28]\n",
      "loss: 0.038796  [    0/   28]\n",
      "loss: 0.038788  [    0/   28]\n",
      "loss: 0.038779  [    0/   28]\n",
      "loss: 0.038771  [    0/   28]\n",
      "loss: 0.038762  [    0/   28]\n",
      "loss: 0.038753  [    0/   28]\n",
      "loss: 0.038745  [    0/   28]\n",
      "loss: 0.038736  [    0/   28]\n",
      "loss: 0.038728  [    0/   28]\n",
      "loss: 0.038719  [    0/   28]\n",
      "loss: 0.038711  [    0/   28]\n",
      "loss: 0.038702  [    0/   28]\n",
      "loss: 0.038694  [    0/   28]\n",
      "loss: 0.038685  [    0/   28]\n",
      "loss: 0.038676  [    0/   28]\n",
      "loss: 0.038668  [    0/   28]\n",
      "loss: 0.038659  [    0/   28]\n",
      "loss: 0.038651  [    0/   28]\n",
      "loss: 0.038642  [    0/   28]\n",
      "loss: 0.038634  [    0/   28]\n",
      "loss: 0.038625  [    0/   28]\n",
      "loss: 0.038617  [    0/   28]\n",
      "loss: 0.038608  [    0/   28]\n",
      "loss: 0.038600  [    0/   28]\n",
      "loss: 0.038591  [    0/   28]\n",
      "loss: 0.038583  [    0/   28]\n",
      "loss: 0.038574  [    0/   28]\n",
      "loss: 0.038566  [    0/   28]\n",
      "loss: 0.038557  [    0/   28]\n",
      "loss: 0.038549  [    0/   28]\n",
      "loss: 0.038540  [    0/   28]\n",
      "loss: 0.038532  [    0/   28]\n",
      "loss: 0.038523  [    0/   28]\n",
      "loss: 0.038515  [    0/   28]\n",
      "loss: 0.038507  [    0/   28]\n",
      "loss: 0.038498  [    0/   28]\n",
      "loss: 0.038490  [    0/   28]\n",
      "loss: 0.038481  [    0/   28]\n",
      "loss: 0.038473  [    0/   28]\n",
      "loss: 0.038464  [    0/   28]\n",
      "loss: 0.038456  [    0/   28]\n",
      "loss: 0.038447  [    0/   28]\n",
      "loss: 0.038439  [    0/   28]\n",
      "loss: 0.038431  [    0/   28]\n",
      "loss: 0.038422  [    0/   28]\n",
      "loss: 0.038413  [    0/   28]\n",
      "loss: 0.038405  [    0/   28]\n",
      "loss: 0.038396  [    0/   28]\n",
      "loss: 0.038388  [    0/   28]\n",
      "loss: 0.038380  [    0/   28]\n",
      "loss: 0.038371  [    0/   28]\n",
      "loss: 0.038363  [    0/   28]\n",
      "loss: 0.038355  [    0/   28]\n",
      "loss: 0.038346  [    0/   28]\n",
      "loss: 0.038337  [    0/   28]\n",
      "loss: 0.038329  [    0/   28]\n",
      "loss: 0.038321  [    0/   28]\n",
      "loss: 0.038312  [    0/   28]\n",
      "loss: 0.038304  [    0/   28]\n",
      "loss: 0.038296  [    0/   28]\n",
      "loss: 0.038287  [    0/   28]\n",
      "loss: 0.038279  [    0/   28]\n",
      "loss: 0.038271  [    0/   28]\n",
      "loss: 0.038262  [    0/   28]\n",
      "loss: 0.038254  [    0/   28]\n",
      "loss: 0.038245  [    0/   28]\n",
      "loss: 0.038237  [    0/   28]\n",
      "loss: 0.038229  [    0/   28]\n",
      "loss: 0.038220  [    0/   28]\n",
      "loss: 0.038212  [    0/   28]\n",
      "loss: 0.038204  [    0/   28]\n",
      "loss: 0.038195  [    0/   28]\n",
      "loss: 0.038187  [    0/   28]\n",
      "loss: 0.038178  [    0/   28]\n",
      "loss: 0.038170  [    0/   28]\n",
      "loss: 0.038162  [    0/   28]\n",
      "loss: 0.038154  [    0/   28]\n",
      "loss: 0.038145  [    0/   28]\n",
      "loss: 0.038137  [    0/   28]\n",
      "loss: 0.038129  [    0/   28]\n",
      "loss: 0.038120  [    0/   28]\n",
      "loss: 0.038111  [    0/   28]\n",
      "loss: 0.038104  [    0/   28]\n",
      "loss: 0.038095  [    0/   28]\n",
      "loss: 0.038087  [    0/   28]\n",
      "loss: 0.038079  [    0/   28]\n",
      "loss: 0.038070  [    0/   28]\n",
      "loss: 0.038062  [    0/   28]\n",
      "loss: 0.038054  [    0/   28]\n",
      "loss: 0.038046  [    0/   28]\n",
      "loss: 0.038037  [    0/   28]\n",
      "loss: 0.038029  [    0/   28]\n",
      "loss: 0.038020  [    0/   28]\n",
      "loss: 0.038012  [    0/   28]\n",
      "loss: 0.038004  [    0/   28]\n",
      "loss: 0.037996  [    0/   28]\n",
      "loss: 0.037987  [    0/   28]\n",
      "loss: 0.037979  [    0/   28]\n",
      "loss: 0.037971  [    0/   28]\n",
      "loss: 0.037962  [    0/   28]\n",
      "loss: 0.037954  [    0/   28]\n",
      "loss: 0.037946  [    0/   28]\n",
      "loss: 0.037938  [    0/   28]\n",
      "loss: 0.037929  [    0/   28]\n",
      "loss: 0.037921  [    0/   28]\n",
      "loss: 0.037913  [    0/   28]\n",
      "loss: 0.037905  [    0/   28]\n",
      "loss: 0.037896  [    0/   28]\n",
      "loss: 0.037888  [    0/   28]\n",
      "loss: 0.037880  [    0/   28]\n",
      "loss: 0.037872  [    0/   28]\n",
      "loss: 0.037864  [    0/   28]\n",
      "loss: 0.037855  [    0/   28]\n",
      "loss: 0.037847  [    0/   28]\n",
      "loss: 0.037839  [    0/   28]\n",
      "loss: 0.037831  [    0/   28]\n",
      "loss: 0.037822  [    0/   28]\n",
      "loss: 0.037814  [    0/   28]\n",
      "loss: 0.037806  [    0/   28]\n",
      "loss: 0.037797  [    0/   28]\n",
      "loss: 0.037789  [    0/   28]\n",
      "loss: 0.037781  [    0/   28]\n",
      "loss: 0.037773  [    0/   28]\n",
      "loss: 0.037765  [    0/   28]\n",
      "loss: 0.037757  [    0/   28]\n",
      "loss: 0.037748  [    0/   28]\n",
      "loss: 0.037740  [    0/   28]\n",
      "loss: 0.037732  [    0/   28]\n",
      "loss: 0.037724  [    0/   28]\n",
      "loss: 0.037716  [    0/   28]\n",
      "loss: 0.037707  [    0/   28]\n",
      "loss: 0.037699  [    0/   28]\n",
      "loss: 0.037691  [    0/   28]\n",
      "loss: 0.037683  [    0/   28]\n",
      "loss: 0.037675  [    0/   28]\n",
      "loss: 0.037666  [    0/   28]\n",
      "loss: 0.037658  [    0/   28]\n",
      "loss: 0.037650  [    0/   28]\n",
      "loss: 0.037642  [    0/   28]\n",
      "loss: 0.037634  [    0/   28]\n",
      "loss: 0.037626  [    0/   28]\n",
      "loss: 0.037617  [    0/   28]\n",
      "loss: 0.037609  [    0/   28]\n",
      "loss: 0.037602  [    0/   28]\n",
      "loss: 0.037593  [    0/   28]\n",
      "loss: 0.037585  [    0/   28]\n",
      "loss: 0.037577  [    0/   28]\n",
      "loss: 0.037569  [    0/   28]\n",
      "loss: 0.037561  [    0/   28]\n",
      "loss: 0.037553  [    0/   28]\n",
      "loss: 0.037545  [    0/   28]\n",
      "loss: 0.037536  [    0/   28]\n",
      "loss: 0.037528  [    0/   28]\n",
      "loss: 0.037520  [    0/   28]\n",
      "loss: 0.037512  [    0/   28]\n",
      "loss: 0.037504  [    0/   28]\n",
      "loss: 0.037495  [    0/   28]\n",
      "loss: 0.037488  [    0/   28]\n",
      "loss: 0.037480  [    0/   28]\n",
      "loss: 0.037472  [    0/   28]\n",
      "loss: 0.037463  [    0/   28]\n",
      "loss: 0.037455  [    0/   28]\n",
      "loss: 0.037447  [    0/   28]\n",
      "loss: 0.037439  [    0/   28]\n",
      "loss: 0.037431  [    0/   28]\n",
      "loss: 0.037423  [    0/   28]\n",
      "loss: 0.037415  [    0/   28]\n",
      "loss: 0.037407  [    0/   28]\n",
      "loss: 0.037399  [    0/   28]\n",
      "loss: 0.037391  [    0/   28]\n",
      "loss: 0.037383  [    0/   28]\n",
      "loss: 0.037374  [    0/   28]\n",
      "loss: 0.037366  [    0/   28]\n",
      "loss: 0.037358  [    0/   28]\n",
      "loss: 0.037350  [    0/   28]\n",
      "loss: 0.037342  [    0/   28]\n",
      "loss: 0.037334  [    0/   28]\n",
      "loss: 0.037326  [    0/   28]\n",
      "loss: 0.037318  [    0/   28]\n",
      "loss: 0.037310  [    0/   28]\n",
      "loss: 0.037302  [    0/   28]\n",
      "loss: 0.037294  [    0/   28]\n",
      "loss: 0.037286  [    0/   28]\n",
      "loss: 0.037278  [    0/   28]\n",
      "loss: 0.037270  [    0/   28]\n",
      "loss: 0.037262  [    0/   28]\n",
      "loss: 0.037254  [    0/   28]\n",
      "loss: 0.037246  [    0/   28]\n",
      "loss: 0.037238  [    0/   28]\n",
      "loss: 0.037230  [    0/   28]\n",
      "loss: 0.037222  [    0/   28]\n",
      "loss: 0.037214  [    0/   28]\n",
      "loss: 0.037206  [    0/   28]\n",
      "loss: 0.037198  [    0/   28]\n",
      "loss: 0.037190  [    0/   28]\n",
      "loss: 0.037182  [    0/   28]\n",
      "loss: 0.037174  [    0/   28]\n",
      "loss: 0.037166  [    0/   28]\n",
      "loss: 0.037158  [    0/   28]\n",
      "loss: 0.037150  [    0/   28]\n",
      "loss: 0.037142  [    0/   28]\n",
      "loss: 0.037134  [    0/   28]\n",
      "loss: 0.037126  [    0/   28]\n",
      "loss: 0.037118  [    0/   28]\n",
      "loss: 0.037110  [    0/   28]\n",
      "loss: 0.037102  [    0/   28]\n",
      "loss: 0.037094  [    0/   28]\n",
      "loss: 0.037086  [    0/   28]\n",
      "loss: 0.037078  [    0/   28]\n",
      "loss: 0.037070  [    0/   28]\n",
      "loss: 0.037062  [    0/   28]\n",
      "loss: 0.037054  [    0/   28]\n",
      "loss: 0.037046  [    0/   28]\n",
      "loss: 0.037038  [    0/   28]\n",
      "loss: 0.037031  [    0/   28]\n",
      "loss: 0.037023  [    0/   28]\n",
      "loss: 0.037015  [    0/   28]\n",
      "loss: 0.037006  [    0/   28]\n",
      "loss: 0.036999  [    0/   28]\n",
      "loss: 0.036991  [    0/   28]\n",
      "loss: 0.036983  [    0/   28]\n",
      "loss: 0.036975  [    0/   28]\n",
      "loss: 0.036967  [    0/   28]\n",
      "loss: 0.036959  [    0/   28]\n",
      "loss: 0.036951  [    0/   28]\n",
      "loss: 0.036944  [    0/   28]\n",
      "loss: 0.036936  [    0/   28]\n",
      "loss: 0.036927  [    0/   28]\n",
      "loss: 0.036920  [    0/   28]\n",
      "loss: 0.036912  [    0/   28]\n",
      "loss: 0.036904  [    0/   28]\n",
      "loss: 0.036896  [    0/   28]\n",
      "loss: 0.036888  [    0/   28]\n",
      "loss: 0.036880  [    0/   28]\n",
      "loss: 0.036872  [    0/   28]\n",
      "loss: 0.036865  [    0/   28]\n",
      "loss: 0.036857  [    0/   28]\n",
      "loss: 0.036849  [    0/   28]\n",
      "loss: 0.036841  [    0/   28]\n",
      "loss: 0.036833  [    0/   28]\n",
      "loss: 0.036825  [    0/   28]\n",
      "loss: 0.036817  [    0/   28]\n",
      "loss: 0.036810  [    0/   28]\n",
      "loss: 0.036801  [    0/   28]\n",
      "loss: 0.036794  [    0/   28]\n",
      "loss: 0.036786  [    0/   28]\n",
      "loss: 0.036778  [    0/   28]\n",
      "loss: 0.036770  [    0/   28]\n",
      "loss: 0.036762  [    0/   28]\n",
      "loss: 0.036754  [    0/   28]\n",
      "loss: 0.036747  [    0/   28]\n",
      "loss: 0.036739  [    0/   28]\n",
      "loss: 0.036731  [    0/   28]\n",
      "loss: 0.036723  [    0/   28]\n",
      "loss: 0.036715  [    0/   28]\n",
      "loss: 0.036708  [    0/   28]\n",
      "loss: 0.036700  [    0/   28]\n",
      "loss: 0.036692  [    0/   28]\n",
      "loss: 0.036684  [    0/   28]\n",
      "loss: 0.036676  [    0/   28]\n",
      "loss: 0.036668  [    0/   28]\n",
      "loss: 0.036660  [    0/   28]\n",
      "loss: 0.036652  [    0/   28]\n",
      "loss: 0.036645  [    0/   28]\n",
      "loss: 0.036637  [    0/   28]\n",
      "loss: 0.036629  [    0/   28]\n",
      "loss: 0.036621  [    0/   28]\n",
      "loss: 0.036614  [    0/   28]\n",
      "loss: 0.036606  [    0/   28]\n",
      "loss: 0.036598  [    0/   28]\n",
      "loss: 0.036590  [    0/   28]\n",
      "loss: 0.036582  [    0/   28]\n",
      "loss: 0.036575  [    0/   28]\n",
      "loss: 0.036567  [    0/   28]\n",
      "loss: 0.036559  [    0/   28]\n",
      "loss: 0.036551  [    0/   28]\n",
      "loss: 0.036544  [    0/   28]\n",
      "loss: 0.036536  [    0/   28]\n",
      "loss: 0.036528  [    0/   28]\n",
      "loss: 0.036520  [    0/   28]\n",
      "loss: 0.036512  [    0/   28]\n",
      "loss: 0.036505  [    0/   28]\n",
      "loss: 0.036497  [    0/   28]\n",
      "loss: 0.036489  [    0/   28]\n",
      "loss: 0.036482  [    0/   28]\n",
      "loss: 0.036474  [    0/   28]\n",
      "loss: 0.036466  [    0/   28]\n",
      "loss: 0.036458  [    0/   28]\n",
      "loss: 0.036450  [    0/   28]\n",
      "loss: 0.036443  [    0/   28]\n",
      "loss: 0.036435  [    0/   28]\n",
      "loss: 0.036428  [    0/   28]\n",
      "loss: 0.036420  [    0/   28]\n",
      "loss: 0.036412  [    0/   28]\n",
      "loss: 0.036404  [    0/   28]\n",
      "loss: 0.036396  [    0/   28]\n",
      "loss: 0.036389  [    0/   28]\n",
      "loss: 0.036381  [    0/   28]\n",
      "loss: 0.036373  [    0/   28]\n",
      "loss: 0.036366  [    0/   28]\n",
      "loss: 0.036358  [    0/   28]\n",
      "loss: 0.036350  [    0/   28]\n",
      "loss: 0.036342  [    0/   28]\n",
      "loss: 0.036335  [    0/   28]\n",
      "loss: 0.036327  [    0/   28]\n",
      "loss: 0.036319  [    0/   28]\n",
      "loss: 0.036312  [    0/   28]\n",
      "loss: 0.036304  [    0/   28]\n",
      "loss: 0.036296  [    0/   28]\n",
      "loss: 0.036288  [    0/   28]\n",
      "loss: 0.036281  [    0/   28]\n",
      "loss: 0.036274  [    0/   28]\n",
      "loss: 0.036266  [    0/   28]\n",
      "loss: 0.036258  [    0/   28]\n",
      "loss: 0.036250  [    0/   28]\n",
      "loss: 0.036242  [    0/   28]\n",
      "loss: 0.036235  [    0/   28]\n",
      "loss: 0.036227  [    0/   28]\n",
      "loss: 0.036220  [    0/   28]\n",
      "loss: 0.036212  [    0/   28]\n",
      "loss: 0.036204  [    0/   28]\n",
      "loss: 0.036197  [    0/   28]\n",
      "loss: 0.036189  [    0/   28]\n",
      "loss: 0.036182  [    0/   28]\n",
      "loss: 0.036174  [    0/   28]\n",
      "loss: 0.036166  [    0/   28]\n",
      "loss: 0.036158  [    0/   28]\n",
      "loss: 0.036151  [    0/   28]\n",
      "loss: 0.036143  [    0/   28]\n",
      "loss: 0.036135  [    0/   28]\n",
      "loss: 0.036128  [    0/   28]\n",
      "loss: 0.036121  [    0/   28]\n",
      "loss: 0.036113  [    0/   28]\n",
      "loss: 0.036105  [    0/   28]\n",
      "loss: 0.036097  [    0/   28]\n",
      "loss: 0.036090  [    0/   28]\n",
      "loss: 0.036082  [    0/   28]\n",
      "loss: 0.036074  [    0/   28]\n",
      "loss: 0.036067  [    0/   28]\n",
      "loss: 0.036059  [    0/   28]\n",
      "loss: 0.036052  [    0/   28]\n",
      "loss: 0.036044  [    0/   28]\n",
      "loss: 0.036037  [    0/   28]\n",
      "loss: 0.036029  [    0/   28]\n",
      "loss: 0.036021  [    0/   28]\n",
      "loss: 0.036014  [    0/   28]\n",
      "loss: 0.036006  [    0/   28]\n",
      "loss: 0.035999  [    0/   28]\n",
      "loss: 0.035991  [    0/   28]\n",
      "loss: 0.035983  [    0/   28]\n",
      "loss: 0.035976  [    0/   28]\n",
      "loss: 0.035968  [    0/   28]\n",
      "loss: 0.035961  [    0/   28]\n",
      "loss: 0.035953  [    0/   28]\n",
      "loss: 0.035946  [    0/   28]\n",
      "loss: 0.035939  [    0/   28]\n",
      "loss: 0.035930  [    0/   28]\n",
      "loss: 0.035923  [    0/   28]\n",
      "loss: 0.035915  [    0/   28]\n",
      "loss: 0.035908  [    0/   28]\n",
      "loss: 0.035900  [    0/   28]\n",
      "loss: 0.035893  [    0/   28]\n",
      "loss: 0.035885  [    0/   28]\n",
      "loss: 0.035878  [    0/   28]\n",
      "loss: 0.035870  [    0/   28]\n",
      "loss: 0.035863  [    0/   28]\n",
      "loss: 0.035855  [    0/   28]\n",
      "loss: 0.035847  [    0/   28]\n",
      "loss: 0.035840  [    0/   28]\n",
      "loss: 0.035833  [    0/   28]\n",
      "loss: 0.035825  [    0/   28]\n",
      "loss: 0.035817  [    0/   28]\n",
      "loss: 0.035810  [    0/   28]\n",
      "loss: 0.035802  [    0/   28]\n",
      "loss: 0.035795  [    0/   28]\n",
      "loss: 0.035787  [    0/   28]\n",
      "loss: 0.035780  [    0/   28]\n",
      "loss: 0.035772  [    0/   28]\n",
      "loss: 0.035765  [    0/   28]\n",
      "loss: 0.035758  [    0/   28]\n",
      "loss: 0.035750  [    0/   28]\n",
      "loss: 0.035742  [    0/   28]\n",
      "loss: 0.035735  [    0/   28]\n",
      "loss: 0.035728  [    0/   28]\n",
      "loss: 0.035720  [    0/   28]\n",
      "loss: 0.035712  [    0/   28]\n",
      "loss: 0.035705  [    0/   28]\n",
      "loss: 0.035698  [    0/   28]\n",
      "loss: 0.035690  [    0/   28]\n",
      "loss: 0.035683  [    0/   28]\n",
      "loss: 0.035675  [    0/   28]\n",
      "loss: 0.035668  [    0/   28]\n",
      "loss: 0.035660  [    0/   28]\n",
      "loss: 0.035653  [    0/   28]\n",
      "loss: 0.035645  [    0/   28]\n",
      "loss: 0.035638  [    0/   28]\n",
      "loss: 0.035630  [    0/   28]\n",
      "loss: 0.035623  [    0/   28]\n",
      "loss: 0.035615  [    0/   28]\n",
      "loss: 0.035608  [    0/   28]\n",
      "loss: 0.035601  [    0/   28]\n",
      "loss: 0.035593  [    0/   28]\n",
      "loss: 0.035586  [    0/   28]\n",
      "loss: 0.035578  [    0/   28]\n",
      "loss: 0.035571  [    0/   28]\n",
      "loss: 0.035564  [    0/   28]\n",
      "loss: 0.035556  [    0/   28]\n",
      "loss: 0.035548  [    0/   28]\n",
      "loss: 0.035541  [    0/   28]\n",
      "loss: 0.035534  [    0/   28]\n",
      "loss: 0.035526  [    0/   28]\n",
      "loss: 0.035519  [    0/   28]\n",
      "loss: 0.035511  [    0/   28]\n",
      "loss: 0.035504  [    0/   28]\n",
      "loss: 0.035497  [    0/   28]\n",
      "loss: 0.035489  [    0/   28]\n",
      "loss: 0.035482  [    0/   28]\n",
      "loss: 0.035475  [    0/   28]\n",
      "loss: 0.035467  [    0/   28]\n",
      "loss: 0.035460  [    0/   28]\n",
      "loss: 0.035452  [    0/   28]\n",
      "loss: 0.035445  [    0/   28]\n",
      "loss: 0.035437  [    0/   28]\n",
      "loss: 0.035430  [    0/   28]\n",
      "loss: 0.035423  [    0/   28]\n",
      "loss: 0.035416  [    0/   28]\n",
      "loss: 0.035408  [    0/   28]\n",
      "loss: 0.035401  [    0/   28]\n",
      "loss: 0.035393  [    0/   28]\n",
      "loss: 0.035386  [    0/   28]\n",
      "loss: 0.035379  [    0/   28]\n",
      "loss: 0.035372  [    0/   28]\n",
      "loss: 0.035364  [    0/   28]\n",
      "loss: 0.035356  [    0/   28]\n",
      "loss: 0.035349  [    0/   28]\n",
      "loss: 0.035342  [    0/   28]\n",
      "loss: 0.035335  [    0/   28]\n",
      "loss: 0.035327  [    0/   28]\n",
      "loss: 0.035320  [    0/   28]\n",
      "loss: 0.035312  [    0/   28]\n",
      "loss: 0.035305  [    0/   28]\n",
      "loss: 0.035298  [    0/   28]\n",
      "loss: 0.035290  [    0/   28]\n",
      "loss: 0.035283  [    0/   28]\n",
      "loss: 0.035275  [    0/   28]\n",
      "loss: 0.035268  [    0/   28]\n",
      "loss: 0.035261  [    0/   28]\n",
      "loss: 0.035254  [    0/   28]\n",
      "loss: 0.035246  [    0/   28]\n",
      "loss: 0.035239  [    0/   28]\n",
      "loss: 0.035232  [    0/   28]\n",
      "loss: 0.035224  [    0/   28]\n",
      "loss: 0.035217  [    0/   28]\n",
      "loss: 0.035210  [    0/   28]\n",
      "loss: 0.035203  [    0/   28]\n",
      "loss: 0.035195  [    0/   28]\n",
      "loss: 0.035188  [    0/   28]\n",
      "loss: 0.035181  [    0/   28]\n",
      "loss: 0.035173  [    0/   28]\n",
      "loss: 0.035166  [    0/   28]\n",
      "loss: 0.035159  [    0/   28]\n",
      "loss: 0.035152  [    0/   28]\n",
      "loss: 0.035144  [    0/   28]\n",
      "loss: 0.035137  [    0/   28]\n",
      "loss: 0.035129  [    0/   28]\n",
      "loss: 0.035122  [    0/   28]\n",
      "loss: 0.035115  [    0/   28]\n",
      "loss: 0.035108  [    0/   28]\n",
      "loss: 0.035101  [    0/   28]\n",
      "loss: 0.035093  [    0/   28]\n",
      "loss: 0.035086  [    0/   28]\n",
      "loss: 0.035079  [    0/   28]\n",
      "loss: 0.035072  [    0/   28]\n",
      "loss: 0.035064  [    0/   28]\n",
      "loss: 0.035057  [    0/   28]\n",
      "loss: 0.035050  [    0/   28]\n",
      "loss: 0.035042  [    0/   28]\n",
      "loss: 0.035035  [    0/   28]\n",
      "loss: 0.035028  [    0/   28]\n",
      "loss: 0.035021  [    0/   28]\n",
      "loss: 0.035014  [    0/   28]\n",
      "loss: 0.035006  [    0/   28]\n",
      "loss: 0.034999  [    0/   28]\n",
      "loss: 0.034992  [    0/   28]\n",
      "loss: 0.034985  [    0/   28]\n",
      "loss: 0.034978  [    0/   28]\n",
      "loss: 0.034970  [    0/   28]\n",
      "loss: 0.034963  [    0/   28]\n",
      "loss: 0.034955  [    0/   28]\n",
      "loss: 0.034949  [    0/   28]\n",
      "loss: 0.034941  [    0/   28]\n",
      "loss: 0.034934  [    0/   28]\n",
      "loss: 0.034927  [    0/   28]\n",
      "loss: 0.034920  [    0/   28]\n",
      "loss: 0.034912  [    0/   28]\n",
      "loss: 0.034905  [    0/   28]\n",
      "loss: 0.034898  [    0/   28]\n",
      "loss: 0.034891  [    0/   28]\n",
      "loss: 0.034884  [    0/   28]\n",
      "loss: 0.034876  [    0/   28]\n",
      "loss: 0.034869  [    0/   28]\n",
      "loss: 0.034862  [    0/   28]\n",
      "loss: 0.034855  [    0/   28]\n",
      "loss: 0.034848  [    0/   28]\n",
      "loss: 0.034840  [    0/   28]\n",
      "loss: 0.034833  [    0/   28]\n",
      "loss: 0.034826  [    0/   28]\n",
      "loss: 0.034819  [    0/   28]\n",
      "loss: 0.034812  [    0/   28]\n",
      "loss: 0.034805  [    0/   28]\n",
      "loss: 0.034798  [    0/   28]\n",
      "loss: 0.034790  [    0/   28]\n",
      "loss: 0.034783  [    0/   28]\n",
      "loss: 0.034776  [    0/   28]\n",
      "loss: 0.034769  [    0/   28]\n",
      "loss: 0.034762  [    0/   28]\n",
      "loss: 0.034755  [    0/   28]\n",
      "loss: 0.034747  [    0/   28]\n",
      "loss: 0.034740  [    0/   28]\n",
      "loss: 0.034733  [    0/   28]\n",
      "loss: 0.034726  [    0/   28]\n",
      "loss: 0.034719  [    0/   28]\n",
      "loss: 0.034712  [    0/   28]\n",
      "loss: 0.034705  [    0/   28]\n",
      "loss: 0.034697  [    0/   28]\n",
      "loss: 0.034690  [    0/   28]\n",
      "loss: 0.034683  [    0/   28]\n",
      "loss: 0.034676  [    0/   28]\n",
      "loss: 0.034669  [    0/   28]\n",
      "loss: 0.034662  [    0/   28]\n",
      "loss: 0.034655  [    0/   28]\n",
      "loss: 0.034647  [    0/   28]\n",
      "loss: 0.034640  [    0/   28]\n",
      "loss: 0.034633  [    0/   28]\n",
      "loss: 0.034626  [    0/   28]\n",
      "loss: 0.034619  [    0/   28]\n",
      "loss: 0.034612  [    0/   28]\n",
      "loss: 0.034605  [    0/   28]\n",
      "loss: 0.034598  [    0/   28]\n",
      "loss: 0.034591  [    0/   28]\n",
      "loss: 0.034584  [    0/   28]\n",
      "loss: 0.034577  [    0/   28]\n",
      "loss: 0.034569  [    0/   28]\n",
      "loss: 0.034562  [    0/   28]\n",
      "loss: 0.034555  [    0/   28]\n",
      "loss: 0.034548  [    0/   28]\n",
      "loss: 0.034541  [    0/   28]\n",
      "loss: 0.034534  [    0/   28]\n",
      "loss: 0.034527  [    0/   28]\n",
      "loss: 0.034520  [    0/   28]\n",
      "loss: 0.034513  [    0/   28]\n",
      "loss: 0.034506  [    0/   28]\n",
      "loss: 0.034499  [    0/   28]\n",
      "loss: 0.034492  [    0/   28]\n",
      "loss: 0.034484  [    0/   28]\n",
      "loss: 0.034477  [    0/   28]\n",
      "loss: 0.034471  [    0/   28]\n",
      "loss: 0.034463  [    0/   28]\n",
      "loss: 0.034457  [    0/   28]\n",
      "loss: 0.034449  [    0/   28]\n",
      "loss: 0.034442  [    0/   28]\n",
      "loss: 0.034435  [    0/   28]\n",
      "loss: 0.034428  [    0/   28]\n",
      "loss: 0.034421  [    0/   28]\n",
      "loss: 0.034414  [    0/   28]\n",
      "loss: 0.034407  [    0/   28]\n",
      "loss: 0.034400  [    0/   28]\n",
      "loss: 0.034393  [    0/   28]\n",
      "loss: 0.034386  [    0/   28]\n",
      "loss: 0.034379  [    0/   28]\n",
      "loss: 0.034372  [    0/   28]\n",
      "loss: 0.034365  [    0/   28]\n",
      "loss: 0.034358  [    0/   28]\n",
      "loss: 0.034351  [    0/   28]\n",
      "loss: 0.034344  [    0/   28]\n",
      "loss: 0.034337  [    0/   28]\n",
      "loss: 0.034330  [    0/   28]\n",
      "loss: 0.034323  [    0/   28]\n",
      "loss: 0.034316  [    0/   28]\n",
      "loss: 0.034309  [    0/   28]\n",
      "loss: 0.034302  [    0/   28]\n",
      "loss: 0.034295  [    0/   28]\n",
      "loss: 0.034288  [    0/   28]\n",
      "loss: 0.034281  [    0/   28]\n",
      "loss: 0.034274  [    0/   28]\n",
      "loss: 0.034267  [    0/   28]\n",
      "loss: 0.034260  [    0/   28]\n",
      "loss: 0.034253  [    0/   28]\n",
      "loss: 0.034246  [    0/   28]\n",
      "loss: 0.034239  [    0/   28]\n",
      "loss: 0.034232  [    0/   28]\n",
      "loss: 0.034225  [    0/   28]\n",
      "loss: 0.034218  [    0/   28]\n",
      "loss: 0.034211  [    0/   28]\n",
      "loss: 0.034204  [    0/   28]\n",
      "loss: 0.034197  [    0/   28]\n",
      "loss: 0.034190  [    0/   28]\n",
      "loss: 0.034183  [    0/   28]\n",
      "loss: 0.034176  [    0/   28]\n",
      "loss: 0.034169  [    0/   28]\n",
      "loss: 0.034162  [    0/   28]\n",
      "loss: 0.034155  [    0/   28]\n",
      "loss: 0.034149  [    0/   28]\n",
      "loss: 0.034142  [    0/   28]\n",
      "loss: 0.034135  [    0/   28]\n",
      "loss: 0.034128  [    0/   28]\n",
      "loss: 0.034121  [    0/   28]\n",
      "loss: 0.034114  [    0/   28]\n",
      "loss: 0.034107  [    0/   28]\n",
      "loss: 0.034100  [    0/   28]\n",
      "loss: 0.034093  [    0/   28]\n",
      "loss: 0.034086  [    0/   28]\n",
      "loss: 0.034079  [    0/   28]\n",
      "loss: 0.034072  [    0/   28]\n",
      "loss: 0.034065  [    0/   28]\n",
      "loss: 0.034059  [    0/   28]\n",
      "loss: 0.034052  [    0/   28]\n",
      "loss: 0.034045  [    0/   28]\n",
      "loss: 0.034038  [    0/   28]\n",
      "loss: 0.034031  [    0/   28]\n",
      "loss: 0.034024  [    0/   28]\n",
      "loss: 0.034017  [    0/   28]\n",
      "loss: 0.034010  [    0/   28]\n",
      "loss: 0.034003  [    0/   28]\n",
      "loss: 0.033996  [    0/   28]\n",
      "loss: 0.033990  [    0/   28]\n",
      "loss: 0.033983  [    0/   28]\n",
      "loss: 0.033976  [    0/   28]\n",
      "loss: 0.033969  [    0/   28]\n",
      "loss: 0.033962  [    0/   28]\n",
      "loss: 0.033955  [    0/   28]\n",
      "loss: 0.033949  [    0/   28]\n",
      "loss: 0.033941  [    0/   28]\n",
      "loss: 0.033934  [    0/   28]\n",
      "loss: 0.033928  [    0/   28]\n",
      "loss: 0.033921  [    0/   28]\n",
      "loss: 0.033914  [    0/   28]\n",
      "loss: 0.033907  [    0/   28]\n",
      "loss: 0.033900  [    0/   28]\n",
      "loss: 0.033893  [    0/   28]\n",
      "loss: 0.033886  [    0/   28]\n",
      "loss: 0.033880  [    0/   28]\n",
      "loss: 0.033873  [    0/   28]\n",
      "loss: 0.033866  [    0/   28]\n",
      "loss: 0.033859  [    0/   28]\n",
      "loss: 0.033853  [    0/   28]\n",
      "loss: 0.033846  [    0/   28]\n",
      "loss: 0.033838  [    0/   28]\n",
      "loss: 0.033832  [    0/   28]\n",
      "loss: 0.033825  [    0/   28]\n",
      "loss: 0.033818  [    0/   28]\n",
      "loss: 0.033812  [    0/   28]\n",
      "loss: 0.033804  [    0/   28]\n",
      "loss: 0.033798  [    0/   28]\n",
      "loss: 0.033791  [    0/   28]\n",
      "loss: 0.033784  [    0/   28]\n",
      "loss: 0.033777  [    0/   28]\n",
      "loss: 0.033770  [    0/   28]\n",
      "loss: 0.033763  [    0/   28]\n",
      "loss: 0.033757  [    0/   28]\n",
      "loss: 0.033750  [    0/   28]\n",
      "loss: 0.033743  [    0/   28]\n",
      "loss: 0.033736  [    0/   28]\n",
      "loss: 0.033730  [    0/   28]\n",
      "loss: 0.033723  [    0/   28]\n",
      "loss: 0.033716  [    0/   28]\n",
      "loss: 0.033709  [    0/   28]\n",
      "loss: 0.033703  [    0/   28]\n",
      "loss: 0.033696  [    0/   28]\n",
      "loss: 0.033689  [    0/   28]\n",
      "loss: 0.033682  [    0/   28]\n",
      "loss: 0.033675  [    0/   28]\n",
      "loss: 0.033669  [    0/   28]\n",
      "loss: 0.033662  [    0/   28]\n",
      "loss: 0.033655  [    0/   28]\n",
      "loss: 0.033648  [    0/   28]\n",
      "loss: 0.033641  [    0/   28]\n",
      "loss: 0.033635  [    0/   28]\n",
      "loss: 0.033628  [    0/   28]\n",
      "loss: 0.033621  [    0/   28]\n",
      "loss: 0.033614  [    0/   28]\n",
      "loss: 0.033608  [    0/   28]\n",
      "loss: 0.033601  [    0/   28]\n",
      "loss: 0.033594  [    0/   28]\n",
      "loss: 0.033587  [    0/   28]\n",
      "loss: 0.033581  [    0/   28]\n",
      "loss: 0.033574  [    0/   28]\n",
      "loss: 0.033567  [    0/   28]\n",
      "loss: 0.033561  [    0/   28]\n",
      "loss: 0.033554  [    0/   28]\n",
      "loss: 0.033547  [    0/   28]\n",
      "loss: 0.033540  [    0/   28]\n",
      "loss: 0.033533  [    0/   28]\n",
      "loss: 0.033527  [    0/   28]\n",
      "loss: 0.033520  [    0/   28]\n",
      "loss: 0.033513  [    0/   28]\n",
      "loss: 0.033507  [    0/   28]\n",
      "loss: 0.033500  [    0/   28]\n",
      "loss: 0.033493  [    0/   28]\n",
      "loss: 0.033486  [    0/   28]\n",
      "loss: 0.033480  [    0/   28]\n",
      "loss: 0.033473  [    0/   28]\n",
      "loss: 0.033466  [    0/   28]\n",
      "loss: 0.033459  [    0/   28]\n",
      "loss: 0.033453  [    0/   28]\n",
      "loss: 0.033446  [    0/   28]\n",
      "loss: 0.033439  [    0/   28]\n",
      "loss: 0.033433  [    0/   28]\n",
      "loss: 0.033426  [    0/   28]\n",
      "loss: 0.033419  [    0/   28]\n",
      "loss: 0.033413  [    0/   28]\n",
      "loss: 0.033406  [    0/   28]\n",
      "loss: 0.033399  [    0/   28]\n",
      "loss: 0.033392  [    0/   28]\n",
      "loss: 0.033386  [    0/   28]\n",
      "loss: 0.033379  [    0/   28]\n",
      "loss: 0.033373  [    0/   28]\n",
      "loss: 0.033366  [    0/   28]\n",
      "loss: 0.033359  [    0/   28]\n",
      "loss: 0.033352  [    0/   28]\n",
      "loss: 0.033346  [    0/   28]\n",
      "loss: 0.033339  [    0/   28]\n",
      "loss: 0.033333  [    0/   28]\n",
      "loss: 0.033326  [    0/   28]\n",
      "loss: 0.033319  [    0/   28]\n",
      "loss: 0.033313  [    0/   28]\n",
      "loss: 0.033306  [    0/   28]\n",
      "loss: 0.033299  [    0/   28]\n",
      "loss: 0.033293  [    0/   28]\n",
      "loss: 0.033286  [    0/   28]\n",
      "loss: 0.033279  [    0/   28]\n",
      "loss: 0.033272  [    0/   28]\n",
      "loss: 0.033266  [    0/   28]\n",
      "loss: 0.033259  [    0/   28]\n",
      "loss: 0.033253  [    0/   28]\n",
      "loss: 0.033246  [    0/   28]\n",
      "loss: 0.033239  [    0/   28]\n",
      "loss: 0.033233  [    0/   28]\n",
      "loss: 0.033226  [    0/   28]\n",
      "loss: 0.033219  [    0/   28]\n",
      "loss: 0.033213  [    0/   28]\n",
      "loss: 0.033206  [    0/   28]\n",
      "loss: 0.033199  [    0/   28]\n",
      "loss: 0.033193  [    0/   28]\n",
      "loss: 0.033186  [    0/   28]\n",
      "loss: 0.033180  [    0/   28]\n",
      "loss: 0.033173  [    0/   28]\n",
      "loss: 0.033166  [    0/   28]\n",
      "loss: 0.033160  [    0/   28]\n",
      "loss: 0.033153  [    0/   28]\n",
      "loss: 0.033147  [    0/   28]\n",
      "loss: 0.033140  [    0/   28]\n",
      "loss: 0.033134  [    0/   28]\n",
      "loss: 0.033127  [    0/   28]\n",
      "loss: 0.033120  [    0/   28]\n",
      "loss: 0.033114  [    0/   28]\n",
      "loss: 0.033107  [    0/   28]\n",
      "loss: 0.033100  [    0/   28]\n",
      "loss: 0.033094  [    0/   28]\n",
      "loss: 0.033087  [    0/   28]\n",
      "loss: 0.033081  [    0/   28]\n",
      "loss: 0.033074  [    0/   28]\n",
      "loss: 0.033067  [    0/   28]\n",
      "loss: 0.033061  [    0/   28]\n",
      "loss: 0.033054  [    0/   28]\n",
      "loss: 0.033048  [    0/   28]\n",
      "loss: 0.033041  [    0/   28]\n",
      "loss: 0.033035  [    0/   28]\n",
      "loss: 0.033028  [    0/   28]\n",
      "loss: 0.033022  [    0/   28]\n",
      "loss: 0.033015  [    0/   28]\n",
      "loss: 0.033008  [    0/   28]\n",
      "loss: 0.033002  [    0/   28]\n",
      "loss: 0.032995  [    0/   28]\n",
      "loss: 0.032989  [    0/   28]\n",
      "loss: 0.032982  [    0/   28]\n",
      "loss: 0.032976  [    0/   28]\n",
      "loss: 0.032969  [    0/   28]\n",
      "loss: 0.032963  [    0/   28]\n",
      "loss: 0.032956  [    0/   28]\n",
      "loss: 0.032950  [    0/   28]\n",
      "loss: 0.032943  [    0/   28]\n",
      "loss: 0.032937  [    0/   28]\n",
      "loss: 0.032930  [    0/   28]\n",
      "loss: 0.032923  [    0/   28]\n",
      "loss: 0.032917  [    0/   28]\n",
      "loss: 0.032910  [    0/   28]\n",
      "loss: 0.032904  [    0/   28]\n",
      "loss: 0.032898  [    0/   28]\n",
      "loss: 0.032891  [    0/   28]\n",
      "loss: 0.032884  [    0/   28]\n",
      "loss: 0.032878  [    0/   28]\n",
      "loss: 0.032871  [    0/   28]\n",
      "loss: 0.032865  [    0/   28]\n",
      "loss: 0.032858  [    0/   28]\n",
      "loss: 0.032852  [    0/   28]\n",
      "loss: 0.032845  [    0/   28]\n",
      "loss: 0.032839  [    0/   28]\n",
      "loss: 0.032832  [    0/   28]\n",
      "loss: 0.032826  [    0/   28]\n",
      "loss: 0.032819  [    0/   28]\n",
      "loss: 0.032813  [    0/   28]\n",
      "loss: 0.032807  [    0/   28]\n",
      "loss: 0.032800  [    0/   28]\n",
      "loss: 0.032793  [    0/   28]\n",
      "loss: 0.032787  [    0/   28]\n",
      "loss: 0.032780  [    0/   28]\n",
      "loss: 0.032774  [    0/   28]\n",
      "loss: 0.032767  [    0/   28]\n",
      "loss: 0.032761  [    0/   28]\n",
      "loss: 0.032755  [    0/   28]\n",
      "loss: 0.032748  [    0/   28]\n",
      "loss: 0.032741  [    0/   28]\n",
      "loss: 0.032735  [    0/   28]\n",
      "loss: 0.032728  [    0/   28]\n",
      "loss: 0.032722  [    0/   28]\n",
      "loss: 0.032715  [    0/   28]\n",
      "loss: 0.032710  [    0/   28]\n",
      "loss: 0.032703  [    0/   28]\n",
      "loss: 0.032696  [    0/   28]\n",
      "loss: 0.032690  [    0/   28]\n",
      "loss: 0.032683  [    0/   28]\n",
      "loss: 0.032677  [    0/   28]\n",
      "loss: 0.032671  [    0/   28]\n",
      "loss: 0.032664  [    0/   28]\n",
      "loss: 0.032658  [    0/   28]\n",
      "loss: 0.032651  [    0/   28]\n",
      "loss: 0.032645  [    0/   28]\n",
      "loss: 0.032638  [    0/   28]\n",
      "loss: 0.032632  [    0/   28]\n",
      "loss: 0.032625  [    0/   28]\n",
      "loss: 0.032619  [    0/   28]\n",
      "loss: 0.032613  [    0/   28]\n",
      "loss: 0.032606  [    0/   28]\n",
      "loss: 0.032600  [    0/   28]\n",
      "loss: 0.032594  [    0/   28]\n",
      "loss: 0.032587  [    0/   28]\n",
      "loss: 0.032580  [    0/   28]\n",
      "loss: 0.032574  [    0/   28]\n",
      "loss: 0.032567  [    0/   28]\n",
      "loss: 0.032561  [    0/   28]\n",
      "loss: 0.032555  [    0/   28]\n",
      "loss: 0.032549  [    0/   28]\n",
      "loss: 0.032542  [    0/   28]\n",
      "loss: 0.032536  [    0/   28]\n",
      "loss: 0.032529  [    0/   28]\n",
      "loss: 0.032523  [    0/   28]\n",
      "loss: 0.032517  [    0/   28]\n",
      "loss: 0.032510  [    0/   28]\n",
      "loss: 0.032504  [    0/   28]\n",
      "loss: 0.032497  [    0/   28]\n",
      "loss: 0.032491  [    0/   28]\n",
      "loss: 0.032485  [    0/   28]\n",
      "loss: 0.032478  [    0/   28]\n",
      "loss: 0.032472  [    0/   28]\n",
      "loss: 0.032465  [    0/   28]\n",
      "loss: 0.032459  [    0/   28]\n",
      "loss: 0.032453  [    0/   28]\n",
      "loss: 0.032446  [    0/   28]\n",
      "loss: 0.032440  [    0/   28]\n",
      "loss: 0.032433  [    0/   28]\n",
      "loss: 0.032428  [    0/   28]\n",
      "loss: 0.032421  [    0/   28]\n",
      "loss: 0.032414  [    0/   28]\n",
      "loss: 0.032408  [    0/   28]\n",
      "loss: 0.032402  [    0/   28]\n",
      "loss: 0.032396  [    0/   28]\n",
      "loss: 0.032389  [    0/   28]\n",
      "loss: 0.032383  [    0/   28]\n",
      "loss: 0.032377  [    0/   28]\n",
      "loss: 0.032370  [    0/   28]\n",
      "loss: 0.032364  [    0/   28]\n",
      "loss: 0.032357  [    0/   28]\n",
      "loss: 0.032351  [    0/   28]\n",
      "loss: 0.032345  [    0/   28]\n",
      "loss: 0.032339  [    0/   28]\n",
      "loss: 0.032332  [    0/   28]\n",
      "loss: 0.032326  [    0/   28]\n",
      "loss: 0.032320  [    0/   28]\n",
      "loss: 0.032313  [    0/   28]\n",
      "loss: 0.032307  [    0/   28]\n",
      "loss: 0.032301  [    0/   28]\n",
      "loss: 0.032294  [    0/   28]\n",
      "loss: 0.032288  [    0/   28]\n",
      "loss: 0.032282  [    0/   28]\n",
      "loss: 0.032275  [    0/   28]\n",
      "loss: 0.032269  [    0/   28]\n",
      "loss: 0.032263  [    0/   28]\n",
      "loss: 0.032256  [    0/   28]\n",
      "loss: 0.032250  [    0/   28]\n",
      "loss: 0.032244  [    0/   28]\n",
      "loss: 0.032238  [    0/   28]\n",
      "loss: 0.032231  [    0/   28]\n",
      "loss: 0.032225  [    0/   28]\n",
      "loss: 0.032219  [    0/   28]\n",
      "loss: 0.032212  [    0/   28]\n",
      "loss: 0.032206  [    0/   28]\n",
      "loss: 0.032200  [    0/   28]\n",
      "loss: 0.032194  [    0/   28]\n",
      "loss: 0.032187  [    0/   28]\n",
      "loss: 0.032181  [    0/   28]\n",
      "loss: 0.032175  [    0/   28]\n",
      "loss: 0.032168  [    0/   28]\n",
      "loss: 0.032162  [    0/   28]\n",
      "loss: 0.032156  [    0/   28]\n",
      "loss: 0.032150  [    0/   28]\n",
      "loss: 0.032144  [    0/   28]\n",
      "loss: 0.032137  [    0/   28]\n",
      "loss: 0.032131  [    0/   28]\n",
      "loss: 0.032125  [    0/   28]\n",
      "loss: 0.032118  [    0/   28]\n",
      "loss: 0.032112  [    0/   28]\n",
      "loss: 0.032106  [    0/   28]\n",
      "loss: 0.032100  [    0/   28]\n",
      "loss: 0.032093  [    0/   28]\n",
      "loss: 0.032087  [    0/   28]\n",
      "loss: 0.032081  [    0/   28]\n",
      "loss: 0.032075  [    0/   28]\n",
      "loss: 0.032068  [    0/   28]\n",
      "loss: 0.032062  [    0/   28]\n",
      "loss: 0.032056  [    0/   28]\n",
      "loss: 0.032050  [    0/   28]\n",
      "loss: 0.032043  [    0/   28]\n",
      "loss: 0.032037  [    0/   28]\n",
      "loss: 0.032031  [    0/   28]\n",
      "loss: 0.032025  [    0/   28]\n",
      "loss: 0.032018  [    0/   28]\n",
      "loss: 0.032012  [    0/   28]\n",
      "loss: 0.032006  [    0/   28]\n",
      "loss: 0.032000  [    0/   28]\n",
      "loss: 0.031993  [    0/   28]\n",
      "loss: 0.031988  [    0/   28]\n",
      "loss: 0.031981  [    0/   28]\n",
      "loss: 0.031975  [    0/   28]\n",
      "loss: 0.031969  [    0/   28]\n",
      "loss: 0.031963  [    0/   28]\n",
      "loss: 0.031956  [    0/   28]\n",
      "loss: 0.031950  [    0/   28]\n",
      "loss: 0.031944  [    0/   28]\n",
      "loss: 0.031938  [    0/   28]\n",
      "loss: 0.031932  [    0/   28]\n",
      "loss: 0.031926  [    0/   28]\n",
      "loss: 0.031919  [    0/   28]\n",
      "loss: 0.031913  [    0/   28]\n",
      "loss: 0.031907  [    0/   28]\n",
      "loss: 0.031901  [    0/   28]\n",
      "loss: 0.031894  [    0/   28]\n",
      "loss: 0.031889  [    0/   28]\n",
      "loss: 0.031882  [    0/   28]\n",
      "loss: 0.031876  [    0/   28]\n",
      "loss: 0.031870  [    0/   28]\n",
      "loss: 0.031864  [    0/   28]\n",
      "loss: 0.031857  [    0/   28]\n",
      "loss: 0.031851  [    0/   28]\n",
      "loss: 0.031845  [    0/   28]\n",
      "loss: 0.031839  [    0/   28]\n",
      "loss: 0.031833  [    0/   28]\n",
      "loss: 0.031827  [    0/   28]\n",
      "loss: 0.031821  [    0/   28]\n",
      "loss: 0.031814  [    0/   28]\n",
      "loss: 0.031808  [    0/   28]\n",
      "loss: 0.031802  [    0/   28]\n",
      "loss: 0.031796  [    0/   28]\n",
      "loss: 0.031790  [    0/   28]\n",
      "loss: 0.031783  [    0/   28]\n",
      "loss: 0.031777  [    0/   28]\n",
      "loss: 0.031771  [    0/   28]\n",
      "loss: 0.031765  [    0/   28]\n",
      "loss: 0.031759  [    0/   28]\n",
      "loss: 0.031753  [    0/   28]\n",
      "loss: 0.031747  [    0/   28]\n",
      "loss: 0.031740  [    0/   28]\n",
      "loss: 0.031734  [    0/   28]\n",
      "loss: 0.031728  [    0/   28]\n",
      "loss: 0.031722  [    0/   28]\n",
      "loss: 0.031716  [    0/   28]\n",
      "loss: 0.031710  [    0/   28]\n",
      "loss: 0.031704  [    0/   28]\n",
      "loss: 0.031698  [    0/   28]\n",
      "loss: 0.031691  [    0/   28]\n",
      "loss: 0.031685  [    0/   28]\n",
      "loss: 0.031679  [    0/   28]\n",
      "loss: 0.031673  [    0/   28]\n",
      "loss: 0.031667  [    0/   28]\n",
      "loss: 0.031661  [    0/   28]\n",
      "loss: 0.031655  [    0/   28]\n",
      "loss: 0.031649  [    0/   28]\n",
      "loss: 0.031643  [    0/   28]\n",
      "loss: 0.031637  [    0/   28]\n",
      "loss: 0.031630  [    0/   28]\n",
      "loss: 0.031624  [    0/   28]\n",
      "loss: 0.031618  [    0/   28]\n",
      "loss: 0.031612  [    0/   28]\n",
      "loss: 0.031606  [    0/   28]\n",
      "loss: 0.031600  [    0/   28]\n",
      "loss: 0.031594  [    0/   28]\n",
      "loss: 0.031588  [    0/   28]\n",
      "loss: 0.031582  [    0/   28]\n",
      "loss: 0.031575  [    0/   28]\n",
      "loss: 0.031569  [    0/   28]\n",
      "loss: 0.031564  [    0/   28]\n",
      "loss: 0.031557  [    0/   28]\n",
      "loss: 0.031551  [    0/   28]\n",
      "loss: 0.031545  [    0/   28]\n",
      "loss: 0.031539  [    0/   28]\n",
      "loss: 0.031533  [    0/   28]\n",
      "loss: 0.031527  [    0/   28]\n",
      "loss: 0.031521  [    0/   28]\n",
      "loss: 0.031515  [    0/   28]\n",
      "loss: 0.031509  [    0/   28]\n",
      "loss: 0.031503  [    0/   28]\n",
      "loss: 0.031497  [    0/   28]\n",
      "loss: 0.031491  [    0/   28]\n",
      "loss: 0.031485  [    0/   28]\n",
      "loss: 0.031479  [    0/   28]\n",
      "loss: 0.031473  [    0/   28]\n",
      "loss: 0.031467  [    0/   28]\n",
      "loss: 0.031461  [    0/   28]\n",
      "loss: 0.031454  [    0/   28]\n",
      "loss: 0.031449  [    0/   28]\n",
      "loss: 0.031442  [    0/   28]\n",
      "loss: 0.031436  [    0/   28]\n",
      "loss: 0.031430  [    0/   28]\n",
      "loss: 0.031424  [    0/   28]\n",
      "loss: 0.031418  [    0/   28]\n",
      "loss: 0.031412  [    0/   28]\n",
      "loss: 0.031406  [    0/   28]\n",
      "loss: 0.031400  [    0/   28]\n",
      "loss: 0.031394  [    0/   28]\n",
      "loss: 0.031388  [    0/   28]\n",
      "loss: 0.031382  [    0/   28]\n",
      "loss: 0.031376  [    0/   28]\n",
      "loss: 0.031370  [    0/   28]\n",
      "loss: 0.031364  [    0/   28]\n",
      "loss: 0.031358  [    0/   28]\n",
      "loss: 0.031352  [    0/   28]\n",
      "loss: 0.031346  [    0/   28]\n",
      "loss: 0.031340  [    0/   28]\n",
      "loss: 0.031334  [    0/   28]\n",
      "loss: 0.031328  [    0/   28]\n",
      "loss: 0.031322  [    0/   28]\n",
      "loss: 0.031316  [    0/   28]\n",
      "loss: 0.031310  [    0/   28]\n",
      "loss: 0.031304  [    0/   28]\n",
      "loss: 0.031298  [    0/   28]\n",
      "loss: 0.031292  [    0/   28]\n",
      "loss: 0.031286  [    0/   28]\n",
      "loss: 0.031280  [    0/   28]\n",
      "loss: 0.031274  [    0/   28]\n",
      "loss: 0.031268  [    0/   28]\n",
      "loss: 0.031262  [    0/   28]\n",
      "loss: 0.031256  [    0/   28]\n",
      "loss: 0.031250  [    0/   28]\n",
      "loss: 0.031244  [    0/   28]\n",
      "loss: 0.031238  [    0/   28]\n",
      "loss: 0.031232  [    0/   28]\n",
      "loss: 0.031226  [    0/   28]\n",
      "loss: 0.031220  [    0/   28]\n",
      "loss: 0.031215  [    0/   28]\n",
      "loss: 0.031208  [    0/   28]\n",
      "loss: 0.031202  [    0/   28]\n",
      "loss: 0.031197  [    0/   28]\n",
      "loss: 0.031191  [    0/   28]\n",
      "loss: 0.031185  [    0/   28]\n",
      "loss: 0.031178  [    0/   28]\n",
      "loss: 0.031173  [    0/   28]\n",
      "loss: 0.031167  [    0/   28]\n",
      "loss: 0.031161  [    0/   28]\n",
      "loss: 0.031155  [    0/   28]\n",
      "loss: 0.031149  [    0/   28]\n",
      "loss: 0.031143  [    0/   28]\n",
      "loss: 0.031137  [    0/   28]\n",
      "loss: 0.031131  [    0/   28]\n",
      "loss: 0.031125  [    0/   28]\n",
      "loss: 0.031119  [    0/   28]\n",
      "loss: 0.031113  [    0/   28]\n",
      "loss: 0.031107  [    0/   28]\n",
      "loss: 0.031101  [    0/   28]\n",
      "loss: 0.031095  [    0/   28]\n",
      "loss: 0.031089  [    0/   28]\n",
      "loss: 0.031084  [    0/   28]\n",
      "loss: 0.031078  [    0/   28]\n",
      "loss: 0.031072  [    0/   28]\n",
      "loss: 0.031066  [    0/   28]\n",
      "loss: 0.031060  [    0/   28]\n",
      "loss: 0.031054  [    0/   28]\n",
      "loss: 0.031048  [    0/   28]\n",
      "loss: 0.031042  [    0/   28]\n",
      "loss: 0.031036  [    0/   28]\n",
      "loss: 0.031030  [    0/   28]\n",
      "loss: 0.031024  [    0/   28]\n",
      "loss: 0.031018  [    0/   28]\n",
      "loss: 0.031013  [    0/   28]\n",
      "loss: 0.031007  [    0/   28]\n",
      "loss: 0.031001  [    0/   28]\n",
      "loss: 0.030995  [    0/   28]\n",
      "loss: 0.030989  [    0/   28]\n",
      "loss: 0.030983  [    0/   28]\n",
      "loss: 0.030977  [    0/   28]\n",
      "loss: 0.030971  [    0/   28]\n",
      "loss: 0.030965  [    0/   28]\n",
      "loss: 0.030960  [    0/   28]\n",
      "loss: 0.030954  [    0/   28]\n",
      "loss: 0.030948  [    0/   28]\n",
      "loss: 0.030942  [    0/   28]\n",
      "loss: 0.030936  [    0/   28]\n",
      "loss: 0.030930  [    0/   28]\n",
      "loss: 0.030925  [    0/   28]\n",
      "loss: 0.030918  [    0/   28]\n",
      "loss: 0.030913  [    0/   28]\n",
      "loss: 0.030907  [    0/   28]\n",
      "loss: 0.030901  [    0/   28]\n",
      "loss: 0.030895  [    0/   28]\n",
      "loss: 0.030889  [    0/   28]\n",
      "loss: 0.030883  [    0/   28]\n",
      "loss: 0.030878  [    0/   28]\n",
      "loss: 0.030871  [    0/   28]\n",
      "loss: 0.030866  [    0/   28]\n",
      "loss: 0.030860  [    0/   28]\n",
      "loss: 0.030854  [    0/   28]\n",
      "loss: 0.030848  [    0/   28]\n",
      "loss: 0.030842  [    0/   28]\n",
      "loss: 0.030837  [    0/   28]\n",
      "loss: 0.030831  [    0/   28]\n",
      "loss: 0.030825  [    0/   28]\n",
      "loss: 0.030819  [    0/   28]\n",
      "loss: 0.030813  [    0/   28]\n",
      "loss: 0.030807  [    0/   28]\n",
      "loss: 0.030801  [    0/   28]\n",
      "loss: 0.030796  [    0/   28]\n",
      "loss: 0.030790  [    0/   28]\n",
      "loss: 0.030784  [    0/   28]\n",
      "loss: 0.030778  [    0/   28]\n",
      "loss: 0.030772  [    0/   28]\n",
      "loss: 0.030766  [    0/   28]\n",
      "loss: 0.030761  [    0/   28]\n",
      "loss: 0.030755  [    0/   28]\n",
      "loss: 0.030749  [    0/   28]\n",
      "loss: 0.030743  [    0/   28]\n",
      "loss: 0.030737  [    0/   28]\n",
      "loss: 0.030732  [    0/   28]\n",
      "loss: 0.030726  [    0/   28]\n",
      "loss: 0.030720  [    0/   28]\n",
      "loss: 0.030714  [    0/   28]\n",
      "loss: 0.030708  [    0/   28]\n",
      "loss: 0.030702  [    0/   28]\n",
      "loss: 0.030697  [    0/   28]\n",
      "loss: 0.030691  [    0/   28]\n",
      "loss: 0.030685  [    0/   28]\n",
      "loss: 0.030679  [    0/   28]\n",
      "loss: 0.030674  [    0/   28]\n",
      "loss: 0.030668  [    0/   28]\n",
      "loss: 0.030662  [    0/   28]\n",
      "loss: 0.030656  [    0/   28]\n",
      "loss: 0.030650  [    0/   28]\n",
      "loss: 0.030644  [    0/   28]\n",
      "loss: 0.030639  [    0/   28]\n",
      "loss: 0.030633  [    0/   28]\n",
      "loss: 0.030627  [    0/   28]\n",
      "loss: 0.030621  [    0/   28]\n",
      "loss: 0.030616  [    0/   28]\n",
      "loss: 0.030610  [    0/   28]\n",
      "loss: 0.030604  [    0/   28]\n",
      "loss: 0.030598  [    0/   28]\n",
      "loss: 0.030593  [    0/   28]\n",
      "loss: 0.030587  [    0/   28]\n",
      "loss: 0.030581  [    0/   28]\n",
      "loss: 0.030576  [    0/   28]\n",
      "loss: 0.030570  [    0/   28]\n",
      "loss: 0.030564  [    0/   28]\n",
      "loss: 0.030558  [    0/   28]\n",
      "loss: 0.030552  [    0/   28]\n",
      "loss: 0.030547  [    0/   28]\n",
      "loss: 0.030541  [    0/   28]\n",
      "loss: 0.030535  [    0/   28]\n",
      "loss: 0.030529  [    0/   28]\n",
      "loss: 0.030523  [    0/   28]\n",
      "loss: 0.030518  [    0/   28]\n",
      "loss: 0.030512  [    0/   28]\n",
      "loss: 0.030506  [    0/   28]\n",
      "loss: 0.030500  [    0/   28]\n",
      "loss: 0.030495  [    0/   28]\n",
      "loss: 0.030489  [    0/   28]\n",
      "loss: 0.030483  [    0/   28]\n",
      "loss: 0.030478  [    0/   28]\n",
      "loss: 0.030472  [    0/   28]\n",
      "loss: 0.030466  [    0/   28]\n",
      "loss: 0.030460  [    0/   28]\n",
      "loss: 0.030455  [    0/   28]\n",
      "loss: 0.030449  [    0/   28]\n",
      "loss: 0.030443  [    0/   28]\n",
      "loss: 0.030438  [    0/   28]\n",
      "loss: 0.030432  [    0/   28]\n",
      "loss: 0.030426  [    0/   28]\n",
      "loss: 0.030420  [    0/   28]\n",
      "loss: 0.030414  [    0/   28]\n",
      "loss: 0.030409  [    0/   28]\n",
      "loss: 0.030403  [    0/   28]\n",
      "loss: 0.030397  [    0/   28]\n",
      "loss: 0.030392  [    0/   28]\n",
      "loss: 0.030386  [    0/   28]\n",
      "loss: 0.030380  [    0/   28]\n",
      "loss: 0.030375  [    0/   28]\n",
      "loss: 0.030369  [    0/   28]\n",
      "loss: 0.030363  [    0/   28]\n",
      "loss: 0.030358  [    0/   28]\n",
      "loss: 0.030352  [    0/   28]\n",
      "loss: 0.030346  [    0/   28]\n",
      "loss: 0.030340  [    0/   28]\n",
      "loss: 0.030335  [    0/   28]\n",
      "loss: 0.030329  [    0/   28]\n",
      "loss: 0.030323  [    0/   28]\n",
      "loss: 0.030318  [    0/   28]\n",
      "loss: 0.030312  [    0/   28]\n",
      "loss: 0.030306  [    0/   28]\n",
      "loss: 0.030301  [    0/   28]\n",
      "loss: 0.030295  [    0/   28]\n",
      "loss: 0.030289  [    0/   28]\n",
      "loss: 0.030283  [    0/   28]\n",
      "loss: 0.030278  [    0/   28]\n",
      "loss: 0.030272  [    0/   28]\n",
      "loss: 0.030267  [    0/   28]\n",
      "loss: 0.030261  [    0/   28]\n",
      "loss: 0.030255  [    0/   28]\n",
      "loss: 0.030250  [    0/   28]\n",
      "loss: 0.030244  [    0/   28]\n",
      "loss: 0.030238  [    0/   28]\n",
      "loss: 0.030233  [    0/   28]\n",
      "loss: 0.030227  [    0/   28]\n",
      "loss: 0.030221  [    0/   28]\n",
      "loss: 0.030216  [    0/   28]\n",
      "loss: 0.030210  [    0/   28]\n",
      "loss: 0.030204  [    0/   28]\n",
      "loss: 0.030199  [    0/   28]\n",
      "loss: 0.030193  [    0/   28]\n",
      "loss: 0.030188  [    0/   28]\n",
      "loss: 0.030182  [    0/   28]\n",
      "loss: 0.030176  [    0/   28]\n",
      "loss: 0.030171  [    0/   28]\n",
      "loss: 0.030165  [    0/   28]\n",
      "loss: 0.030159  [    0/   28]\n",
      "loss: 0.030154  [    0/   28]\n",
      "loss: 0.030148  [    0/   28]\n",
      "loss: 0.030142  [    0/   28]\n",
      "loss: 0.030137  [    0/   28]\n",
      "loss: 0.030131  [    0/   28]\n",
      "loss: 0.030126  [    0/   28]\n",
      "loss: 0.030120  [    0/   28]\n",
      "loss: 0.030114  [    0/   28]\n",
      "loss: 0.030109  [    0/   28]\n",
      "loss: 0.030103  [    0/   28]\n",
      "loss: 0.030097  [    0/   28]\n",
      "loss: 0.030092  [    0/   28]\n",
      "loss: 0.030086  [    0/   28]\n",
      "loss: 0.030081  [    0/   28]\n",
      "loss: 0.030075  [    0/   28]\n",
      "loss: 0.030070  [    0/   28]\n",
      "loss: 0.030064  [    0/   28]\n",
      "loss: 0.030058  [    0/   28]\n",
      "loss: 0.030053  [    0/   28]\n",
      "loss: 0.030047  [    0/   28]\n",
      "loss: 0.030041  [    0/   28]\n",
      "loss: 0.030036  [    0/   28]\n",
      "loss: 0.030030  [    0/   28]\n",
      "loss: 0.030024  [    0/   28]\n",
      "loss: 0.030019  [    0/   28]\n",
      "loss: 0.030014  [    0/   28]\n",
      "loss: 0.030008  [    0/   28]\n",
      "loss: 0.030002  [    0/   28]\n",
      "loss: 0.029997  [    0/   28]\n",
      "loss: 0.029991  [    0/   28]\n",
      "loss: 0.029986  [    0/   28]\n",
      "loss: 0.029980  [    0/   28]\n",
      "loss: 0.029974  [    0/   28]\n",
      "loss: 0.029969  [    0/   28]\n",
      "loss: 0.029963  [    0/   28]\n",
      "loss: 0.029958  [    0/   28]\n",
      "loss: 0.029952  [    0/   28]\n",
      "loss: 0.029947  [    0/   28]\n",
      "loss: 0.029941  [    0/   28]\n",
      "loss: 0.029936  [    0/   28]\n",
      "loss: 0.029930  [    0/   28]\n",
      "loss: 0.029924  [    0/   28]\n",
      "loss: 0.029919  [    0/   28]\n",
      "loss: 0.029913  [    0/   28]\n",
      "loss: 0.029908  [    0/   28]\n",
      "loss: 0.029902  [    0/   28]\n",
      "loss: 0.029896  [    0/   28]\n",
      "loss: 0.029891  [    0/   28]\n",
      "loss: 0.029886  [    0/   28]\n",
      "loss: 0.029880  [    0/   28]\n",
      "loss: 0.029874  [    0/   28]\n",
      "loss: 0.029869  [    0/   28]\n",
      "loss: 0.029863  [    0/   28]\n",
      "loss: 0.029858  [    0/   28]\n",
      "loss: 0.029852  [    0/   28]\n",
      "loss: 0.029847  [    0/   28]\n",
      "loss: 0.029841  [    0/   28]\n",
      "loss: 0.029835  [    0/   28]\n",
      "loss: 0.029830  [    0/   28]\n",
      "loss: 0.029825  [    0/   28]\n",
      "loss: 0.029819  [    0/   28]\n",
      "loss: 0.029813  [    0/   28]\n",
      "loss: 0.029808  [    0/   28]\n",
      "loss: 0.029803  [    0/   28]\n",
      "loss: 0.029797  [    0/   28]\n",
      "loss: 0.029791  [    0/   28]\n",
      "loss: 0.029786  [    0/   28]\n",
      "loss: 0.029780  [    0/   28]\n",
      "loss: 0.029775  [    0/   28]\n",
      "loss: 0.029769  [    0/   28]\n",
      "loss: 0.029764  [    0/   28]\n",
      "loss: 0.029758  [    0/   28]\n",
      "loss: 0.029753  [    0/   28]\n",
      "loss: 0.029747  [    0/   28]\n",
      "loss: 0.029742  [    0/   28]\n",
      "loss: 0.029736  [    0/   28]\n",
      "loss: 0.029731  [    0/   28]\n",
      "loss: 0.029725  [    0/   28]\n",
      "loss: 0.029720  [    0/   28]\n",
      "loss: 0.029714  [    0/   28]\n",
      "loss: 0.029709  [    0/   28]\n",
      "loss: 0.029703  [    0/   28]\n",
      "loss: 0.029698  [    0/   28]\n",
      "loss: 0.029692  [    0/   28]\n",
      "loss: 0.029687  [    0/   28]\n",
      "loss: 0.029681  [    0/   28]\n",
      "loss: 0.029676  [    0/   28]\n",
      "loss: 0.029670  [    0/   28]\n",
      "loss: 0.029665  [    0/   28]\n",
      "loss: 0.029660  [    0/   28]\n",
      "loss: 0.029654  [    0/   28]\n",
      "loss: 0.029648  [    0/   28]\n",
      "loss: 0.029643  [    0/   28]\n",
      "loss: 0.029638  [    0/   28]\n",
      "loss: 0.029632  [    0/   28]\n",
      "loss: 0.029627  [    0/   28]\n",
      "loss: 0.029621  [    0/   28]\n",
      "loss: 0.029616  [    0/   28]\n",
      "loss: 0.029610  [    0/   28]\n",
      "loss: 0.029605  [    0/   28]\n",
      "loss: 0.029599  [    0/   28]\n",
      "loss: 0.029594  [    0/   28]\n",
      "loss: 0.029588  [    0/   28]\n",
      "loss: 0.029583  [    0/   28]\n",
      "loss: 0.029578  [    0/   28]\n",
      "loss: 0.029572  [    0/   28]\n",
      "loss: 0.029567  [    0/   28]\n",
      "loss: 0.029561  [    0/   28]\n",
      "loss: 0.029556  [    0/   28]\n",
      "loss: 0.029550  [    0/   28]\n",
      "loss: 0.029545  [    0/   28]\n",
      "loss: 0.029540  [    0/   28]\n",
      "loss: 0.029534  [    0/   28]\n",
      "loss: 0.029528  [    0/   28]\n",
      "loss: 0.029523  [    0/   28]\n",
      "loss: 0.029518  [    0/   28]\n",
      "loss: 0.029512  [    0/   28]\n",
      "loss: 0.029507  [    0/   28]\n",
      "loss: 0.029501  [    0/   28]\n",
      "loss: 0.029496  [    0/   28]\n",
      "loss: 0.029490  [    0/   28]\n",
      "loss: 0.029485  [    0/   28]\n",
      "loss: 0.029480  [    0/   28]\n",
      "loss: 0.029474  [    0/   28]\n",
      "loss: 0.029469  [    0/   28]\n",
      "loss: 0.029463  [    0/   28]\n",
      "loss: 0.029458  [    0/   28]\n",
      "loss: 0.029452  [    0/   28]\n",
      "loss: 0.029447  [    0/   28]\n",
      "loss: 0.029442  [    0/   28]\n",
      "loss: 0.029436  [    0/   28]\n",
      "loss: 0.029431  [    0/   28]\n",
      "loss: 0.029426  [    0/   28]\n",
      "loss: 0.029420  [    0/   28]\n",
      "loss: 0.029415  [    0/   28]\n",
      "loss: 0.029409  [    0/   28]\n",
      "loss: 0.029404  [    0/   28]\n",
      "loss: 0.029399  [    0/   28]\n",
      "loss: 0.029393  [    0/   28]\n",
      "loss: 0.029388  [    0/   28]\n",
      "loss: 0.029382  [    0/   28]\n",
      "loss: 0.029377  [    0/   28]\n",
      "loss: 0.029372  [    0/   28]\n",
      "loss: 0.029366  [    0/   28]\n",
      "loss: 0.029361  [    0/   28]\n",
      "loss: 0.029355  [    0/   28]\n",
      "loss: 0.029350  [    0/   28]\n",
      "loss: 0.029345  [    0/   28]\n",
      "loss: 0.029339  [    0/   28]\n",
      "loss: 0.029334  [    0/   28]\n",
      "loss: 0.029328  [    0/   28]\n",
      "loss: 0.029323  [    0/   28]\n",
      "loss: 0.029318  [    0/   28]\n",
      "loss: 0.029312  [    0/   28]\n",
      "loss: 0.029307  [    0/   28]\n",
      "loss: 0.029302  [    0/   28]\n",
      "loss: 0.029296  [    0/   28]\n",
      "loss: 0.029291  [    0/   28]\n",
      "loss: 0.029285  [    0/   28]\n",
      "loss: 0.029280  [    0/   28]\n",
      "loss: 0.029274  [    0/   28]\n",
      "loss: 0.029269  [    0/   28]\n",
      "loss: 0.029264  [    0/   28]\n",
      "loss: 0.029259  [    0/   28]\n",
      "loss: 0.029253  [    0/   28]\n",
      "loss: 0.029248  [    0/   28]\n",
      "loss: 0.029242  [    0/   28]\n",
      "loss: 0.029237  [    0/   28]\n",
      "loss: 0.029232  [    0/   28]\n",
      "loss: 0.029227  [    0/   28]\n",
      "loss: 0.029221  [    0/   28]\n",
      "loss: 0.029216  [    0/   28]\n",
      "loss: 0.029210  [    0/   28]\n",
      "loss: 0.029205  [    0/   28]\n",
      "loss: 0.029200  [    0/   28]\n",
      "loss: 0.029195  [    0/   28]\n",
      "loss: 0.029189  [    0/   28]\n",
      "loss: 0.029184  [    0/   28]\n",
      "loss: 0.029179  [    0/   28]\n",
      "loss: 0.029173  [    0/   28]\n",
      "loss: 0.029168  [    0/   28]\n",
      "loss: 0.029162  [    0/   28]\n",
      "loss: 0.029157  [    0/   28]\n",
      "loss: 0.029152  [    0/   28]\n",
      "loss: 0.029147  [    0/   28]\n",
      "loss: 0.029141  [    0/   28]\n",
      "loss: 0.029136  [    0/   28]\n",
      "loss: 0.029130  [    0/   28]\n",
      "loss: 0.029125  [    0/   28]\n",
      "loss: 0.029120  [    0/   28]\n",
      "loss: 0.029115  [    0/   28]\n",
      "loss: 0.029109  [    0/   28]\n",
      "loss: 0.029104  [    0/   28]\n",
      "loss: 0.029099  [    0/   28]\n",
      "loss: 0.029094  [    0/   28]\n",
      "loss: 0.029088  [    0/   28]\n",
      "loss: 0.029083  [    0/   28]\n",
      "loss: 0.029078  [    0/   28]\n",
      "loss: 0.029072  [    0/   28]\n",
      "loss: 0.029067  [    0/   28]\n",
      "loss: 0.029062  [    0/   28]\n",
      "loss: 0.029057  [    0/   28]\n",
      "loss: 0.029051  [    0/   28]\n",
      "loss: 0.029046  [    0/   28]\n",
      "loss: 0.029040  [    0/   28]\n",
      "loss: 0.029035  [    0/   28]\n",
      "loss: 0.029030  [    0/   28]\n",
      "loss: 0.029025  [    0/   28]\n",
      "loss: 0.029019  [    0/   28]\n",
      "loss: 0.029014  [    0/   28]\n",
      "loss: 0.029009  [    0/   28]\n",
      "loss: 0.029004  [    0/   28]\n",
      "loss: 0.028999  [    0/   28]\n",
      "loss: 0.028993  [    0/   28]\n",
      "loss: 0.028988  [    0/   28]\n",
      "loss: 0.028982  [    0/   28]\n",
      "loss: 0.028977  [    0/   28]\n",
      "loss: 0.028972  [    0/   28]\n",
      "loss: 0.028967  [    0/   28]\n",
      "loss: 0.028961  [    0/   28]\n",
      "loss: 0.028956  [    0/   28]\n",
      "loss: 0.028951  [    0/   28]\n",
      "loss: 0.028946  [    0/   28]\n",
      "loss: 0.028940  [    0/   28]\n",
      "loss: 0.028935  [    0/   28]\n",
      "loss: 0.028930  [    0/   28]\n",
      "loss: 0.028925  [    0/   28]\n",
      "loss: 0.028920  [    0/   28]\n",
      "loss: 0.028914  [    0/   28]\n",
      "loss: 0.028909  [    0/   28]\n",
      "loss: 0.028904  [    0/   28]\n",
      "loss: 0.028899  [    0/   28]\n",
      "loss: 0.028893  [    0/   28]\n",
      "loss: 0.028888  [    0/   28]\n",
      "loss: 0.028883  [    0/   28]\n",
      "loss: 0.028878  [    0/   28]\n",
      "loss: 0.028872  [    0/   28]\n",
      "loss: 0.028867  [    0/   28]\n",
      "loss: 0.028862  [    0/   28]\n",
      "loss: 0.028856  [    0/   28]\n",
      "loss: 0.028851  [    0/   28]\n",
      "loss: 0.028846  [    0/   28]\n",
      "loss: 0.028841  [    0/   28]\n",
      "loss: 0.028836  [    0/   28]\n",
      "loss: 0.028830  [    0/   28]\n",
      "loss: 0.028825  [    0/   28]\n",
      "loss: 0.028820  [    0/   28]\n",
      "loss: 0.028815  [    0/   28]\n",
      "loss: 0.028810  [    0/   28]\n",
      "loss: 0.028805  [    0/   28]\n",
      "loss: 0.028799  [    0/   28]\n",
      "loss: 0.028794  [    0/   28]\n",
      "loss: 0.028789  [    0/   28]\n",
      "loss: 0.028784  [    0/   28]\n",
      "loss: 0.028778  [    0/   28]\n",
      "loss: 0.028773  [    0/   28]\n",
      "loss: 0.028768  [    0/   28]\n",
      "loss: 0.028763  [    0/   28]\n",
      "loss: 0.028758  [    0/   28]\n",
      "loss: 0.028752  [    0/   28]\n",
      "loss: 0.028747  [    0/   28]\n",
      "loss: 0.028742  [    0/   28]\n",
      "loss: 0.028737  [    0/   28]\n",
      "loss: 0.028732  [    0/   28]\n",
      "loss: 0.028727  [    0/   28]\n",
      "loss: 0.028721  [    0/   28]\n",
      "loss: 0.028716  [    0/   28]\n",
      "loss: 0.028711  [    0/   28]\n",
      "loss: 0.028706  [    0/   28]\n",
      "loss: 0.028701  [    0/   28]\n",
      "loss: 0.028695  [    0/   28]\n",
      "loss: 0.028690  [    0/   28]\n",
      "loss: 0.028685  [    0/   28]\n",
      "loss: 0.028680  [    0/   28]\n",
      "loss: 0.028674  [    0/   28]\n",
      "loss: 0.028670  [    0/   28]\n",
      "loss: 0.028664  [    0/   28]\n",
      "loss: 0.028659  [    0/   28]\n",
      "loss: 0.028654  [    0/   28]\n",
      "loss: 0.028649  [    0/   28]\n",
      "loss: 0.028644  [    0/   28]\n",
      "loss: 0.028638  [    0/   28]\n",
      "loss: 0.028633  [    0/   28]\n",
      "loss: 0.028628  [    0/   28]\n",
      "loss: 0.028623  [    0/   28]\n",
      "loss: 0.028618  [    0/   28]\n",
      "loss: 0.028613  [    0/   28]\n",
      "loss: 0.028608  [    0/   28]\n",
      "loss: 0.028603  [    0/   28]\n",
      "loss: 0.028597  [    0/   28]\n",
      "loss: 0.028592  [    0/   28]\n",
      "loss: 0.028587  [    0/   28]\n",
      "loss: 0.028582  [    0/   28]\n",
      "loss: 0.028577  [    0/   28]\n",
      "loss: 0.028572  [    0/   28]\n",
      "loss: 0.028566  [    0/   28]\n",
      "loss: 0.028561  [    0/   28]\n",
      "loss: 0.028556  [    0/   28]\n",
      "loss: 0.028551  [    0/   28]\n",
      "loss: 0.028546  [    0/   28]\n",
      "loss: 0.028541  [    0/   28]\n",
      "loss: 0.028536  [    0/   28]\n",
      "loss: 0.028531  [    0/   28]\n",
      "loss: 0.028525  [    0/   28]\n",
      "loss: 0.028520  [    0/   28]\n",
      "loss: 0.028515  [    0/   28]\n",
      "loss: 0.028510  [    0/   28]\n",
      "loss: 0.028505  [    0/   28]\n",
      "loss: 0.028500  [    0/   28]\n",
      "loss: 0.028495  [    0/   28]\n",
      "loss: 0.028490  [    0/   28]\n",
      "loss: 0.028484  [    0/   28]\n",
      "loss: 0.028479  [    0/   28]\n",
      "loss: 0.028474  [    0/   28]\n",
      "loss: 0.028469  [    0/   28]\n",
      "loss: 0.028464  [    0/   28]\n",
      "loss: 0.028459  [    0/   28]\n",
      "loss: 0.028454  [    0/   28]\n",
      "loss: 0.028449  [    0/   28]\n",
      "loss: 0.028443  [    0/   28]\n",
      "loss: 0.028438  [    0/   28]\n",
      "loss: 0.028433  [    0/   28]\n",
      "loss: 0.028428  [    0/   28]\n",
      "loss: 0.028423  [    0/   28]\n",
      "loss: 0.028418  [    0/   28]\n",
      "loss: 0.028413  [    0/   28]\n",
      "loss: 0.028408  [    0/   28]\n",
      "loss: 0.028403  [    0/   28]\n",
      "loss: 0.028398  [    0/   28]\n",
      "loss: 0.028393  [    0/   28]\n",
      "loss: 0.028388  [    0/   28]\n",
      "loss: 0.028382  [    0/   28]\n",
      "loss: 0.028377  [    0/   28]\n",
      "loss: 0.028372  [    0/   28]\n",
      "loss: 0.028367  [    0/   28]\n",
      "loss: 0.028362  [    0/   28]\n",
      "loss: 0.028357  [    0/   28]\n",
      "loss: 0.028352  [    0/   28]\n",
      "loss: 0.028347  [    0/   28]\n",
      "loss: 0.028342  [    0/   28]\n",
      "loss: 0.028337  [    0/   28]\n",
      "loss: 0.028332  [    0/   28]\n",
      "loss: 0.028327  [    0/   28]\n",
      "loss: 0.028322  [    0/   28]\n",
      "loss: 0.028317  [    0/   28]\n",
      "loss: 0.028311  [    0/   28]\n",
      "loss: 0.028306  [    0/   28]\n",
      "loss: 0.028301  [    0/   28]\n",
      "loss: 0.028297  [    0/   28]\n",
      "loss: 0.028291  [    0/   28]\n",
      "Model structure: NeuralNetwork(\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=20, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=1, bias=True)\n",
      "    (3): Sigmoid()\n",
      "  )\n",
      ")\n",
      "\n",
      "\n",
      "Layer: linear_relu_stack.0.weight | Size: torch.Size([512, 20]) | Values : tensor([[ 0.0968,  0.0908, -0.1142, -0.2550,  0.1825,  0.0254,  0.0726, -0.1681,\n",
      "          0.0145,  0.0527, -0.0946,  0.0098,  0.1623,  0.1505, -0.1298,  0.0522,\n",
      "          0.1431,  0.0637, -0.1884, -0.0228],\n",
      "        [-0.1382,  0.1577,  0.1161, -0.1547, -0.0049, -0.0192, -0.3037,  0.1496,\n",
      "         -0.0058,  0.1348,  0.3016, -0.0022,  0.0982, -0.2565,  0.0144, -0.2168,\n",
      "         -0.1212,  0.1633, -0.2266, -0.1346]], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.0.bias | Size: torch.Size([512]) | Values : tensor([0.1045, 0.1403], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.2.weight | Size: torch.Size([1, 512]) | Values : tensor([[ 2.7584e-01, -4.3633e-01, -3.0448e-01, -1.0582e-01, -4.9612e-01,\n",
      "          1.4996e-01, -1.8974e-02, -4.7831e-01,  1.1907e-01, -5.3228e-02,\n",
      "          3.4786e-01,  5.5284e-02,  8.7259e-02, -9.5119e-03, -4.2197e-01,\n",
      "         -4.8195e-01,  6.8644e-02,  1.6204e-01,  3.7602e-02,  2.0128e-01,\n",
      "         -1.9567e-01, -7.2450e-02,  9.1152e-03,  1.7478e-01,  6.9502e-02,\n",
      "          1.0440e-01,  1.0444e-01,  1.1373e-01, -2.0145e-01,  1.8312e-01,\n",
      "          1.8150e-01, -7.9901e-02,  8.7931e-02,  2.2567e-01, -1.6919e-01,\n",
      "          6.6383e-02,  2.5212e-02,  2.5405e-01, -2.5109e-01, -1.6131e-01,\n",
      "         -1.0430e-01, -1.6143e-01, -1.4789e-01, -1.8681e-01,  3.0581e-03,\n",
      "          4.3275e-01, -3.0159e-01, -2.3470e-02,  5.5892e-01, -3.5574e-01,\n",
      "         -4.0767e-02, -6.0385e-02, -3.8179e-02,  1.4497e-01, -1.1580e-01,\n",
      "         -2.1143e-02,  4.1318e-01, -1.4992e-01, -3.0572e-02,  1.2684e-01,\n",
      "         -2.9372e-02, -1.3814e-01,  1.8500e-01,  4.2585e-02,  1.4119e-01,\n",
      "          1.8519e-01, -1.6793e-01,  2.4727e-01,  9.5692e-02,  3.0803e-01,\n",
      "         -2.9880e-01,  6.3669e-02,  3.4167e-01,  1.9364e-01,  7.6735e-03,\n",
      "         -6.3639e-01,  1.0719e-01, -1.5668e-01,  2.0367e-02,  1.7115e-01,\n",
      "         -2.5668e-01,  6.8287e-01, -1.1381e-01, -8.8448e-02, -8.2031e-02,\n",
      "          1.7745e-01, -1.5836e-01,  4.0850e-01, -4.0695e-01,  5.5337e-02,\n",
      "         -5.6706e-02,  4.4658e-01, -2.4870e-02, -4.4111e-01,  5.3674e-02,\n",
      "         -3.1738e-01, -2.8931e-01,  9.0866e-02,  8.6144e-02, -1.6350e-01,\n",
      "          2.4673e-01, -3.3864e-01, -4.3605e-01,  5.5338e-02,  2.7057e-01,\n",
      "         -2.0297e-01, -1.3885e-01, -2.3417e-01,  3.4669e-02, -3.0895e-01,\n",
      "          3.4419e-02,  3.5755e-01,  2.1553e-01,  1.6722e-01, -4.0835e-02,\n",
      "          1.8565e-01, -7.8439e-02, -9.9991e-02,  2.4493e-02, -3.2068e-01,\n",
      "          1.4571e-01, -1.5393e-01,  1.6768e-02,  3.3204e-01, -1.0322e-01,\n",
      "         -4.8787e-02,  2.5982e-01, -1.7693e-01, -6.0245e-01, -2.9590e-01,\n",
      "         -3.5146e-01,  1.8196e-01, -4.8785e-01, -4.7863e-01,  1.0066e-01,\n",
      "          7.6168e-02, -4.3134e-01, -8.3896e-02, -1.1818e-01, -5.4764e-02,\n",
      "          2.9456e-01,  2.3238e-01,  2.5414e-02, -3.3389e-01,  2.2894e-01,\n",
      "          3.4075e-01, -6.4500e-02,  1.7154e-01,  2.1687e-01,  1.3698e-01,\n",
      "         -3.2044e-01, -2.5218e-02, -5.2969e-02,  7.0103e-01,  1.0721e-01,\n",
      "         -7.1201e-02, -1.1198e-01,  4.3143e-03, -2.1732e-01,  2.0495e-01,\n",
      "         -5.6591e-01, -8.9027e-02,  2.8366e-01, -7.6022e-03,  1.1842e-01,\n",
      "          1.5335e-01, -8.7587e-02, -3.5212e-01, -4.0573e-01, -1.5663e-01,\n",
      "         -1.1843e-01,  1.7602e-01, -5.4013e-02,  1.5503e-01,  2.5938e-01,\n",
      "          2.4074e-01, -7.1546e-02,  1.1126e-01, -3.3298e-03, -7.1853e-02,\n",
      "          1.3352e-01, -2.8499e-02,  8.8273e-02,  3.3162e-01, -1.5682e-01,\n",
      "         -7.2549e-02,  1.9390e-01, -2.8021e-01,  4.0107e-01, -1.5723e-01,\n",
      "          1.0363e-01,  8.8156e-02, -4.6505e-02, -1.5581e-01, -2.0730e-01,\n",
      "          8.2947e-02, -3.8060e-01, -1.0521e-01,  9.6164e-02, -9.0466e-02,\n",
      "         -4.4508e-01,  2.5155e-02, -5.3896e-02,  3.2404e-01,  4.2242e-02,\n",
      "          2.4821e-01,  3.9676e-01,  7.2511e-02, -1.2691e-01, -4.8866e-01,\n",
      "         -2.3854e-01, -1.1036e-01, -5.2127e-01,  1.3872e-01,  2.1022e-01,\n",
      "          3.8425e-01, -2.3940e-01, -2.5022e-01, -1.9291e-01,  1.3512e-02,\n",
      "          2.9680e-01,  1.1513e-01, -1.1332e-01, -1.4018e-01,  2.3069e-01,\n",
      "         -3.9093e-01,  7.9162e-02, -2.3081e-01,  9.2724e-02,  2.1660e-01,\n",
      "         -1.0553e-01, -6.8179e-02,  2.3011e-01,  9.9799e-02, -2.6270e-01,\n",
      "          3.4526e-01, -3.5023e-01,  4.8391e-01,  2.6161e-01,  3.6195e-01,\n",
      "          7.4024e-02,  1.8803e-02, -6.0799e-02, -3.4490e-01,  1.9551e-01,\n",
      "         -2.1337e-01, -9.3688e-02,  2.7129e-01,  3.4806e-01,  1.5230e-01,\n",
      "          9.7186e-03, -4.0688e-01, -4.1721e-01, -1.5210e-01, -5.9169e-03,\n",
      "          1.1677e-01, -4.7621e-01, -4.1546e-02, -2.4280e-04,  3.8050e-02,\n",
      "         -1.7387e-01, -2.1627e-01,  5.9881e-02, -4.3850e-02, -4.8522e-01,\n",
      "         -2.6180e-01, -4.1032e-01, -1.0614e-01, -1.4096e-01,  2.6822e-01,\n",
      "          1.1273e-01,  4.0123e-01,  1.3386e-02,  4.9251e-02, -1.8860e-01,\n",
      "         -3.5431e-02,  1.2199e-01, -1.4772e-02, -5.1449e-01, -2.1975e-01,\n",
      "          2.1861e-01,  7.8945e-04, -5.1552e-01,  1.5696e-02,  8.8709e-02,\n",
      "          5.1472e-02,  5.9859e-02, -3.6038e-01,  2.5840e-01,  8.4175e-02,\n",
      "         -8.7588e-02,  1.9223e-01, -1.3678e-01, -7.6238e-02, -1.8625e-01,\n",
      "          5.4844e-02, -9.0050e-02,  2.5105e-01,  2.1396e-01, -9.1472e-03,\n",
      "          7.6335e-02,  7.5873e-02,  4.2702e-01,  9.3920e-02, -9.7275e-02,\n",
      "          6.2487e-02, -1.0308e-01, -9.6555e-02,  4.4442e-01, -3.0902e-01,\n",
      "          2.7737e-01,  5.8582e-02, -3.7891e-01, -1.1442e-01,  2.4957e-03,\n",
      "         -7.1419e-02, -3.4335e-01,  4.2456e-02,  2.6725e-01, -2.4695e-02,\n",
      "          2.4412e-01, -4.3363e-01, -8.7100e-03, -1.4339e-01, -1.5254e-01,\n",
      "          2.2245e-01,  1.4825e-02,  7.8557e-02, -2.0618e-02, -3.4864e-01,\n",
      "         -2.5554e-01, -3.5996e-01, -3.8347e-02, -7.4948e-01,  2.3345e-01,\n",
      "         -4.4370e-01,  4.8696e-02, -3.3578e-01, -1.5759e-01,  9.4127e-02,\n",
      "         -1.2777e-01,  3.2049e-01,  1.9062e-01, -1.3928e-01, -4.3013e-01,\n",
      "         -2.4726e-01,  1.1094e-01, -1.4528e-01, -3.9840e-02, -3.7906e-01,\n",
      "          5.6791e-02, -4.5137e-01, -6.0441e-01, -2.9442e-01, -9.4791e-01,\n",
      "         -3.8723e-01, -2.1591e-01, -1.7980e-01,  1.1869e-01,  9.5635e-02,\n",
      "         -3.9726e-01, -4.6637e-02, -2.8513e-01, -5.9486e-01,  1.4975e-01,\n",
      "         -1.0220e-01,  3.1273e-01,  2.9410e-05,  1.1897e-01, -2.1393e-01,\n",
      "          3.5480e-02,  3.7525e-01, -2.0780e-01,  1.6936e-01,  2.0366e-01,\n",
      "          1.4344e-01, -5.7699e-02, -4.2561e-03, -1.0648e-01, -1.3297e-01,\n",
      "         -2.7904e-01,  5.2885e-01,  1.5278e-01, -1.7723e-01, -3.8741e-01,\n",
      "          4.9524e-02,  3.9907e-02, -6.6518e-01,  3.3180e-02, -1.9819e-01,\n",
      "         -1.5533e-02, -1.1684e-01,  2.9202e-01, -3.0469e-01,  1.3096e-01,\n",
      "          4.9453e-02, -6.0942e-02, -5.1185e-01,  1.7612e-01, -7.5557e-02,\n",
      "          2.4172e-01, -2.8570e-02,  1.2154e-01,  4.4006e-01,  2.2836e-01,\n",
      "         -1.3460e-01,  1.5763e-03,  2.8259e-02,  3.5028e-01, -7.7545e-02,\n",
      "          2.9936e-01, -4.9439e-01,  2.1384e-01, -1.5008e-02, -1.7402e-01,\n",
      "         -7.4572e-02,  1.8695e-01,  5.9819e-02, -1.6010e-01,  5.4195e-02,\n",
      "         -3.3602e-01,  7.6742e-02, -8.9008e-02, -4.6152e-01, -1.8090e-01,\n",
      "          6.8874e-02,  2.6615e-01, -2.8234e-01,  6.8821e-02, -2.6706e-01,\n",
      "          1.5769e-01,  2.4570e-01,  3.4337e-01,  5.2819e-02, -8.3348e-02,\n",
      "          1.1114e-01,  4.7233e-01,  1.9401e-01, -6.0041e-01,  1.5154e-01,\n",
      "         -1.3565e-01, -3.9881e-01,  2.3568e-01, -3.0523e-02, -6.2407e-01,\n",
      "          4.1666e-02, -2.8791e-01, -1.5488e-03, -1.4962e-01,  8.7956e-02,\n",
      "          2.1250e-01,  3.2595e-01, -2.8315e-02,  3.0989e-01, -1.7852e-01,\n",
      "          3.7893e-01, -7.1496e-02, -1.5077e-01, -4.3876e-01,  2.3800e-01,\n",
      "         -6.1313e-02, -2.4444e-01,  1.9357e-01,  2.2900e-01, -1.6102e-01,\n",
      "         -2.5573e-03,  3.1682e-02,  2.0611e-01,  1.9905e-01,  1.5287e-01,\n",
      "          2.2849e-01, -6.1991e-01,  1.0957e-01,  1.6652e-01, -1.8269e-02,\n",
      "          3.2626e-01,  1.9280e-01, -2.0909e-01, -2.1714e-01, -3.5170e-01,\n",
      "         -1.8237e-01,  2.5569e-02,  2.6648e-01, -5.0150e-01, -6.0585e-01,\n",
      "          3.9145e-01, -6.3972e-02,  3.9738e-02,  1.5248e-01, -3.3874e-01,\n",
      "          5.6679e-02, -2.4484e-02, -2.8963e-01,  2.2531e-02, -1.4735e-01,\n",
      "          6.5719e-02,  2.2627e-01, -1.8708e-01, -1.7223e-01,  1.4685e-01,\n",
      "          3.5539e-01, -1.5291e-01,  1.2540e-01,  2.5486e-01, -1.4955e-01,\n",
      "         -1.6922e-01,  2.7709e-01, -7.0004e-01, -7.2565e-03,  2.5066e-01,\n",
      "          3.1019e-01,  1.7315e-01]], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.2.bias | Size: torch.Size([1]) | Values : tensor([-0.0850], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Saved PyTorch Model State to model.pth\n",
      "0\n",
      "Accuracy: 0.0000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets, transforms\n",
    "from torch.optim import Adam\n",
    "\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = inputTotal.float()\n",
    "        self.labels = labels.float()\n",
    "        self.test_dataset = testSet.float()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Retrieve data and labels at the specified index\n",
    "        x = self.data[index]\n",
    "        y = self.labels[index]\n",
    "        return x, y\n",
    "\n",
    "dataset = CustomDataset(inputTotal, labels)\n",
    "dataloader = DataLoader(dataset, batch_size=28, shuffle=True)\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(1*20, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "    \n",
    "    \n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)\n",
    "\n",
    "loss_fn = nn.BCELoss()\n",
    "learning_rate = 0.01\n",
    "epochs = 10000\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y.unsqueeze(1))  # Make sure y has the same shape as pred\n",
    "\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for param in model.parameters():\n",
    "                param -= learning_rate * param.grad\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{len(dataloader.dataset):>5d}]\")\n",
    "\n",
    "print(f\"Model structure: {model}\\n\\n\")\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \\n\")\n",
    "\n",
    "torch.save(model.state_dict(), \"model.pth\")\n",
    "print(\"Saved PyTorch Model State to model.pth\")\n",
    "\n",
    "test_dataset = CustomDataset(testSet, testLabels)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "model.eval()\n",
    "true_labels = []\n",
    "predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X, y in test_dataloader:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        pred = model(X)\n",
    "        # Store the true labels and predictions\n",
    "        true_labels.extend(y.tolist())\n",
    "        predictions.extend(pred.round().tolist())\n",
    "\n",
    "correct = sum(p == t for p, t in zip(predictions, true_labels))\n",
    "print(correct)\n",
    "accuracy = correct / len(true_labels)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# X = torch.tensor( [0, 0, 0, 0, 0, 0], dtype=torch.float32).unsqueeze(0).to(device)\n",
    "# logits = model(X)\n",
    "# predictions = torch.sign(torch.tanh(logits))\n",
    "# print('prediction:', predictions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "        [0., 1., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 1., 0., 0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 1., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1., 0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testSet.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1085],\n",
      "        [0.7351],\n",
      "        [0.6252],\n",
      "        [0.5696],\n",
      "        [0.6302],\n",
      "        [0.6065],\n",
      "        [0.5713],\n",
      "        [0.5285],\n",
      "        [0.7156],\n",
      "        [0.8161],\n",
      "        [0.0693],\n",
      "        [0.2095],\n",
      "        [0.6441],\n",
      "        [0.4124],\n",
      "        [0.4150],\n",
      "        [0.3690],\n",
      "        [0.3974],\n",
      "        [0.4450],\n",
      "        [0.5333],\n",
      "        [0.7194],\n",
      "        [0.0931],\n",
      "        [0.1461],\n",
      "        [0.2045],\n",
      "        [0.6138],\n",
      "        [0.3045],\n",
      "        [0.3166],\n",
      "        [0.3422],\n",
      "        [0.3813],\n",
      "        [0.4618],\n",
      "        [0.6739],\n",
      "        [0.0778],\n",
      "        [0.2229],\n",
      "        [0.1864],\n",
      "        [0.1887],\n",
      "        [0.6212],\n",
      "        [0.3063],\n",
      "        [0.3358],\n",
      "        [0.3149],\n",
      "        [0.4043],\n",
      "        [0.6664],\n",
      "        [0.0677],\n",
      "        [0.2903],\n",
      "        [0.2735],\n",
      "        [0.1975],\n",
      "        [0.1764],\n",
      "        [0.6382],\n",
      "        [0.3241],\n",
      "        [0.3462],\n",
      "        [0.3912],\n",
      "        [0.5826],\n",
      "        [0.0664],\n",
      "        [0.2160],\n",
      "        [0.2829],\n",
      "        [0.2941],\n",
      "        [0.2206],\n",
      "        [0.1978],\n",
      "        [0.5910],\n",
      "        [0.2821],\n",
      "        [0.4478],\n",
      "        [0.6253],\n",
      "        [0.0811],\n",
      "        [0.2206],\n",
      "        [0.2340],\n",
      "        [0.2660],\n",
      "        [0.2783],\n",
      "        [0.1636],\n",
      "        [0.1865],\n",
      "        [0.5816],\n",
      "        [0.3268],\n",
      "        [0.5382],\n",
      "        [0.0571],\n",
      "        [0.2234],\n",
      "        [0.3115],\n",
      "        [0.2777],\n",
      "        [0.2750],\n",
      "        [0.2281],\n",
      "        [0.2305],\n",
      "        [0.1681],\n",
      "        [0.6475],\n",
      "        [0.6552],\n",
      "        [0.0478],\n",
      "        [0.1580],\n",
      "        [0.1690],\n",
      "        [0.1838],\n",
      "        [0.2285],\n",
      "        [0.1946],\n",
      "        [0.1964],\n",
      "        [0.1409],\n",
      "        [0.2245],\n",
      "        [0.7424],\n",
      "        [0.0084],\n",
      "        [0.0269],\n",
      "        [0.0351],\n",
      "        [0.0493],\n",
      "        [0.0372],\n",
      "        [0.0328],\n",
      "        [0.0354],\n",
      "        [0.0495],\n",
      "        [0.0611],\n",
      "        [0.1106]], grad_fn=<SigmoidBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 0,  ..., 0, 0, 0],\n",
       "        [1, 0, 0,  ..., 0, 0, 0],\n",
       "        [1, 0, 0,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0,  ..., 1, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 1, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 1]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(model(testSet.float()))\n",
    "testSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 1, 1, 1],\n",
       "        [0, 0, 1, 1, 1],\n",
       "        [0, 0, 0, 1, 1],\n",
       "        [0, 0, 0, 0, 1],\n",
       "        [0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testLabels.reshape(5,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0933, 0.7676, 0.5895, 0.7358, 0.8610],\n",
       "        [0.0490, 0.1603, 0.7233, 0.5696, 0.7475],\n",
       "        [0.0389, 0.1177, 0.1602, 0.6867, 0.6383],\n",
       "        [0.0343, 0.1042, 0.1117, 0.1964, 0.7517],\n",
       "        [0.0069, 0.0289, 0.0396, 0.0525, 0.1298]], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(testSet.float()).reshape(5,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [0, 0, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [0, 0, 0, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [0, 0, 0, 0, 1, 1, 1, 1, 1, 1],\n",
       "        [0, 0, 0, 0, 0, 1, 1, 1, 1, 1],\n",
       "        [0, 0, 0, 0, 0, 0, 1, 1, 1, 1],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 1, 1, 1],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testLabels.reshape(10,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x193dc103cd0>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZoAAAGkCAYAAAAIduO+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/H5lhTAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAUlElEQVR4nO3df6iW9f348dfxmMezOOdgNs2Dx3KxYamldizKL62RJH0qCkZbYCAGY2yn1ISYblSLZifHJoI2y9iaMO0HDKnFtyQc5VyJphnFttyQbztL1II4txncuXPu7x/jcz47H7Wd23x53ffx8YCLOFf3de4X7yPnyfvc51x3Q6VSqQQAJBlR9AAADG9CA0AqoQEgldAAkEpoAEglNACkEhoAUgkNAKmEBoBUQgNAqroNzWOPPRYXXXRRjB49Oq666qrYuXNn0SPVlO7u7pg9e3a0tLTEuHHj4rbbbov33nuv6LFq3qOPPhoNDQ2xZMmSokepSR988EHceeedMXbs2Ghubo7p06fHm2++WfRYNaWvry/uv//+mDx5cjQ3N8fFF18cDz/8cJzNd/uqy9A8++yzsXTp0njwwQdjz549cfnll8e8efPi8OHDRY9WM1577bXo6uqKHTt2xCuvvBLHjh2LG264IY4ePVr0aDVr165d8cQTT8Rll11W9Cg16eOPP445c+bEOeecEy+99FL86U9/ip///OcxZsyYokerKStXrox169bF2rVr489//nOsXLkyfvrTn8aaNWuKHq0wDfV4U82rrroqZs+eHWvXro2IiP7+/ujo6Ih77rknli1bVvB0tenDDz+McePGxWuvvRbXXntt0ePUnE8++SRmzZoVv/jFL+InP/lJzJgxI1avXl30WDVl2bJl8cc//jH+8Ic/FD1KTbv55ptj/Pjx8ctf/nLg3De/+c1obm6O3/zmNwVOVpy629F89tlnsXv37pg7d+7AuREjRsTcuXPjjTfeKHCy2tbb2xsREeedd17Bk9Smrq6uuOmmmwb9u2KwF154ITo7O+P222+PcePGxcyZM+PJJ58seqyac80118TWrVtj3759ERHx9ttvx/bt2+PGG28seLLijCx6gGp99NFH0dfXF+PHjx90fvz48fGXv/yloKlqW39/fyxZsiTmzJkT06ZNK3qcmvPMM8/Enj17YteuXUWPUtP2798f69ati6VLl8YPf/jD2LVrVyxatChGjRoVCxYsKHq8mrFs2bIolUoxZcqUaGxsjL6+vlixYkXMnz+/6NEKU3ehoXpdXV3x7rvvxvbt24sepeb09PTE4sWL45VXXonRo0cXPU5N6+/vj87OznjkkUciImLmzJnx7rvvxuOPPy40/+a5556LjRs3xqZNm2Lq1Kmxd+/eWLJkSbS3t5+161R3oTn//POjsbExDh06NOj8oUOH4oILLihoqtp19913x4svvhjbtm2LiRMnFj1Ozdm9e3ccPnw4Zs2aNXCur68vtm3bFmvXro1yuRyNjY0FTlg7JkyYEJdeeumgc5dcckn89re/LWii2nTffffFsmXL4o477oiIiOnTp8f7778f3d3dZ21o6u41mlGjRsUVV1wRW7duHTjX398fW7dujauvvrrAyWpLpVKJu+++OzZv3hy///3vY/LkyUWPVJOuv/76eOedd2Lv3r0DR2dnZ8yfPz/27t0rMv9mzpw5x/2K/L59++LCCy8saKLa9Omnn8aIEYO/tTY2NkZ/f39BExWv7nY0ERFLly6NBQsWRGdnZ1x55ZWxevXqOHr0aCxcuLDo0WpGV1dXbNq0KZ5//vloaWmJgwcPRkREW1tbNDc3Fzxd7WhpaTnudatzzz03xo4d6/Ws/+Xee++Na665Jh555JH41re+FTt37oz169fH+vXrix6tptxyyy2xYsWKmDRpUkydOjXeeuutWLVqVdx1111Fj1acSp1as2ZNZdKkSZVRo0ZVrrzyysqOHTuKHqmmRMQJj6eeeqro0Wre17/+9crixYuLHqMm/e53v6tMmzat0tTUVJkyZUpl/fr1RY9Uc0qlUmXx4sWVSZMmVUaPHl35yle+UvnRj35UKZfLRY9WmLr8OxoA6kfdvUYDQH0RGgBSCQ0AqYQGgFRCA0AqoQEgVd2Gplwux49//OMol8tFj1LzrNXQWKehsU5DZ63+pW7/jqZUKkVbW1v09vZGa2tr0ePUNGs1NNZpaKzT0Fmrf6nbHQ0A9UFoAEh1xm+q2d/fHwcOHIiWlpZoaGg45c9TKpUG/ZeTs1ZDY52GxjoN3XBfq0qlEkeOHIn29vbj7lj97874azT/+Mc/oqOj40w+JQCJenp6Pvf9rs74jqalpSUiIv5P/FeMjHPO9NOf1OZ97xQ9AkBdKX3SHxfO+n8D39dP5oyH5r9/XDYyzomRDbUTmtYWL1cBnIr/9DKI764ApBIaAFIJDQCphAaAVEIDQCqhASCV0ACQSmgASCU0AKQSGgBSCQ0AqYQGgFSnFJrHHnssLrroohg9enRcddVVsXPnztM9FwDDRNWhefbZZ2Pp0qXx4IMPxp49e+Lyyy+PefPmxeHDhzPmA6DOVR2aVatWxXe+851YuHBhXHrppfH444/Hl770pfjVr36VMR8Ada6q0Hz22Wexe/fumDt37v98ghEjYu7cufHGG2+c8JpyuRylUmnQAcDZo6rQfPTRR9HX1xfjx48fdH78+PFx8ODBE17T3d0dbW1tA4e3cQY4u6T/1tny5cujt7d34Ojp6cl+SgBqSFVv5Xz++edHY2NjHDp0aND5Q4cOxQUXXHDCa5qamqKpqenUJwSgrlW1oxk1alRcccUVsXXr1oFz/f39sXXr1rj66qtP+3AA1L+qdjQREUuXLo0FCxZEZ2dnXHnllbF69eo4evRoLFy4MGM+AOpc1aH59re/HR9++GE88MADcfDgwZgxY0a8/PLLx/2CAABERDRUKpXKmXzCUqkUbW1tcV3cGiMbzjmTT/25thzYW/QIAHWldKQ/xnxtf/T29kZra+tJH+deZwCkEhoAUgkNAKmEBoBUQgNAKqEBIJXQAJBKaABIJTQApBIaAFIJDQCpqr6p5nA1r31G0SMcp1bvv1aLa1WLavHrV4tfu1pcJ04vOxoAUgkNAKmEBoBUQgNAKqEBIJXQAJBKaABIJTQApBIaAFIJDQCphAaAVEIDQCqhASCV0ACQSmgASCU0AKQSGgBSCQ0AqYQGgFRCA0AqoQEgldAAkEpoAEglNACkEhoAUgkNAKmEBoBUQgNAKqEBIJXQAJBKaABIJTQApBIaAFIJDQCphAaAVEIDQKqRRQ/Ayc1rn1H0CCe05cDeokc4Ti2uVS3OVItqdZ1q8d95vbKjASCV0ACQSmgASCU0AKQSGgBSCQ0AqYQGgFRCA0AqoQEgldAAkEpoAEglNACkEhoAUgkNAKmqCk13d3fMnj07WlpaYty4cXHbbbfFe++9lzUbAMNAVaF57bXXoqurK3bs2BGvvPJKHDt2LG644YY4evRo1nwA1Lmq3vjs5ZdfHvTxr3/96xg3blzs3r07rr322tM6GADDwxd6h83e3t6IiDjvvPNO+phyuRzlcnng41Kp9EWeEoA6c8q/DNDf3x9LliyJOXPmxLRp0076uO7u7mhraxs4Ojo6TvUpAahDpxyarq6uePfdd+OZZ5753MctX748ent7B46enp5TfUoA6tAp/ejs7rvvjhdffDG2bdsWEydO/NzHNjU1RVNT0ykNB0D9qyo0lUol7rnnnti8eXO8+uqrMXny5Ky5ABgmqgpNV1dXbNq0KZ5//vloaWmJgwcPRkREW1tbNDc3pwwIQH2r6jWadevWRW9vb1x33XUxYcKEgePZZ5/Nmg+AOlf1j84AoBrudQZAKqEBIJXQAJBKaABIJTQApBIaAFIJDQCphAaAVEIDQCqhASCV0ACQSmgASHVKb3zG2W1e+4yiRzjOlgN7ix7hOLW4TgxdLX79avHf+VDY0QCQSmgASCU0AKQSGgBSCQ0AqYQGgFRCA0AqoQEgldAAkEpoAEglNACkEhoAUgkNAKmEBoBUQgNAKqEBIJXQAJBKaABIJTQApBIaAFIJDQCphAaAVEIDQCqhASCV0ACQSmgASCU0AKQSGgBSCQ0AqYQGgFRCA0AqoQEgldAAkEpoAEglNACkEhoAUo0segA4Hea1zyh6hONsObC36BGOU4vrVKtq8etXr+xoAEglNACkEhoAUgkNAKmEBoBUQgNAKqEBIJXQAJBKaABIJTQApBIaAFIJDQCphAaAVEIDQKovFJpHH300GhoaYsmSJadpHACGm1MOza5du+KJJ56Iyy677HTOA8Awc0qh+eSTT2L+/Pnx5JNPxpgxY073TAAMI6cUmq6urrjpppti7ty5//Gx5XI5SqXSoAOAs0fVb+X8zDPPxJ49e2LXrl1Denx3d3c89NBDVQ8GwPBQ1Y6mp6cnFi9eHBs3bozRo0cP6Zrly5dHb2/vwNHT03NKgwJQn6ra0ezevTsOHz4cs2bNGjjX19cX27Zti7Vr10a5XI7GxsZB1zQ1NUVTU9PpmRaAulNVaK6//vp45513Bp1buHBhTJkyJX7wgx8cFxkAqCo0LS0tMW3atEHnzj333Bg7duxx5wEgwp0BAEhW9W+d/W+vvvrqaRgDgOHKjgaAVEIDQCqhASCV0ACQSmgASCU0AKQSGgBSCQ0AqYQGgFRCA0AqoQEg1Re+1xlwYvPaZxQ9wnG2HNhb9AjHqcV1iqjNuWrx6zcUdjQApBIaAFIJDQCphAaAVEIDQCqhASCV0ACQSmgASCU0AKQSGgBSCQ0AqYQGgFRCA0AqoQEgldAAkEpoAEglNACkEhoAUgkNAKmEBoBUQgNAKqEBIJXQAJBKaABIJTQApBIaAFIJDQCphAaAVEIDQCqhASCV0ACQSmgASCU0AKQSGgBSCQ0AqYQGgFQjix4AOHPmtc8oeoTjbDmwt+gRTqgW16pe2dEAkEpoAEglNACkEhoAUgkNAKmEBoBUQgNAKqEBIJXQAJBKaABIJTQApBIaAFIJDQCphAaAVFWH5oMPPog777wzxo4dG83NzTF9+vR48803M2YDYBio6v1oPv7445gzZ0584xvfiJdeeim+/OUvx1//+tcYM2ZM1nwA1LmqQrNy5cro6OiIp556auDc5MmTT/tQAAwfVf3o7IUXXojOzs64/fbbY9y4cTFz5sx48sknP/eacrkcpVJp0AHA2aOq0Ozfvz/WrVsXX/3qV2PLli3xve99LxYtWhQbNmw46TXd3d3R1tY2cHR0dHzhoQGoHw2VSqUy1AePGjUqOjs74/XXXx84t2jRoti1a1e88cYbJ7ymXC5HuVwe+LhUKkVHR0dcF7fGyIZzvsDowHCw5cDeokc4oXntM4oe4Ti1tlalI/0x5mv7o7e3N1pbW0/6uKp2NBMmTIhLL7100LlLLrkk/v73v5/0mqampmhtbR10AHD2qCo0c+bMiffee2/QuX379sWFF154WocCYPioKjT33ntv7NixIx555JH429/+Fps2bYr169dHV1dX1nwA1LmqQjN79uzYvHlzPP300zFt2rR4+OGHY/Xq1TF//vys+QCoc1X9HU1ExM033xw333xzxiwADEPudQZAKqEBIJXQAJBKaABIJTQApBIaAFIJDQCphAaAVEIDQCqhASCV0ACQqup7nQGcTrX4BmMRtfcmY/XMjgaAVEIDQCqhASCV0ACQSmgASCU0AKQSGgBSCQ0AqYQGgFRCA0AqoQEgldAAkEpoAEglNACkEhoAUgkNAKmEBoBUQgNAKqEBIJXQAJBKaABIJTQApBIaAFIJDQCphAaAVEIDQCqhASCV0ACQSmgASCU0AKQSGgBSCQ0AqYQGgFRCA0AqoQEgldAAkEpoAEg1sugBAGrRvPYZRY9wnC0H9hY9wimxowEgldAAkEpoAEglNACkEhoAUgkNAKmEBoBUQgNAKqEBIJXQAJBKaABIJTQApBIaAFJVFZq+vr64//77Y/LkydHc3BwXX3xxPPzww1GpVLLmA6DOVfU2AStXrox169bFhg0bYurUqfHmm2/GwoULo62tLRYtWpQ1IwB1rKrQvP7663HrrbfGTTfdFBERF110UTz99NOxc+fOlOEAqH9V/ejsmmuuia1bt8a+ffsiIuLtt9+O7du3x4033njSa8rlcpRKpUEHAGePqnY0y5Yti1KpFFOmTInGxsbo6+uLFStWxPz58096TXd3dzz00ENfeFAA6lNVO5rnnnsuNm7cGJs2bYo9e/bEhg0b4mc/+1ls2LDhpNcsX748ent7B46enp4vPDQA9aOqHc19990Xy5YtizvuuCMiIqZPnx7vv/9+dHd3x4IFC054TVNTUzQ1NX3xSQGoS1XtaD799NMYMWLwJY2NjdHf339ahwJg+KhqR3PLLbfEihUrYtKkSTF16tR46623YtWqVXHXXXdlzQdAnasqNGvWrIn7778/vv/978fhw4ejvb09vvvd78YDDzyQNR8Ada6hcob/rL9UKkVbW1tcF7fGyIZzzuRTA9S1LQf2Fj3CIKUj/THma/ujt7c3WltbT/o49zoDIJXQAJBKaABIJTQApBIaAFIJDQCphAaAVEIDQCqhASCV0ACQSmgASCU0AKSq6u7NABRnXvuMokcY5J+VYxGx/z8+zo4GgFRCA0AqoQEgldAAkEpoAEglNACkEhoAUgkNAKmEBoBUQgNAKqEBIJXQAJBKaABIJTQApBIaAFIJDQCphAaAVEIDQCqhASCV0ACQSmgASCU0AKQSGgBSCQ0AqYQGgFRCA0AqoQEgldAAkEpoAEglNACkEhoAUgkNAKmEBoBUQgNAKqEBINXIM/2ElUolIiL+GcciKmf62QE4Xf4ZxyLif76vn8wZD82RI0ciImJ7/N8z/dQAJDhy5Ei0tbWd9P83VP5Tik6z/v7+OHDgQLS0tERDQ8Mpf55SqRQdHR3R09MTra2tp3HC4cdaDY11GhrrNHTDfa0qlUocOXIk2tvbY8SIk78Sc8Z3NCNGjIiJEyeets/X2to6LL+AGazV0FinobFOQzec1+rzdjL/zS8DAJBKaABIVbehaWpqigcffDCampqKHqXmWauhsU5DY52Gzlr9yxn/ZQAAzi51u6MBoD4IDQCphAaAVEIDQCqhASCV0ACQSmgASCU0AKT6/5a1491bNwuXAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(model(testSet.float()).reshape(10,10).detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(model(testSet.float())[:,0].round()==testLabels).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "NeuralNetwork                            [1, 1, 1, 1]              --\n",
       "Sequential: 1-1                        [1, 1, 1, 1]              --\n",
       "    Linear: 2-1                       [1, 1, 1, 512]            3,584\n",
       "    ReLU: 2-2                         [1, 1, 1, 512]            --\n",
       "    Linear: 2-3                       [1, 1, 1, 1]              513\n",
       "    Sigmoid: 2-4                      [1, 1, 1, 1]              --\n",
       "==========================================================================================\n",
       "Total params: 4,097\n",
       "Trainable params: 4,097\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 0.00\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.00\n",
       "Params size (MB): 0.02\n",
       "Estimated Total Size (MB): 0.02\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "summary(model, input_size=(1, 1, 1, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define a function to get the activations of the last layer\n",
    "def get_activations(model, dataloader):\n",
    "    model.eval()\n",
    "    activations = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X = X.to(device)\n",
    "            # Get the activations of the last layer (before sigmoid)\n",
    "            logits = model(X)\n",
    "            # Append the activations to the list\n",
    "            activations.extend(logits.cpu().numpy())\n",
    "\n",
    "    return activations\n",
    "\n",
    "# Get the activations of the last layer for the test dataset\n",
    "activations = get_activations(model, test_dataloader)\n",
    "\n",
    "# Plot the activations\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(activations, 'o', markersize=2)\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Activation')\n",
    "plt.title('Activations of Last Layer')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lukel\\AppData\\Local\\Temp\\ipykernel_26920\\2814909403.py:13: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  pred_label = int(pred_label)  # Convert to integer\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Convert true labels and predictions to numpy arrays\n",
    "true_labels_np = np.array(true_labels)\n",
    "predictions_np = np.array(predictions)\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = np.zeros((2, 2))\n",
    "for true_label, pred_label in zip(true_labels_np, predictions_np):\n",
    "    true_label = int(true_label)  # Convert to integer\n",
    "    pred_label = int(pred_label)  # Convert to integer\n",
    "    conf_matrix[true_label][pred_label] += 1\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\".0f\", cmap=\"Blues\", cbar=False)\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
